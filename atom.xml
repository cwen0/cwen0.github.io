<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>cwen</title>
  <id>http://int64.me</id>
  <updated>2022-06-13T19:31:45+08:00</updated>
  <subtitle>Life is magic. Coding is art.</subtitle>
  <link href="http://int64.me"></link>
  <entry>
    <title>计算机基础概念：状态机</title>
    <updated>2020-08-06T00:00:00Z</updated>
    <id>tag:int64.me,2020-08-06:/2020/计算机基础概念：状态机.html</id>
    <link href="http://int64.me/2020/计算机基础概念：状态机.html" rel="alternate"></link>
    <summary type="html">&lt;hr&gt;&#xA;&lt;p&gt;最近在看 Raft 算法的时候，在论文中提到了状态机的概念，说实话其实一开始还是很懵逼，并不知道这个状态机为何物（有点丢人），于是乎就去学习了一波，这里只是做一个简单的整理和记录。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;定义&lt;/h2&gt;&#xA;&lt;p&gt;状态机是有限状态机的简称 （fsm），用于设计算法的数学抽象，简单来说，状态机将读取一系列输入，当它读取输入时，将切换到一个特定的状态，并且当输入不变的时候，每次的切换到的状态也是不变的。这些相互切换的状态数量是有限的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-1&#34;&gt;案例解释&lt;/h2&gt;&#xA;&lt;p&gt;想象一下，有这样一个设备可以读取一系列输入，输入的内容是一段连续的字母，这段字母中只包含了 a 和 b。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/finite-state-machine-tape.png&#34; alt=&#34;fsm&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;把这个设备看作一个状态机，当状态机读取每一个字母的时候，它会改变状态，并且它只有两个状态 s 和 q 。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/simple-state-machine.png&#34; alt=&#34;stm&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上图中圆圈中是状态机可以进入的 “状态”。箭头代表过度。所以如果你在状态 s 中读取到 a 你就会转变为状态 q，如果你读取了一个 b，那么就会停留在 s 状态。这样可以看出来，给定一个输入以及知道当前的自己状态，我们很容易推算出输出的结果，这里和很好的符合了一个数学模型抽象的概念。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-2&#34;&gt;程序中的状态机&lt;/h2&gt;&#xA;&lt;p&gt;从上面可以得知状态机并不是实际的机器设备，而是一个数学模型，通常体现为一个状态转换图。同样在我们日常编程代码实现中，其实我们也是经常使用到的，这里我想当一个经典的案例就是 TCP 的状态转换:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/tcp-state.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;从上图可以看出，整体的 TPC 状态转换图也可以称为一个状态机。这是复制案例，在编程中简单的状态机器实现其实很简单，就比使用简单 &lt;code&gt;if...else...&lt;/code&gt; 或者 &lt;code&gt;switch&lt;/code&gt; 就可以办到:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 定义状态&#xA;enum {&#xA;  GOOD,&#xA;  BAD,&#xA;}&#xA;&#xA;int main() {&#xA;  int state = GOOD;&#xA;  while (1) {&#xA;    if (state == GOOD) {&#xA;      xxx; // 具体调用函数&#xA;      state = BAD；// 状态转移&#xA;    } else if (state == BAD) {&#xA;      xxx; // 具体调用函数&#xA;      state == GOOD;&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;上面可以说是一个最简单的状态机了，里面之涉及到两个状态之间的转移。由此可见其实状态机其实是我们编程中最最基本的一种编程思想了😂。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-3&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.markshead.com/869/state-machines-computer-science/&#34;&gt;State Machines – Basics of Computer Science&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Finite-state_machine&#34;&gt;Wiki&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/47434856&#34;&gt;什么是状态机&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>一致性模型笔记</title>
    <updated>2020-04-26T00:00:00Z</updated>
    <id>tag:int64.me,2020-04-26:/2020/一致性模型笔记.html</id>
    <link href="http://int64.me/2020/一致性模型笔记.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;谈到分布式系统，一致性的问题就不得不被提到，可以说是一个老生长谈的话题，这几天在准备一个关于分布式测试相关的分享的时候，涉及到一些一致性和一致性验证相关的问题，但是突然发现自己的脑子里差不多一片空白，之前也有看过相关的论文和一些实践项目，可能是由于没有自己实际去实践导致很多概念都不太清楚，就重新学习了一波，并整理一些相关的笔记（毕竟好记性不如烂笔头，如果笔记中存在错误，还请指出来帮助我改正）帮助更好的理解这些概念。&lt;/p&gt;&#xA;&lt;p&gt;数据库和分布式系统中都有一致性的概念，如数据库四大特征 &lt;code&gt;ACID&lt;/code&gt; 中的 &lt;code&gt;C&lt;/code&gt; 就是 &lt;code&gt;Consistency&lt;/code&gt; 的简写，只是这个一致性强调的是数据库逻辑的一致性，保证事务前后的数据都符合业务里的不变性约束，比如保证外键约束等。再比如分布式理论 &lt;code&gt;CAP&lt;/code&gt; 中的 &lt;code&gt;C&lt;/code&gt; 也是一致性，这里的一致性主要强调是读操作是否能够读到最新的结果，以及并发场景下操作执行的时序关系，一般而言，分布式系统中的一致性从强到弱可以分为四种：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Linearizability&#34;&gt;线性一致性 （Linearizability：Strong consistency or Atomic consistency)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Sequential_consistency&#34;&gt;顺序一致性（Sequential consistency）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Causal_consistency&#34;&gt;因果一致性（Causal consistency）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Eventual_consistency&#34;&gt;最终一致性（Eventual consistency）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在这篇笔记中主要会涉及到线性一致性和顺序一致性，并且会讲到之前我一直分不清的线性一致性和可序列化（Serializability）之间的差异，最后会着重介绍到目前用来验证线性一致性的几个常用算法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;先看一张图&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/jepsen.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这图来自 &lt;a href=&#34;https://jepsen.io/consistency&#34;&gt;Jepesn&lt;/a&gt; 官网的博客，用来展示并发系统中一致性模型之间的关系。模块之间的箭头显示的是之间的互相依赖关系，比如严格可序列化 (Strict Serializble，Strict 1SR, Strong 1SR) 意味着需要同时满足线性一致性 (Linearizability) 和可序列化(Serializability)。图片上不同的颜色显示异步网络上的分布式系统每个模型的可用性。 关于可用性的更多细节，可以参考论文 [Highly Available Transactions: V&lt;img src=&#34;http://note.youdao.com/yws/res/8917/WEBRESOURCE0f62a29cb1a76d66329ba6f1305538d3&#34; alt=&#34;image&#34;&gt;irtues and Limitations] (&lt;a href=&#34;http://www.vldb.org/pvldb/vol7/p181-bailis.pdf&#34;&gt;http://www.vldb.org/pvldb/vol7/p181-bailis.pdf&lt;/a&gt;)，这篇论文里，作者总结不同模型是否满足 Highly Available Transactions(HATs)，在这里就不多加赘述。&lt;/p&gt;&#xA;&lt;p&gt;从上面图中可以看到，从根节点 Strict Serializble 开始分成两个分支，一个分支对应的就是分布式系统中一致性 Consistency (CAP 中 C)，另一个对应的就是数据库中的 Isolation (ACID 中的 I)。后面会分别介绍这两个分支，并分析他们之间的差异。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-linearizability&#34;&gt;线性一致性 (Linearizability)&lt;/h2&gt;&#xA;&lt;p&gt;线性一致性 (Linearizability) 是上图右边分支的开始，Linearizability  又被称为强一致性或者原子一致性，在 &lt;a href=&#34;https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf&#34;&gt;Linearizability: A Correctness Condition for Concurrent Objects&lt;/a&gt; 论文中给出了形式化的定义和证明，论文里面一致性是基于 single-object (eg: queue, register) 以及 single-operation (eg: read, write, enqueue, dequeue) 的模型来定义的，从定义上来看线性一致性是一个单对象的模型，但是这个对象的范围是变化的，我们也可以把一个 register 作为一个对象同样也可以把一个分布式数据库看作一个对象。由于上述定义，如果我们要在任意的分布式系统中严谨的讨论 Linearizability, 就需要将系统以某种方式规约到这个模型中。&lt;/p&gt;&#xA;&lt;p&gt;Linearizability 的基本想法是让一个系统看起好像只有一个数据副本，且所有的操作都是原子的。在一个可线性化的系统中，一旦某个客户端成功提交写请求，所有客户端的读请求一定能够看到最近写入的值。在这个解释里面需要注意两个关键词：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最近写入&lt;/li&gt;&#xA;&lt;li&gt;所有客户端&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;最近写入&lt;/strong&gt;强调的是明确基于实际时间的先后顺序，&lt;strong&gt;所有客户端&lt;/strong&gt;强调的是对任务客户端的表现是一致的。为了更好的解释 Linearizability 想法，我们先看一个理想中的例子：&lt;/p&gt;&#xA;&lt;p&gt;假如我们将分布式系统看作一个整体，如果我们的系统满足线性一致性并且同时我们有四个 Client 进行读写操作，那么我们系统处理这四个客户端请求的流程应该如下图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/linearizability-1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在上面描述的时候，我们有一个假设就是假设把我们的分布式系统看作一个整体，并且满足线性一致性，那么我们的每次操作都是原子的并且依次的执行，上图的更加简化版本可以把每一次操作看作是一个单独的点，每次操作都是立刻发生的:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/linearizability-2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;但是在实际情况中，分布式系统通常是很多节点作为一个整体对外提供服务，并会遇到网络异常或者某些节点出现故障，所以我们每一次操作的时候并不能做到立即相应，当我们多个客户端进行请求的时候大概率是会出现重叠的，在这种情况下，如果我们的操作满足约束：&lt;strong&gt;一旦某一个读操作返回了新值，之后所有的读（包括相同或不同的客户端）都必须返回新值&lt;/strong&gt;，那么我们可以判断这组操作历史满足线性一致性。这条约束也是后面我们用来验证线性一致性的关键之一。&lt;/p&gt;&#xA;&lt;p&gt;为了更好的理解，我们先看一组&lt;strong&gt;不满足线性一致性&lt;/strong&gt;的历史操作：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/linearizability-3.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上图中每一个客户端所在的行代表这个客户端所进行的请求，每一个矩形框代表一次请求，&lt;code&gt;Invoke&lt;/code&gt; 代表发起请求的时间，&lt;code&gt;Response&lt;/code&gt; 代表收到响应结果的时间，由于网络延迟不确定，客户端并不清楚系统具体何时真正处理请求的，而只知道它是发生在发起请求、收到响应之前的某一个中间点。&lt;/p&gt;&#xA;&lt;p&gt;在上图例子中，我们假设所有点线性化到时间轴上的，可以看到在 client 3 成功读取到 x-&amp;gt;1, 但是在 client3 读取之后，client 4 同样也发起了一个读取的请求，但是确读取到了 x-&amp;gt;0, client 4 的读取操作违反了上述线性一致性的约定，所以这段操作历史是不满足线性一致性的。为了更好的对比，这里提供一个满足线性一致性的历史的示例，其实在图中如果 client 4 读取的结果返回的是 1， 这段历史其实就是满足线性一致性。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/linearizability-4.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;其实我们在判断这段历史是否符合线性一致性的过程最后用代码的方式去实现就构成了验证线性一致性算法的最基本逻辑。在后续会更加详细的介绍到。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-sequential-consistency&#34;&gt;顺序一致性 (Sequential Consistency)&lt;/h2&gt;&#xA;&lt;p&gt;在 Herlihy &amp;amp; Wing 提出线性一致性之前，Lamport 老爷子早在 1979 年就提出了顺序一致性（Sequential consistency)的概念:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;A multiprocessor system is sequentially consistent if the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;上述定义是基于 shared-memory multi-processor 系统的，我们可以把这种系统理解成不同分布式模式，从而拓展到分布式系统领域。&lt;/p&gt;&#xA;&lt;p&gt;Lamport 的定义中对系统提出了两条共享对象时的约束：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从单个处理器 (线程或者进程)的角度来看，执行指令的顺序以编程中的顺序为准。&lt;/li&gt;&#xA;&lt;li&gt;从所有的处理器(线程或者进程)的角度来看，指令的执行保持一个单一的顺序。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;约束 1 保证列单个进程中的执行按照程序顺序来执行，约束2保证了所有的内存操作都是原子。这里我们可以发现这里的约束和线性一致性相比，宽松了很多，这里只是要求按照编程顺序而不再是时间顺序了。为了更好的理解这两个的差异，我们同样用一组示例来解释：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/linearizability-5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;对于顺序一致性来讲，不在要求绝对的时间顺序，只要满足编程顺序就可以，所以针对上图中历史 (a) 我们可以找到这样的执行序列 &lt;code&gt;Write(&amp;quot;y&amp;quot;, 1) -&amp;gt; Read(&amp;quot;x&amp;quot; -&amp;gt; 0) -&amp;gt; Write(&amp;quot;x&amp;quot;, 1) -&amp;gt; Read(&amp;quot;y&amp;quot; -&amp;gt; 1)&lt;/code&gt; 满足顺序一致性，但是对于历史 (a) 我们可以判断他是部署线性一致性，因为 &lt;code&gt;Wriete(&amp;quot;x&amp;quot;,1)&lt;/code&gt; 要先于 &lt;code&gt;Read(&amp;quot;x&amp;quot;) -&amp;gt; 0&lt;/code&gt; 执行，但是 Read 却没有读取到最新值。&lt;/p&gt;&#xA;&lt;p&gt;对于历史 (b) 而言，差异是 clien2 执行 &lt;code&gt;Read(&amp;quot;x&amp;quot;)&lt;/code&gt; 得到的结果是 1, 为最新的值，符合时间顺序的 &amp;quot;写后读&amp;quot; 的约束，所以是线性一致性。&lt;/p&gt;&#xA;&lt;p&gt;对于历史 (c) 不管如何的排序，都无法满足 &amp;quot;写后读&amp;quot; 约束，所以既不符合线性一致性，也不符合顺序一致性。&lt;/p&gt;&#xA;&lt;p&gt;从上述的示例可以看出，&lt;strong&gt;顺序一致性和线性一致性都是要找到一个满足  &amp;quot;写后读&amp;quot; 的一组操作历史，差异在于线性一致性要求严格的时间序，而顺序一致性只要求满足编程顺序&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在回到最开始 Jepsen 的那张图上，顺序一致性再往下是因果一致性以及 PRAM(Pipeline Random Access Memory),  这些是更加宽松的一致性保证，这里不多做解释，我们继续探索另一分支。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-serializability&#34;&gt;可串行化 (Serializability)&lt;/h2&gt;&#xA;&lt;p&gt;可串行化 (Serializability) 是上图 Jepsen 中左边分支的开始，可序列化是事务的隔离属性，可以读写多个对象（行，文档，记录等）。他用来确保事务的执行结果与串行（即每次执行一次事务）的结果完全相同，即使串行执行的顺序可能钺事务的实际执行顺序不同。&lt;/p&gt;&#xA;&lt;p&gt;这里要想快速理解事务的隔离级别，可以参考论文 &lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf&#34;&gt;A Critique of ANSI SQL Isolation Levels&lt;/a&gt;, 在这篇论文中详细节介绍了数据库实现中遇到的各种个样的隔离问题，以及讨论不同隔离级别存在的问题。为了更好系统的解释隔离级别，下面会简要描述下论文里面用来区分不同隔离级别的各种异常现象。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;后面关于隔离级别的描述示例取自唐长老博客：&lt;a href=&#34;https://www.jianshu.com/p/3673e612cce2&#34;&gt;一致性模型&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;p0---dirty-write&#34;&gt;P0 - Dirty Write&lt;/h3&gt;&#xA;&lt;p&gt;Dirty Write 描述的一个事务覆盖了另一个之前未提交事务写入的值。比如说我们有两个事务，一个事务写入 T1 x=y=1, 而另一个事务 T2 写入 x=y=2, 最终结果却得到了 x=2 y=1，这明显就是一个事务覆盖了一个未提交的事务。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+------+-------+-------+-------+-------+&#xA;| T1   | Wx(1) |       |       | Wy(1) |&#xA;+------+-------+-------+-------+-------+&#xA;| T2   |       | Wx(2) | Wy(2) |       |&#xA;+------+-------+-------+-------+-------+&#xA;| x(0) | 1     | 2     | 2     | 2     |&#xA;+------+-------+-------+-------+-------+&#xA;| y(0) | 0     | 0     | 2     | 1     |&#xA;+------+-------+-------+-------+-------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;p1---dirty-read&#34;&gt;P1 - Dirty Read&lt;/h3&gt;&#xA;&lt;p&gt;Dirty Read 现象描述： T1 对某一个数据项进行修改，T2 在 T1 commit 或者 rollback之前读取这个数据项，然后 T1 rollback 了，那么 T2 就读取到了一个从未被 commit 或者一个从未存在的数据&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-------+--------+--------+--------+--------+&#xA;| T1    | Wx(10) |        |        | Wy(90) |&#xA;+-------+--------+--------+--------+--------+&#xA;| T2    |        | Rx(10) | Ry(50) |        |&#xA;+-------+--------+--------+--------+--------+&#xA;| x(50) | 10     | 10     | 10     | 10     |&#xA;+-------+--------+--------+--------+--------+&#xA;| y(50) | 50     | 50     | 50     | 90     |&#xA;+-------+--------+--------+--------+--------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如上述示例中，初始状态 x=y=50, x+y=100, 然后 T1 写入了 x=10, 这个时候 T2 开始读取到 x=10, y=50, 这个时候 x+y=60, 打破了约束条件。&lt;/p&gt;&#xA;&lt;h3 id=&#34;p2---non-repeatable-read--fuzzy-read&#34;&gt;P2 - Non-Repeatable Read / Fuzzy Read&lt;/h3&gt;&#xA;&lt;p&gt;Non-Repeatable Read 现象描述：T1 读取某个数据项，另一个事务 T2 修改了这个数据项目并且提交了，然后 T1 再次读取这个数据项，读取到了一个已经被 T2 更新过的数据项（可能是修改也可能是被删除）&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-------+--------+--------+--------+--------+&#xA;| T1    | Rx(50) |        |        | Ry(90) |&#xA;+-------+--------+--------+--------+--------+&#xA;| T2    |        | Wx(10) | Wy(90) |        |&#xA;+-------+--------+--------+--------+--------+&#xA;| x(50) | 50     | 10     | 10     | 10     |&#xA;+-------+--------+--------+--------+--------+&#xA;| y(50) | 50     | 50     | 90     | 90     |&#xA;+-------+--------+--------+--------+--------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;上述示例中在 T1 还在运行的过程中，T2 已经完成了转账，但 T1 这时候能读到最新的值，也就是 x + y = 140 了，破坏了约束条件。&lt;/p&gt;&#xA;&lt;h3 id=&#34;p3---phantom&#34;&gt;P3 - Phantom&lt;/h3&gt;&#xA;&lt;p&gt;Phantom 现象描述： T1 读取满足一些&amp;lt;搜索条件&amp;gt;的一组数据项，事务T2然后创建满足 T1 的&amp;lt;搜索条件&amp;gt;并提交的数据项，如果T1然后使用相同的&amp;lt;搜索条件&amp;gt;重复读取，它将获得与第一次读取不同的组数据项&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+----------------+-----------+--------------+--------------+--------------+&#xA;| T1             | {a, b, c} |              |              | R(4)         |&#xA;+----------------+-----------+--------------+--------------+--------------+&#xA;| T2             |           | W(d)         | W(4)         |              |&#xA;+----------------+-----------+--------------+--------------+--------------+&#xA;| Employees      | {a, b, c} | {a, b, c, d} | {a, b, c, d} | {a, b, c, d} |&#xA;+----------------+-----------+--------------+--------------+--------------+&#xA;| Employee Count | 3         | 3            | 4            | 4            |&#xA;+----------------+-----------+--------------+--------------+--------------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设现在 T1 按照某个条件读取到了所有雇员 a，b，c，这时候 count 是 3，然后 T2 插入了一个新的雇员 d，同时更新了 count 为 4，但这时候 T1 在读取 count 的时候会得到 4，已经跟之前读取到的 a，b，c 冲突了。&lt;/p&gt;&#xA;&lt;h3 id=&#34;p4---lost-update&#34;&gt;P4 - Lost Update&lt;/h3&gt;&#xA;&lt;p&gt;Lost Update 描述的现象是事务 T1 执行了跟新操作提交后，T2 也执行了跟新操作，这个时候 T1 的更新就丢失了的现象。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+--------+-----+---------+---------+&#xA;| T1     |     |         | Wx(110) |&#xA;+--------+-----+---------+---------+&#xA;| T2     |     | Wx(120) |         |&#xA;+--------+-----+---------+---------+&#xA;| x(100) | 100 | 120     | 110     |&#xA;+--------+-----+---------+---------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在上面的例子中，我们没有任何 dirty write，因为 T2 在 T1 更新之前已经提交成功，也没有任何 dirty read，因为我们在 write 之后没有任何 read 操作，但是，当整个事务结束之后，T2 的更新其实丢失了。&lt;/p&gt;&#xA;&lt;h3 id=&#34;p4c---cursor-lost-update&#34;&gt;P4C - Cursor Lost Update&lt;/h3&gt;&#xA;&lt;p&gt;Cursor Lost Update 是上面 Lost Update 的一个变种，跟 SQL 的 cursor 相关。在下面的例子中，RC(x) 表明在 cursor 下面 read x，而 WC(x) 则表明在 cursor 下面写入 x。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+--------+----------+---------+----------+&#xA;| T1     | RCx(100) |         | Wx(110) |&#xA;+--------+----------+---------+----------+&#xA;| T2     |          | Wx(75) |          |&#xA;+--------+----------+---------+----------+&#xA;| x(100) | 100      | 75      | 110      |&#xA;+--------+----------+---------+----------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果我们允许 T2 在 T1 RC 和 WC 之间写入数据，那么 T2 的更新也会丢失。&lt;/p&gt;&#xA;&lt;h3 id=&#34;a5a---read-skew&#34;&gt;A5A - Read Skew&lt;/h3&gt;&#xA;&lt;p&gt;Read Skew 现象描述：假设事务T1读取x，然后第二个事务T2将x和y更新并提交。如果现在T1读取y，它可能会看到不一致的状态。就历史而言，我们有异常：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;A5A：r1 [x] ... w2 [x] ... w2 [y] ... c2 ... r1 [y] ...（c1 or a1）（读偏）&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;结合具体示例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-------+--------+--------+--------+--------+&#xA;| T1    | Rx(50) |        |        | Ry(75) |&#xA;+-------+--------+--------+--------+--------+&#xA;| T2    |        | Wx(25) | Wy(75) |        |&#xA;+-------+--------+--------+--------+--------+&#xA;| x(50) | 50     | 25     | 25     | 25     |&#xA;+-------+--------+--------+--------+--------+&#xA;| y(50) | 50     | 50     | 75     | 75     |&#xA;+-------+--------+--------+--------+--------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;示例中还是传统的转账例子，需要保证 x + y = 100，那么 T1 就会看到不一致的数据了。&lt;/p&gt;&#xA;&lt;h3 id=&#34;a5b---write-skew&#34;&gt;A5B - Write Skew&lt;/h3&gt;&#xA;&lt;p&gt;Write Skew 现象描述：假设T1读取与C（）一致的x和y，然后T2读取x和y，写入x和提交。然后T1写y。如果x和y之间存在约束，则可能会被违反。在历史方面：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;A5B：r1 [x] ... r2 [y] ... w1 [y] ... w2 [x] ...（c1 and c2 occur）（写偏）&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;结合具体示例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-------+--------+--------+--------+--------+&#xA;| T1    | Rx(30) | Ry(10) | Wy(60) |        |&#xA;+-------+--------+--------+--------+--------+&#xA;| T2    | Rx(30) | Ry(10) |        | Wx(50) |&#xA;+-------+--------+--------+--------+--------+&#xA;| x(30) | 30     | 30     | 30     | 50     |&#xA;+-------+--------+--------+--------+--------+&#xA;| y(10) | 10     | 10     | 60     | 60     |&#xA;+-------+--------+--------+--------+--------+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;上述示例中，假设 x + y &amp;lt;= 100，T1 和 T2 在执行的时候都发现满足约束，然后 T1 更新了 y，而 T2 更新了 x，然后最终结果打破了约束。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-1&#34;&gt;隔离级别&lt;/h3&gt;&#xA;&lt;p&gt;上面以及描述了不同的异常情况，通常我们根据这些异常情况定义了一些隔离级别：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/isolation.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;NP - Not Possible，在该隔离级别下面不可能发生&lt;br&gt;&#xA;SP - Sometimes Possible，在该隔离级别下面有时候可能发生  &lt;br&gt;&#xA;P - Possible，在该隔离级别下面会发生&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;另外需要注意，上面提到的 isolation level 都不保证实时约束，如果一个进程 A 完成了一次写入 w，然后另外的进程 B 开始了一次读取 r，r 并不能保证观察到 w 的结果。另外，在不同事务之间，这些 isolation level 也不保证不同进程的顺序。一个进程可能在一次事务里面看到一次写入 w，但可能在后面的事务上面没看到同样的 w。事实上，一个进程甚至可能看不到在这个进程上面之前的写入，如果这些写入都是发生在不同的事务里面。有时候，他们还可能会对事务进行排序，譬如将 write-only 的事务放到所有的 read 事务的后面。&lt;/p&gt;&#xA;&lt;p&gt;要解决这些问题，我们就需要结合前几个章节中定义的一致性约束来共同来确保我们分布式数据库能够真正的达到我们想要的效果。&lt;/p&gt;&#xA;&lt;h2 id=&#34;linearizability-vs-serializability&#34;&gt;Linearizability vs Serializability&lt;/h2&gt;&#xA;&lt;p&gt;Linearizability 和 Serializability 很多时候会发生混淆，这两个词都是表达表达 &amp;quot;可以按照顺序排序&amp;quot; 的意思，但是他们完全不同，需要仔细区分：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Linearizability： 可线性化是读写寄存器（单个对象）的最新值的保证。它并不要去做作组合到事务中，因此无比避免写倾斜等问题。&lt;/li&gt;&#xA;&lt;li&gt;Serializability: 可串行化是事务的隔离属性，其中每隔事务可以读写多个对象（行，文档，记录等）。它用来确保事务的执行结果和串行执行（每次执行一个事务）的结果完全相同，即使串行执行的顺序可能和事务的实际执行顺序不同。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;数据库可以同时支持可串行化和可线性化，这种组合又被称作严格的可串行化(Strict Serializability, strong-1SR), 就是最开始 Jepsen 图中根节点。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-2&#34;&gt;如何验证线性一致性&lt;/h2&gt;&#xA;&lt;p&gt;上面讲了那么多，接下来在梳理一下，目前大多数情况下我们是如何来验证线性一致性 (Linearizability)。&lt;/p&gt;&#xA;&lt;p&gt;通常为了判断是否正确提供了一致性，首先在运行过程中获得一系列不同的执行历史，接着验证每组历史是否满足线性一致性，只要有一个不满足，便可以说系统不满足线性一致性。但如果没有发现不满足的历史，也不证明系统一定是一致性的。这里验证系统是否满足一致性就转变成如何判断一组执行历史是否满足线性一致性，在上面介绍线性一致性的是以后我们也聊到验证一致性算法的关键，是从这个执行历史中找一条合理的线性执行序列，如何能够找到这样的序列，就可以判断这个历史符合线性一致性，反正，就可以判断这段历史不符合线性一致性。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-3&#34;&gt;问题复杂度&lt;/h3&gt;&#xA;&lt;p&gt;我们要在这段历史中寻找符合线性一致性的序列，直观来看，这个问题变成了一个排序问题，极端的情况下时间复杂度是 O(N!)。事实上，Phillip B. Gibbons 和 Ephraim Korach 在 &lt;a href=&#34;http://www.cs.ox.ac.uk/people/gavin.lowe/LinearizabiltyTesting/paper.pdf&#34;&gt;Testing Shared Memories&lt;/a&gt; 中已经证明其是一个 &lt;strong&gt;NP-Complete&lt;/strong&gt; 问题。虽然 Gavin Lowe 在 Testing for Linearizability 中给出了一些特殊限制下的多项式甚至是线性复杂度的算法，但在通用场景下，判定线性一致性并不是一个容易解决的问题，&lt;strong&gt;其搜索空间会随着执行历史的规模急速膨胀&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-4&#34;&gt;具体实践&lt;/h3&gt;&#xA;&lt;p&gt;即使线性一致性验证是 NP 完全的，在实际中，它仍然能在一些小的历史上面很好的工作。线性一致性验证器的实现会用一个可执行的规范，加上一个历史，执行一个搜索过程去构造一个线性化，并使用一些技巧来限制减少搜索的空间。&lt;/p&gt;&#xA;&lt;h4 id=&#34;knossos&#34;&gt;Knossos&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jepsen-io/knossos&#34;&gt;Knossos&lt;/a&gt; 是 Jepsen 中使用的一致性验证工具，是基于 &lt;a href=&#34;http://www.cs.cmu.edu/~wing/publications/WingGong93.pdf&#34;&gt;WGL&lt;/a&gt; 算法实现的,这个算法主要是在 WG&lt;br&gt;&#xA;算法的基础的一个改进，改进的方式主要是&lt;strong&gt;对搜索树的剪枝：通过缓存已经见过的配置，来减少重复搜索&lt;/strong&gt;，具体关于 Knossos 可以参考 &lt;a href=&#34;https://pingcap.com/blog-cn/linearizability/#linearizability-%E4%B8%80%E8%87%B4%E6%80%A7%E9%AA%8C%E8%AF%81&#34;&gt;Linearizability 一致性验证&lt;/a&gt; 博客。&lt;/p&gt;&#xA;&lt;h4 id=&#34;porcupine&#34;&gt;Porcupine&lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/anishathalye/porcupine&#34;&gt;Porcupine&lt;/a&gt;&lt;br&gt;&#xA;一个用 Go 写的更快的线性一致性验证工具。是基于 &lt;a href=&#34;http://www.kroening.com/papers/forte2015-li.pdf&#34;&gt;P-compositionality&lt;/a&gt; 算法，P-compositionality 算法利用了线性一致性的 Locality 原理，即&lt;strong&gt;如果一个调用历史的所有子历史都满足线性一致性，那么这个历史本身也满足线性一致性&lt;/strong&gt;。因此，可以将一些不相关的历史划分开来，形成多个规模更小的子历史，转而验证这些子历史的线性一致性，例如kv数据结构中对不同key的操作。上面提到了算法的计算时间随着历史规模的增加急速膨胀，P-compositionality 相当于用&lt;strong&gt;分治&lt;/strong&gt;的办法来降低历史规模，这种方法在可以划分子问题的场景下会非常有用。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;这些算法的实现还未深入去研究，后面需要在抽出时间一一的去尝试一下这些算法的实现，可能对理解一致性会更有帮助。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;heading-5&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/3673e612cce2&#34;&gt;一致性模型&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://kaiyuan.me/2018/04/21/consistency-concept/&#34;&gt;分布式系统一致性&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://duanple.blog.163.com/blog/static/7097176720185963122866/&#34;&gt;线性一致性理论  &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.lagou.com/lgeduarticle/30180.html&#34;&gt;当数据库遇到分布式&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://catkang.github.io/2018/07/30/test-linearizability.html&#34;&gt;如何验证线性一致性&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-cn/linearizability-and-raft/#%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E5%92%8C-raft&#34;&gt;线性一致性和 Raft&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://jepsen.io/consistency&#34;&gt;Consistency Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.bailis.org/blog/linearizability-versus-serializability/&#34;&gt;Linearizability versus Serializability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://courses.csail.mit.edu/6.852/01/papers/p91-attiya.pdf&#34;&gt;Sequential Consistency versus Linearizability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf&#34;&gt;Linearizability: A Correctness Condition for&lt;br&gt;&#xA;Concurrent Objects &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf&#34;&gt;A Critique of ANSI SQL Isolation Levels&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>在容器中让时间自由摇摆</title>
    <updated>2020-03-12T00:00:00Z</updated>
    <id>tag:int64.me,2020-03-12:/2020/在容器中让时间自由摇摆.html</id>
    <link href="http://int64.me/2020/在容器中让时间自由摇摆.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;a href=&#34;https://github.com/pingcap/chaos-mesh&#34;&gt;Chaos Mesh&lt;/a&gt; 是最近开源的 Kubernetes 混沌测试平台，并且最近支持了 TimeChaos 的新功能，用来模拟 Time skew 的情况，通常情况下，我们知道直接修在容器中修改时间，会影响整个物理节点, 这不是我们想要的，那么 Chaos Mesh 是如何解决这个问题的呢？接下来就让我们一起探索一下 Chaos Mesh 是如何在容器中让时间自由摇摆的！&lt;/p&gt;&#xA;&lt;h2 id=&#34;time-skew-&#34;&gt;Time skew 是什么?&lt;/h2&gt;&#xA;&lt;p&gt;Time Skew 直接翻译就是时间偏移，白话一点就是我们从节点上获取的时间和当前真实的时间出现偏差。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-time-skew-&#34;&gt;为什么需要模拟 Time skew 呢？&lt;/h2&gt;&#xA;&lt;p&gt;分布式数据库要实现全局一致性快照，需要解决不同节点之间时钟一致的问题。工业界目前有三种解决方案：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;全局集中式授时服务&lt;/li&gt;&#xA;&lt;li&gt;混合逻辑时钟（HLC）&lt;/li&gt;&#xA;&lt;li&gt;原子钟 Truetime。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这里不具体解释具体的实现原理和优缺点，简单来说都是为了保证时钟的一致性，但是往往物理节点上的物理时间总是会出现偏差，不管是使用 NPT 服务同步也好，或者其他方法总是没办法完全避免出现误差，这时候如果我们的应用不能够很好的处理这样的情况的话，就可能造成无法预知的错误。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;物理节点上可以肿么做？&lt;/h2&gt;&#xA;&lt;p&gt;在物理节点可以直接使用 &lt;code&gt;date -s&lt;/code&gt; 命令修改时间, 但需要注意的是此修改会影响整个节点上的时间，也就是其他进程也会受到影响。&lt;/p&gt;&#xA;&lt;p&gt;示例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# 将系统日期设定成2009年 9月3日的命令&#xA;date -s 9/03/2009&#xA;&#xA;# 将系统时间设定成下午5点55分55秒的命令&#xA;date -s 17:55:55&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;jepsen-&#34;&gt;Jepsen 是肿么做的？&lt;/h2&gt;&#xA;&lt;p&gt;Jepsen 是目前比较流行的验证分布式一致性验证框架，采用函数式编程语言 Clojure 编写（不得不说之前搞 Jepsen 的时候，差点被 clojure 搞疯）。Jepsen 也提供了 time skew 功能，在 Jepsen 里是直接使用了一段 C 代码来搞定的:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;....&#xA;    /* Set time */&#xA;    if (0 != settimeofday(&amp;amp;time, &amp;amp;tz)) {&#xA;      perror(&amp;quot;settimeofday&amp;quot;);&#xA;      return 2;&#xA;    }&#xA;....&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;详细实现：https://github.com/jepsen-io/jepsen/blob/master/jepsen/resources/bump-time.c&lt;/p&gt;&#xA;&lt;p&gt;简单解释一下就是使用了 &lt;code&gt;settimeofday&lt;/code&gt; 时间函数来设置系统时间。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-docker-&#34;&gt;探索 Docker 中的实现方式&lt;/h2&gt;&#xA;&lt;p&gt;由于 Jepsen 实现中直接是调用了 &lt;code&gt;settimeofday&lt;/code&gt; 操作设置时间，这样的操作会导致整个物理节点上的时间都发生改变，但是 Chaos Mesh 是运行在 Kubernetes 上的，如果我们给某个进程注入 time skew 导致整个物理节点都出现了时间问题，那么会影响整个 node 上其他的容器，这是我们无法容忍。所以直接通过 &lt;code&gt;data&lt;/code&gt; 命令或者是直接使用 &lt;code&gt;sttimeofday&lt;/code&gt; 之类的时间函数是行不通的，那么挑战来了，在该肿么去达到我们想要的效果呢？&lt;/p&gt;&#xA;&lt;p&gt;首先我们想到使用 BPF 通过内核的方向寻找突破口，幸好我们 Team 有一位 Kernel 方面的专家，这一光荣挑战性的任务就落在了他的头上，接下来分析几个我们探索的思路&lt;/p&gt;&#xA;&lt;h3 id=&#34;-ld-preload&#34;&gt;使用 LD_PRELOAD&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;LD_PRELOAD&lt;/code&gt; 是 Linux 系统的一个环境变量，它可以影响程序的运行时的链接（Runtime linker），它允许你定义在程序运行前优先加载的动态链接库。这个功能主要就是用来有选择性的载入不同动态链接库中的相同函数。通过这个环境变量，我们可以在主程序和其动态链接库的中间加载别的动态链接库，甚至覆盖正常的函数库。一方面，我们可以以此功能来使用自己的或是更好的函数（无需别人的源码），而另一方面，我们也可以以向别人的程序注入程序，从而达到特定的目的。&lt;/p&gt;&#xA;&lt;p&gt;对于使用应用程序调用时间函数是使用 glibc 的方式话， &lt;code&gt;LD_PRELOAD&lt;/code&gt; 是可以生效的，比如 Rust, C ， 但是对于有些程序比如 Golng，Golang 会直接解析 &lt;a href=&#34;http://man7.org/linux/man-pages/man7/vdso.7.html&#34;&gt;vDSO&lt;/a&gt; 段获取时间函数地址跳转过去，因此无法使用 &lt;code&gt;LD_PRELOAD&lt;/code&gt; 的方式拦截 glibc 接口.&lt;/p&gt;&#xA;&lt;p&gt;下面简单解释一下 VDSO&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;VDSO (virtual dynamic share object) 是一种加速方法，内核开发人员发现有个别系统调用只会产生读 kernel 内存操作，而从来不写，但出于安全性用户地址空间和内核地址空间是分离的。每次读都会发生特权级切换，开销很大。因为只读，所以内核开发人员决定干脆将这些地址放在一个区域，虽然从地址空间范围来看属于内核地址空间，但把它算成是用户态地址空间，地址里面的值的更新由内核态来负责，用户态的程序去读区这段内存和访问用户态程序一样 （gdb 可以直接 step 进去），这样就大幅度的提高了性能。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;由于 &lt;code&gt;LD_PRELOAD&lt;/code&gt; 的局限性，所以这个思路看起来行不通&lt;/p&gt;&#xA;&lt;h3 id=&#34;-bpf--clock-gettime-&#34;&gt;使用 BPF 修改系统调用 clock_gettime 返回值&lt;/h3&gt;&#xA;&lt;p&gt;我们可以使用 BPF 对任务的 PID 进行过滤这样我们就可以通过只对具体的某个进程进行 time skew, 并且通过修改系统调用 clock_gettime 的返回值实现我们的目的。这个思路看似很好，但是问题来了，clock_gettime 绝大数情况下是通过 VDSO 加速，并不会进行真正的系统调用，呱唧一下，走不通了，最后查到，如果我们的系统内核版本 4.18 及以上的话，并且使用 &lt;a href=&#34;https://www.kernel.org/doc/html/latest/timers/hpet.html&#34;&gt;HPET&lt;/a&gt; 时钟，clock_gettime 系统调用在 VDSO 中是不生效的，并且会正常走系统调用。&lt;/p&gt;&#xA;&lt;p&gt;并且我们使用上述方案实现了一版 &lt;a href=&#34;https://github.com/chaos-mesh/bpfki&#34;&gt;time skew&lt;/a&gt;, 并且经过测试对于 Rust, C 这样的程序是可以正常工作的，但是对于 Golang 这样的程序来说获取时间是正常的，但是出现一个问题就是如果程序在被注入 time skew 的期间，执行 sleep 操作的话，sleep 操作存在很大可能会被 block 住（time skew 取消后依然无法恢复），经过排查怀疑是因为 bpf 会在系统调用返回前修改用户态地址空间 （存储 timeval 或 timspec 的地方），而 golang 的 runtime 为了防止阻塞，会把这个调用系统调用的 G 丢出去，新的 G 和 P 绑定，那么那块地址空间可能会被新绑定的 G 访问 ，导致了 panic 或 hang。（具体问题的原因还没完全确定）&lt;/p&gt;&#xA;&lt;p&gt;好了上面简单描述了两种我们在探索中想到的两种方案，都存在些局限性和问题，那么最后在 Chaos Mesh 中是真正如何去实现的呢？&lt;/p&gt;&#xA;&lt;p&gt;不得说现在的实习生太强了，最终我们使用的方式是我们 Team 一实习生提出来并实现的，吹爆他，特别 hack 的方案，下面就一探究竟...&lt;/p&gt;&#xA;&lt;h2 id=&#34;chaos-meshhttpsgithubcompingcapchaos-mesh-&#34;&gt;&lt;a href=&#34;https://github.com/pingcap/chaos-mesh&#34;&gt;Chaos Mesh&lt;/a&gt; 中落地&lt;/h2&gt;&#xA;&lt;p&gt;从上面探索方案中可以知道，正常程序获取系统是时间绝大多数情况下是通过 clock_gettime 实现的，只是我们的 clock_gettime 刚好是使用 vDSO 加速，导致我们没办法好直接使用 LD_PRELOAD 方式去 hack clock_gettime 的系统调用，那么我们就从 VDSO 着手解决这个问题，如果我们可以把 VDSO 中记录 clock_gettime 结果的地址指向一个我们自己定一个的实现就好了，理想是美好的，但现实总是残酷，要达到这个效果，我们需要解决如下几个问题：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;需要知道 VDSO 段的用户态地址&lt;/li&gt;&#xA;&lt;li&gt;如果要通过内核态的任意地址更改 vDSO 段中 clock_gettime 函数的内容，需要知道 VDSO 段的内核态地址&lt;/li&gt;&#xA;&lt;li&gt;如何去修改 VDSO 段中的数据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;首先我们先看看 VDSO 是个什么样子的, 我们可以通过查看的 &lt;code&gt;/proc/pid/maps&lt;/code&gt; 中查看到 VDSO 的内存地址：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ cat /proc/pid/maps &#xA;...&#xA;7fa931533000-7fabb1533000 r--s 00000000 08:03 13631798                   /var/lib/etcd/member/snap/db&#xA;7fabb1533000-7fabb1cf3000 rw-p 00000000 00:00 0&#xA;7fae3192b000-7fae31f33000 rw-p 00000000 00:00 0&#xA;7ffe530fc000-7ffe5311d000 rw-p 00000000 00:00 0                          [stack]&#xA;7ffe53143000-7ffe53145000 r-xp 00000000 00:00 0                          [vdso]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后一行就是 VDSO 的相关信息，可以看到这段内存空间的权限是 &lt;code&gt;r-xp&lt;/code&gt; ，可读可执行但是不可写，也就是我们在用户态没办法去修改这段内存，为了实现可以去修改 VDSO, 我们选择使用 &lt;a href=&#34;http://man7.org/linux/man-pages/man2/ptrace.2.html&#34;&gt;ptrace&lt;/a&gt; 搞事情。&lt;/p&gt;&#xA;&lt;p&gt;接下来我们看看这个 VDSO 里面具体有些什么，我们可以使用 gdb dump memory 直接把 VDSO 导出来，并且可以使用 &lt;code&gt;objdump&lt;/code&gt; 查看一下具体内容：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) dump memory vdso.so 0x00007ffe53143000 0x00007ffe53145000 &#xA;&#xA;&#xA;$ objdump -T vdso.so&#xA;&#xA;vdso.so:     file format elf64-x86-64&#xA;&#xA;DYNAMIC SYMBOL TABLE:&#xA;ffffffffff700600  w   DF .text&#x9;0000000000000545  LINUX_2.6   clock_gettime&#xA;0000000000000000 g    DO *ABS*&#x9;0000000000000000  LINUX_2.6   LINUX_2.6&#xA;ffffffffff700b50 g    DF .text&#x9;00000000000002b4  LINUX_2.6   __vdso_gettimeofday&#xA;ffffffffff700e30 g    DF .text&#x9;000000000000003d  LINUX_2.6   __vdso_getcpu&#xA;ffffffffff700b50  w   DF .text&#x9;00000000000002b4  LINUX_2.6   gettimeofday&#xA;ffffffffff700e10  w   DF .text&#x9;0000000000000016  LINUX_2.6   time&#xA;ffffffffff700e30  w   DF .text&#x9;000000000000003d  LINUX_2.6   getcpu&#xA;ffffffffff700600 g    DF .text&#x9;0000000000000545  LINUX_2.6   __vdso_clock_gettime&#xA;ffffffffff700e10 g    DF .text&#x9;0000000000000016  LINUX_2.6   __vdso_time&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其实整个 VDSO 可以看作是一个 &lt;code&gt;.so&lt;/code&gt; 的文件，这样我们就可以直接使用 &lt;code&gt;ELF&lt;/code&gt; 文件处理方式，来格式化 VDSO。说到这里我们实现 time skew 的基本思路已经有了：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/timechaos.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上述流程图即为 Chaos Mesh 中 TimeChaos 的实现基本流程&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;第一步我们会先使用 ptrace attach 指定的 pid 进程，让当前进程处于 stop 状态&lt;/li&gt;&#xA;&lt;li&gt;接着使用 ptrace 在进程内存中映射出一段内存空间将我们自己的 &lt;code&gt;fake_clock_gettime&lt;/code&gt; 使用 &lt;code&gt;process_vm_writev&lt;/code&gt; 写到内存空间中&lt;/li&gt;&#xA;&lt;li&gt;将指定的参数通过 &lt;code&gt;process_vm_writev&lt;/code&gt; 写到 &lt;code&gt;fake_clock_gettime&lt;/code&gt; 中，这里的参数是指我们真正想要注入的时间，比如往前 2h, 往后 2d 之类的参数&lt;/li&gt;&#xA;&lt;li&gt;接着使用 ptrace 修改 VDSO 中 &lt;code&gt;clock_gettime&lt;/code&gt; 函数部分，直接跳转到 &lt;code&gt;fake_clock_gettime&lt;/code&gt; 函数上。&lt;/li&gt;&#xA;&lt;li&gt;最后 ptrace detch&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;具体实现可以参考：https://github.com/pingcap/chaos-mesh/blob/master/pkg/time/time_linux.go&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-1&#34;&gt;看一下效果&lt;/h2&gt;&#xA;&lt;p&gt;这里我直接拿 TiDB 作为小白鼠，在 TiDB 中采用集中式的服务 TSO 来获取全局一直的版本号，并保证事务的版本号单调递增的。&lt;br&gt;&#xA;并且 TSO 服务是由 PD 负责的，这里我会随机选择一 PD 节点，定期注入 TimeChaos, 将时间往前调整 10m, 来检验一下 TiDB 是否还能正常工作😏。&lt;br&gt;&#xA;为了更好观察实验效果，实验中使用 &lt;a href=&#34;https://github.com/cwen0/bank&#34;&gt;bank&lt;/a&gt; 作为 TiDB 的 Workload, bank 程序模拟银行转账, 常用来验证事务的正确性。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pingcap/chaos-mesh/wiki&#34;&gt;Chaos Mesh&lt;/a&gt; 和 &lt;a href=&#34;https://pingcap.com/docs/stable/tidb-in-kubernetes/tidb-operator-overview/&#34;&gt;TiDB&lt;/a&gt; 的安装流程可以参考具体文档，这里不在多加赘述。&lt;/p&gt;&#xA;&lt;p&gt;先看一下具体实验配置：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: pingcap.com/v1alpha1&#xA;kind: TimeChaos&#xA;metadata:&#xA;  name: time-skew-example&#xA;  namespace: tidb-demo&#xA;spec:&#xA;  mode: one&#xA;  selector:&#xA;    labelSelectors:&#xA;      &amp;quot;app.kubernetes.io/component&amp;quot;: &amp;quot;pd&amp;quot;&#xA;  timeOffset:&#xA;    sec: -600&#xA;  clockIds:&#xA;    - CLOCK_REALTIME&#xA;  duration: &amp;quot;10s&amp;quot;&#xA;  scheduler:&#xA;    cron: &amp;quot;@every 1m&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;执行上述实验，Chaos Mesh 会每隔 1m 选中一个 PD pod 注入 TimeChaos 并持续 10s, 在这 10s 内，&lt;br&gt;&#xA;PD 获取的时间会和真实的时间相差 600s。具体实验定义可以参考 Chaos Mesh &lt;a href=&#34;https://github.com/pingcap/chaos-mesh/wiki/Time-Chaos&#34;&gt;Wiki&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;我们可以通过 &lt;code&gt;kubectl apply&lt;/code&gt; 命令创建 TimeChaos 实验：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl apply -f pd-time.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;成功创建实验后，就到了检验结果的时候了，我们可以通过下列命令去检索 PD 的日志:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl logs -n tidb-demo tidb-app-pd-0 | grep &amp;quot;system time jump backward&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;得到如下输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[2020/03/24 09:06:23.164 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585041383060109693]&#xA;[2020/03/24 09:16:32.260 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585041992160476622]&#xA;[2020/03/24 09:20:32.059 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585042231960027622]&#xA;[2020/03/24 09:23:32.059 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585042411960079655]&#xA;[2020/03/24 09:25:32.059 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585042531963640321]&#xA;[2020/03/24 09:28:32.060 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585042711960148191]&#xA;[2020/03/24 09:33:32.063 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043011960517655]&#xA;[2020/03/24 09:34:32.060 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043071959942937]&#xA;[2020/03/24 09:35:32.059 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043131978582964]&#xA;[2020/03/24 09:36:32.059 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043191960687755]&#xA;[2020/03/24 09:38:32.060 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043311959970737]&#xA;[2020/03/24 09:41:32.060 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043491959970502]&#xA;[2020/03/24 09:45:32.061 +00:00] [ERROR] [systime_mon.go:32] [&amp;quot;system time jump backward&amp;quot;] [last=1585043731961304629]&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;从日志中可以看出，每隔一段时间，PD 就会检测出系统时间会退的信息，由此可以说明两个问题：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;TimeChaos 生效了&lt;/li&gt;&#xA;&lt;li&gt;PD 实现中考虑到 Time skew 的情况&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;最后通过 Chaos-Dashboard 再次确认一下 TimeChaos 对 TiDB 的影响:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../images/time-skew.png&#34; alt=&#34;pd TimeChaos&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;从监控中可以看到，每隔 1m 会注入一次 TimeChaos 并持续 10s，&lt;br&gt;&#xA;并且注入的 TimeChaos 对 TiDB 几乎无影响，bank 程序正常运行，并且性能也基本没有变化。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-2&#34;&gt;最后&lt;/h2&gt;&#xA;&lt;p&gt;最后说点啥呢？欢迎大家入坑 &lt;a href=&#34;https://github.com/pingcap/chaos-mesh&#34;&gt;Chaos Mesh&lt;/a&gt;&lt;/p&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>TC - Linux 流量控制工具</title>
    <updated>2018-05-23T00:00:00Z</updated>
    <id>tag:int64.me,2018-05-23:/2018/TC - Linux 流量控制工具.html</id>
    <link href="http://int64.me/2018/TC - Linux 流量控制工具.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;最近一个新任务，需要模拟限制主机带宽的场景，之前只是知道使用 &lt;code&gt;tc&lt;/code&gt; 是可以做到模拟网络延迟、网络丢包等情况，所有就想应该 &lt;code&gt;tc&lt;/code&gt; 也可以搞定限制带宽的情况，就在网上搜了一波，果不其然 &lt;code&gt;tc&lt;/code&gt; 还是强大，可是对于用来限制带宽，操作起来还是很蛋疼，踩了不少坑..&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;简单说一下原理&lt;/h2&gt;&#xA;&lt;p&gt;本来打算直接列一波用法，但是总觉得，不记录一下原理，操作起来也是一脸懵逼。&lt;br&gt;&#xA;TC 通过建立处理数据包队列，并定义队列中数据包被发送的方式，从而实现进行流量控制。TC 模拟实现流量控制功能使用的队列分为两类：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;无类队列（clssless）: 使用 classless 队列，TC 对进入网卡的流量不加任何区分，统一对待, 常用的无类队列有 &lt;strong&gt;pfifo _fast (先进现出) 、TBF ( 令牌桶过滤器) 、SFQ(随机公平队列) 、ID (前 向随机丢包)&lt;/strong&gt; 等等。这类队列规定使用的流量整形手段主要 是排序、限速和丢包。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;fifo, 使用最简单的 qdisc（排队规则），纯粹的先进先出。只有一个参数：limit ，用来设置队列的长度，pfifo 是以数据包的个数为单位；bfifo 是以字节数为单位。&lt;/li&gt;&#xA;&lt;li&gt;pfifo_fast，在编译内核时，如果打开了高级路由器（Advanced Router）编译选项，pfifo_fast 就是系统的标准 qdisc(排队规则)。它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。而三个波段（band）的优先级也不相同，band 0 的优先级最高，band 2 的最低。如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包，band 1 和 band 2 之间也是一样的。数据包是按照服务类型（Type Of Service，TOS ）被分配到三个波段（band）里面的。&lt;/li&gt;&#xA;&lt;li&gt;red，red 是 Random Early Detection（随机早期探测）的简写。如果使用这种 qdsic，当带宽的占用接近与规定的带宽时，系统会随机的丢弃一些数据包。他非常适合高带宽的应用。&lt;/li&gt;&#xA;&lt;li&gt;sfq，sfq 是 Stochastic Fairness Queueing 的简写。它会按照会话（session -- 对应与每个 TCP 连接或者 UDP 流）为流量进行排序，然后循环发送每个会话的数据包。&lt;/li&gt;&#xA;&lt;li&gt;tbf，tbf 是 Token Bucket Filter 的简写，适用于把流速降低到某个值。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;分类队列（classful）：当使用 classful 队列时，TC 对进行的网络设备的数据包根据不同的需求进行分类处理。TC 使用过滤器进行分类，TC 根据过滤器定义的规则匹配相应的数据包，发送到对应的分类队列，同时我们可以对子类在次使用过滤器进行分类。理论上这可以是一个无限深度的树。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CBQ，CBQ 是 Class Based Queueing（基于类别排队）的缩写。它实现了一个丰富的连接共享类别结构，既有限制（shaping）带宽的能力，也具有带宽优先级别管理的能力。带宽限制是通过计算连接的空闲时间完成的。空闲时间的计算标准是数据包离队事件的频率和下层连接（数据链路层）的带宽。&lt;/li&gt;&#xA;&lt;li&gt;HTB，HTB 是 Hierarchy Token Bucket 的缩写。通过在实践基础上的改进，它实现一个丰富的连接共享类别体系。使用 HTB 可以很容易地保证每个类别的带宽，虽然它也允许特定的类可以突破带宽上限，占用别的类的带宽。HTB 可以通过 TBF（Token Bucket Filter）实现带宽限制，也能够划分类别的优先级。&lt;/li&gt;&#xA;&lt;li&gt;PRIO，PRIO qdisc 不能限制带宽，因为属于不同类别的数据包是顺序离队的。使用 PRIO qdisc 可以很容易对流量进行优先级管理，只有属于高优先级类别的数据包全部发送完毕，参会发送属于低优先级类别的数据包。为了方便管理，需要使用 iptables 或者 ipchains 处理数据包的服务类型（Type Of Service，TOS）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;classful 队列规定（qdisc）, 类（class）和过滤器（filter）这 3 个组件组成，绘图中一般用圆形表示队列规定，用矩形表示类，图 copy 自 &lt;a href=&#34;http://blog.51cto.com/professor/1570778&#34;&gt;Linux 下 TC 以及 netem 队列的使用&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/wKiom1RU0lKAEIb9AAFPHLlaSng303.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;看一张图说明一下基本原理（直接 copy 自 &lt;a href=&#34;http://www.ituring.com.cn/article/274014&#34;&gt;流量控制工具 TC 详细说明&lt;/a&gt;：&lt;br&gt;&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/image_1b6at6vf47qubm51vq69qvaod1g.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;接收包从输入接口（Input Interface）进来后，经过流量限制（Ingress Policing）丢弃不符合规定的数据包，由输入多路分配器（Input De-Multiplexing）进行判断选择......&lt;/li&gt;&#xA;&lt;li&gt;如果接收包的目的是本主机，那么将该包送给上层处理；否则需要进行转发，将接收包交到转发块（Forwarding Block）处理。转发块同时也接收本主机上层（TCP、UDP 等）产生的包。转发块通过查看路由表，决定所处理包的下一跳。然后，对包进行排列以便将它们传送到输出接口（Output Interface）。&lt;/li&gt;&#xA;&lt;li&gt;一般我们只能限制网卡发送的数据包，不能限制网卡接收的数据包，所以我们可以通过改变发送次序来控制传输速率。（控制网卡入口流量，需要把数据包重定向到虚拟设备 ifb， 在 ifb 的输出方向可以配置，后面会详细说这个）&lt;/li&gt;&#xA;&lt;li&gt;Linux 流量控制主要是在输出接口排列时进行处理和实现的。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;tc-&#34;&gt;TC 基础&lt;/h2&gt;&#xA;&lt;h3 id=&#34;heading-1&#34;&gt;结构&lt;/h3&gt;&#xA;&lt;p&gt;都是以一个根 qdisc 开始的，若根 qdisc 是不分类的队列规定，那它就没有子类，因此不可能包含其他的子对象，也不会有过滤器与之关联，发送数据时，数据包进入这个队列里面排队，然后根据该队列规定的处理方式将数据包发送出去。&lt;/p&gt;&#xA;&lt;p&gt;分类的 qdisc 内部包含一个或多个类，而每个类可以包含一个队列规定或者包含若干个子类，这些子类友可以包含分类或者不分类的队列规定，如此递归，形成了一个树。&lt;/p&gt;&#xA;&lt;p&gt;句柄号：qdisc 和类都使用一个句柄进行标识，且在一棵树中必须是唯一的，每个句柄由主号码和次号码组成 qdisc 的次号码必须为 0（0 通常可以省略不写）&lt;/p&gt;&#xA;&lt;p&gt;根 qdisc 的句柄为 1：，也就是 1：0。类的句柄的主号码与它的父辈相同（父类或者父 qdisc），如类 1：1 的主号码与包含他的队列规定 1：的主号码相同，1：10 和 1：11 与他们的父类 1：1 的主号码相同，也为 1。&lt;/p&gt;&#xA;&lt;p&gt;新建一个类时，默认带有一个 pfifo_fast 类型的不分类队列规定，当添加一个子类时，这个类型的 qdisc 就会被删除，所以，非叶子类是没有队列规定的，数据包最后只能到叶子类的队列规定里面排队。&lt;/p&gt;&#xA;&lt;p&gt;若一个类有子类，那么允许这些子类竞争父类的带宽，但是，以队列规定为父辈的类之间是不允许相互竞争带宽的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-2&#34;&gt;基本命令&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;add 命令：在一个节点里加入一个 qdisc，类或者过滤器。添加时，需要传递一个祖先作为参数，传递参数时既可以使用 ID 也可以直接传递设备的根，若建一个 qdisc 或者 filter，可以使用句柄来命名，若建一个类，使用类识别符来命名。&lt;/li&gt;&#xA;&lt;li&gt;del：删除由某个句柄指定的 qdisc，根 qdisc 也可以被删除，被删除的 qdisc 上的所有子类以及附属于各个类的过滤器都会被自动删除。&lt;/li&gt;&#xA;&lt;li&gt;change：以替代方式修改某些项目，句柄和祖先不能修改，change 和 add 语法相同。&lt;/li&gt;&#xA;&lt;li&gt;replace：对一个现有节点进行近于原子操作的删除 / 添加，如果节点不存在，这个命令就会建立节点。&lt;/li&gt;&#xA;&lt;li&gt;link：只适用于 qdisc，替代一个现有的节点&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;-egress&#34;&gt;控制出口流量 (egress)&lt;/h2&gt;&#xA;&lt;p&gt;默认 TC 的 qdisc 控制就是出口流量，要使用 TC 控制入口，需要把流量重定向到 ifb 网卡，其实就是加了一层，原理上还是控制出口😂 。&lt;/p&gt;&#xA;&lt;h3 id=&#34;-classless-&#34;&gt;先说 classless 队列&lt;/h3&gt;&#xA;&lt;p&gt;为何要先说 classless 队列，毕竟这个简单嘛，要快速使用，那么这个就是首选了。基于 classless 队列，我们可以进行故障模拟，也可以用来限制带宽。&lt;/p&gt;&#xA;&lt;p&gt;TC 使用 linux network &lt;a href=&#34;https://wiki.linuxfoundation.org/networking/netem&#34;&gt;netem&lt;/a&gt; 模块进行网络故障模拟&lt;/p&gt;&#xA;&lt;h4 id=&#34;heading-3&#34;&gt;模拟网络延迟&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;添加一个固定延迟到本地网卡 eth0&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;// delay: 100ms&#xA;tc qdisc add dev eth0 root netem delay 100ms&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;给延迟加上上下 10ms 的波动&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem delay 100ms 10ms&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;加一个 25% 的相关概率&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;相关性，是这当前的延迟会和上一次数据包的延迟有关，短时间里相邻报文的延迟应该是近似的而不是完全随机的。这个值是个百分比，如果为 100%，就退化到固定延迟的情况；如果是 0% 则退化到随机延迟的情况，&lt;br&gt;&#xA;Pn = 25% Pn-1 + 75% Random&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem delay 100ms 10ms 25%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;让波动变成正态分布的&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem delay 100ms 20ms distribution normal&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4 id=&#34;heading-4&#34;&gt;模拟网络丢包&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;设置丢包率为 1%&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem loss 0.1%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;添加一个相关性参数&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;这个参数表示当前丢包的概率与上一条数据包丢包概率有 25% 的相关性&lt;br&gt;&#xA;Pn = 25% Pn-1 + 75% Random&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem loss 0.1% 25%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4 id=&#34;heading-5&#34;&gt;模拟数据包重复&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;1% 的数据包重复&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem duplicate 1%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4 id=&#34;heading-6&#34;&gt;模拟包损坏&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2% 的包损坏&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc add dev eth0 root netem corrupt 2%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4 id=&#34;heading-7&#34;&gt;模拟包乱序&lt;/h4&gt;&#xA;&lt;p&gt;网络传输并不能保证顺序，传输层 TCP 会对报文进行重组保证顺序，所以报文乱序对应用的影响比上面的几种问题要小。&lt;/p&gt;&#xA;&lt;p&gt;报文乱序可前面的参数不太一样，因为上面的报文问题都是独立的，针对单个报文做操作就行，而乱序则牵涉到多个报文的重组。模拟报乱序一定会用到延迟（因为模拟乱序的本质就是把一些包延迟发送），netem 有两种方法可以做。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;第一种是固定的每隔一定数量的报文就乱序一次：&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每 5th (10th, 15th...) 的包延迟 10ms&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem gap 5 delay 10ms&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;第二种方法使用概率来选择乱序，相对来说更偏向实际情况一些&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;25 % 的立刻发送（50% 的相关性），其余的延迟 10ms&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc change dev eth0 root netem delay 10ms reorder 25% 50%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;只使用 delay 也可能造成数据包的乱序&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt; tc qdisc change dev eth0 root netem delay 100ms 75ms&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;比如 first one random 100ms, second random 25ms，这样就是会造成第一个包先于第二个包发送&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h4 id=&#34;heading-8&#34;&gt;限制出口带宽&lt;/h4&gt;&#xA;&lt;p&gt;以 tbf (Token Bucket Filter) 为例，&lt;/p&gt;&#xA;&lt;p&gt;参数说明：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc add tbf limit BYTES burst BYTES rate KBPS [mtu BYTES] [peakrate KBPS] [latency TIME] [overhead BYTES] [linklayer TYPE]&#xA;&#xA;rate 是第一个令牌桶的填充速率&#xA;peakrate 是第二个令牌桶的填充速率&#xA;peakrate&amp;gt;rate&#xA;burst 是第一个令牌桶的大小&#xA;mtu 是第二个令牌桶的大小&#xA;burst&amp;gt;mtu (此处是个坑，一定要保证 burst &amp;gt; mtu, 要不然一个包也发不出了)&#xA;若令牌桶中令牌不够，数据包就需要等待一定时间，这个时间由 latency 参数控制，如果等待时间超过 latency，那么这个包就会被丢弃&#xA;limit 参数是设置最多允许多少数据可以在队列中等待&#xA;latency=max((limit-burst)/rate,(limit-mtu)/peakrate);&#xA;burst 应该大于 mtu 和 rate&#xA;overhead 表示 ADSL 网络对数据包的封装开销&#xA;linklayer 指定了链路的类型，可以是以太网或者 ATM 或 ADSL&#xA;ATM 和 ADSL 报头开销均为 5 个字节。&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;example：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;限制 100mbit&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc add dev ens33 root tbf rate 100mbit latency 50ms burst 1600&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;限制延迟 100ms, 流量 100mbit&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;tc qdisc add dev eth0 root handle 1:0 netem delay 100ms&#xA;tc qdisc add dev eth0 parent 1:1 handle 10: tbf rate 256kbit buffer 1600 limit 3000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;classful-&#34;&gt;classful 队列&lt;/h3&gt;&#xA;&lt;p&gt;这个就复杂一些，同样也特别灵活，可以限制特定的 ip 或者服务类型以及端口&lt;/p&gt;&#xA;&lt;p&gt;以使用 htb 为例&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// 给 root 添加 htb 队列 id: 1:0&#xA;tc qdi sc add dev eth0 root handle 1: htb default 20&#xA;// 给 htb 队列添加一个 class， clas id: 1:1&#xA;tc class add dev eth0 parent 1:0 classid 1:1 htb rate 100mbit burst 10k&#xA;// 给这个 class 1:1 加上一个 filter, 此 filter 只是对 ip 做了过滤&#xA;tc filter add dev eth0 parent 1: protocol ip prio 16 u32  match ip dst 0.0.0.0/0 flowid 1:1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;heading-9&#34;&gt;控制入口流量&lt;/h2&gt;&#xA;&lt;p&gt;使用 TC 进行入口限流，需要把流量重定向到 ifb 虚拟网卡，然后在控制 ifb 的输出流量&lt;/p&gt;&#xA;&lt;p&gt;原理图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1354528849_1019.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// 开启 ifb 虚拟网卡&#xA;modprobe ifb numifbs=1&#xA;ip link set dev $IFB up&#xA;&#xA;// 将 eth0 流量重定向到 ifb0&#xA;tc qdisc add dev eth0 handle ffff: ingress&#xA;tc filter add dev eth0 parent ffff: protocol ip u32 match u32 0 0 flowid 1:1 action mirred egress redirect dev ifb0&#xA;&#xA;// 然后就是限制 ifb0 的输出就可以了&#xA;......&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;heading-10&#34;&gt;在说几句&lt;/h2&gt;&#xA;&lt;p&gt;TC 还有很多细节没有去研究到，目前这些基本上可以满足目前的需求，最后还想吐槽一句，当 TC 命令出错的时候，TC 的报错信息太少了，调试起来太坑...&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/magnific0/wondershaper&#34;&gt;wondershaper&lt;/a&gt; 这个脚本用起来还是很方便&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;heading-11&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.tldp.org/HOWTO/html_single/Traffic-Control-HOWTO/&#34;&gt;Traffic Control HOWTO&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.linuxfoundation.org/networking/netem&#34;&gt;netem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.ituring.com.cn/article/274015&#34;&gt;Linux 流量控制工具 TC&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.ituring.com.cn/article/274014&#34;&gt;流量控制工具 TC 详细说明&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.51cto.com/professor/1570778&#34;&gt;Linux 下 TC 以及 netem 队列的使用&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zhangskd/article/details/8240290&#34;&gt;输入方向的流量控制&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/magnific0/wondershaper&#34;&gt;wondershaper&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>漏桶算法 &amp;&amp; 令牌桶算法</title>
    <updated>2018-05-22T00:00:00Z</updated>
    <id>tag:int64.me,2018-05-22:/2018/漏桶算法 &amp;&amp; 令牌桶算法.html</id>
    <link href="http://int64.me/2018/漏桶算法 &amp;&amp; 令牌桶算法.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;在看 &lt;code&gt;TC&lt;/code&gt; 文档的时候，文档中提到了 token bucket，TC 中可以使用这个算法来进行流量控制，模糊印象中听过这个算法，但是并不知道这个算法具体是什么，就好奇的去一探究竟...&lt;/p&gt;&#xA;&lt;h2 id=&#34;leaky-bucket&#34;&gt;先说漏桶（Leaky bucket）&lt;/h2&gt;&#xA;&lt;p&gt;从 wiki 上介绍，Leaky bucket 算法有两个版本：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;as a meter（作为计量工具）&lt;/li&gt;&#xA;&lt;li&gt;as a queue（作为调度队列）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;其中，第一种含义和 Token Bucket 是等价的（所有我就没详细的去看版本一，而是后面直接去看 Token Bucket 算法），只是表述的角度不同。更有趣的是，第二种含义其实是第一种的特例。这些对比和区别在后面再谈，先整体看一下 Leaky Bucket。&lt;/p&gt;&#xA;&lt;p&gt;先看一张图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Leaky_bucket_analogy.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;其实这图已经很好的展示了 leaky bucket 的抽象模型，就是一个会漏水的桶😂&lt;/p&gt;&#xA;&lt;p&gt;如图描述，桶有一个输入一个输出，输出就是桶的下方有一个恒定速度的往下漏水，输入就是以一个变化的速度往水桶里进水，一旦水满了，上方的水就无法加入。对于如何处理桶满后的上方欲流下的水，有有一下两种常见的方式（其实这已经不是 leaky bucket 算法考虑的事情了）。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Traffic_shaping&#34;&gt;Traffic Shaping&lt;/a&gt;: 暂时拦截住上方水的向下流动，等待桶中的一部分水漏走后，再放行上方水。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Traffic_policing&#34;&gt;Traffic Policing&lt;/a&gt;: 溢出的上方水直接抛弃。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;其实是将水看作网络通信中数据包的抽象，Traffic Shaping 的核心理念是 “等待”，Traffic Policing 的核心理念是 “丢弃”。它们是两种常见的流速控制方法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;as a meter&lt;/code&gt; 版本的 leaky bucket 和 token bucket 只是换个描述角度，原理上是一样的，所以就没有做过多的研究。可以看一下 wiki 上两种算法的对比，你就会发现其实是一样的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-05-22%20at%201.56.57%20PM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;-token-bucket&#34;&gt;令牌桶 （Token Bucket)&lt;/h2&gt;&#xA;&lt;p&gt;还是先上图&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/token_bucket.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;概述：令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。&lt;br&gt;&#xA;算法基本过程：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;假如用户配置的平均发送速率为 r，则每隔 1/r 秒一个令牌被加入到桶中；&lt;/li&gt;&#xA;&lt;li&gt;假设桶最多可以存发 b 个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃；&lt;/li&gt;&#xA;&lt;li&gt;当一个 n 个字节的数据包到达时，就从令牌桶中删除 n 个令牌，并且数据包被发送到网络；&lt;/li&gt;&#xA;&lt;li&gt;如果令牌桶中少于 n 个令牌，那么不会删除令牌，并且认为这个数据包在流量限制之外；&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;算法允许最长 b 个字节的突发，但从长期运行结果看，数据包的速率被限制成常量 r。对于在流量限制外的数据包可以以不同的方式处理：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;它们可以被丢弃；&lt;/li&gt;&#xA;&lt;li&gt;它们可以排放在队列中以便当令牌桶中累积了足够多的令牌时再传输；&lt;br&gt;&#xA;它们可以继续发送，但需要做特殊标记，网络过载的时候将这些特殊标记的包丢弃&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;github 实现源码:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rbarrois/throttle&#34;&gt;https://github.com/rbarrois/throttle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/titan-web/rate-limit&#34;&gt;https://github.com/titan-web/rate-limit&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/yangwenmai/ratelimit&#34;&gt;https://github.com/yangwenmai/ratelimit&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;总结&lt;/h2&gt;&#xA;&lt;p&gt;其实 &lt;code&gt;as a queue leaky bucket&lt;/code&gt; 算法就是 token bucket 算法的一个特例，平时我们大多数说的漏桶算法就是指 &lt;code&gt;as a queue leaky bucket&lt;/code&gt;。漏桶算法主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。而令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-1&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Token_bucket&#34;&gt;wiki Token Bucket&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Leaky_bucket&#34;&gt;wiki Leaky Bucket&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/smyte/rate-limiter-df3408325846&#34;&gt;High-performance rate limiting&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/LBSer/p/4083131.html&#34;&gt;流量调整和限流技术&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.51cto.com/leyew/860302&#34;&gt;漏桶算法 Leaky Bucket （令牌桶算法 Token Bucket）学习笔记&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://caden16.github.io/python/python%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/&#34;&gt;python 网速控制&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>TiDB 性能优化之玄学调优</title>
    <updated>2018-04-08T00:00:00Z</updated>
    <id>tag:int64.me,2018-04-08:/2018/TiDB 性能优化之玄学调优.html</id>
    <link href="http://int64.me/2018/TiDB 性能优化之玄学调优.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TiDB 玄学调优是我们自黑比较狠的梗之一，当初 TiKV 里大把的参数让我头疼了好久 ( TiKV 的配置参数大多数是和 RocksDB 相关 )。好在现在很多参数现在的默认值已经很科学大大的减少了我们玄学调优的难度。&lt;br&gt;&#xA;以下是是我平时在测试 TiDB 时候，进行瓶颈定位的过程...&lt;/p&gt;&#xA;&lt;p&gt;我们以 sysbench 测试为例，使用的测试脚本：https://github.com/pingcap/tidb-bench/tree/master/sysbench&lt;br&gt;&#xA;可用机器公共四台，机器配置：CPU 16 核 / Mem 110 GB  / Disk 1024GB SSD&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;硬件性能测试&lt;/h2&gt;&#xA;&lt;p&gt;测试之前先进行基本的硬件测试，比如磁盘 fio 测试，网络延迟以及网速的测试，这些测试有利于排除一些干扰因素。&lt;br&gt;&#xA;这地方就提供几本的测试方法，之前已经测试过了，此处就不实际测试了。&lt;/p&gt;&#xA;&lt;p&gt;测试磁盘：推荐 fio （fio 使用需谨慎，不要直接写裸设备，笔者连续写坏好几块盘，都是血泪啊），dd，sysbench...&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// fio&#xA;fio -ioengine=libaio -bs=32k -direct=1 -thread -rw=read  -size=10G -filename=test -name=&amp;quot;PingCAP max throughput&amp;quot; -iodepth=4 -runtime=60&#xA;&#xA;// dd&#xA;dd bs=4k count=250000 oflag=direct if=/dev/zero of=./dd_test.txt&#xA;&#xA;// sysbench&#xA;sysbench --test=fileio --file-num=16 --file-block-size=16384 --file-total-size=2G prepare&#xA;sysbench --test=fileio --file-num=16 --file-block-size=16384 --file-total-size=2G --num-threads=4 --max-requests=100000000 --max-time=180 --file-test-mode=seqwr --file-extra-flags=direct run&#xA;sysbench --test=fileio --file-num=16 --file-block-size=16384 --file-total-size=2G --num-threads=4 --max-requests=100000000 --max-time=180 --file-test-mode=seqwr --file-extra-flags=direct clean&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;测试延迟：直接 ping 查看延迟以及丢包情况&lt;/p&gt;&#xA;&lt;p&gt;测试网速: 最简单 dd + scp，dd + pv + nc , iperf&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// scp&#xA;dd if=/dev/zero bs=2M count=2048 of=./test // 生成 4 GB 文件&#xA;scp ./test ip ip&#xA;&#xA;// dd + pv + nc&#xA;dd if=/dev/zero bs=1M count=1024 of=./test&#xA;pv test| nc 10.0.1.8 5433 // 发送&#xA;nc -vv -l -p 5433 &amp;gt; test  // 接收&#xA;&#xA;// iperf&#xA;iperf -s            // server&#xA;iperf -c 10.0.1.4   // client&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;sysbench-oltp-&#34;&gt;sysbench oltp 测试瓶颈定位&lt;/h2&gt;&#xA;&lt;p&gt;运行 sysbench oltp 测试， sysbench 默认 oltp 一个事务包含 18 条 SQL:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;10 * point select&#xA;1 * simple range select&#xA;1 * sum range&#xA;1 * order range&#xA;1 * distinct range&#xA;1 * index update&#xA;1 * non index update&#xA;1 * insert&#xA;1 * delete&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;从事务的组合上来看度占大部分，经验告诉我们最先读多属于 CPU 密集型的操作，TiDB 的 CPU 最有可能成为瓶颈，我们先使用 1 TiDB + 3 TiKV 的架构进行测试，实际观察一下运行情况。&lt;/p&gt;&#xA;&lt;p&gt;使用 &lt;a href=&#34;https://github.com/pingcap/tidb-ansible&#34;&gt;tidb-ansible&lt;/a&gt; 部署集群&lt;/p&gt;&#xA;&lt;p&gt;部署拓扑：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th style=&#34;text-align:center&#34;&gt;ip&lt;/th&gt;&#xA;&lt;th style=&#34;text-align:center&#34;&gt;部署&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;10.0.1.6&lt;/td&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;tidb / pd / sysbench&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;10.0.1.7&lt;/td&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;tikv&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;10.0.1.8&lt;/td&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;tikv&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;10.0.1.9&lt;/td&gt;&#xA;&lt;td style=&#34;text-align:center&#34;&gt;tikv&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;测试流程：prepare -&amp;gt; run&lt;/p&gt;&#xA;&lt;p&gt;运行测试脚本，先观察 tidb / tikv 的 cpu 使用情况（一般来说 oltp 测试，主要瓶颈会集中在 tidb 的 cpu 上，要又重点的去排查问题）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-04-08%20at%2012.16.54%20AM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以看到 tidb 的机器的 load 已经达到了 20+，这是一台 15 核的机器，感觉这台机器的 cpu 几乎已经被榨干了，我们都不需要去看别的瓶颈，这 tidb 的cpu 已经限制了整体性能。那么我们接下来要做的就是要把这个瓶颈去掉，&lt;strong&gt;最直接的方法就是升级硬件或是加机器，我们尝试增加机器，同时主要注意增加压力&lt;/strong&gt;。（没有多余的机器就不做实验了） 当我们把 tidb 机器的数量也增加到 3 台或是更多的时候，我们就会发现瓶颈发生了转移，这个时候瓶颈就会从 tidb 转移到了 tikv，tikv 有个 end-point-concurrency 这样一个东西用来处理 tidb 的请求，我们使用 top -H 来观察一下&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-04-08%20at%2012.31.58%20AM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;对应 grafana 监控上的就是&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-04-08%20at%2012.34.02%20AM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;end-point-concurrency 什么时候算是出现瓶颈呢？ 默认 end-point-concurrency  是使用 4个线程，那么我们就可以这么认为，当 top -H 的时候发现这个四个线程的 cpu 使用都超过了 90% ，那么就可以认为 end-point-concurrency 限制了整个系统的吞吐，接下来我们要做的就是如何来把这个瓶颈给消除掉，如果目前 tikv 的机器整体 cpu 使用还是很闲，那么我们就&lt;strong&gt;增加这个 end-point-concurrency 的线程数量&lt;/strong&gt;，这个就要修改 tikv 的启动参数了,这个可以参考文档：https://github.com/pingcap/docs-cn/blob/master/op-guide/tune-tikv.md 。&lt;br&gt;&#xA;（grpc 线程也是会出现瓶颈，改进方法和 end-point-concurrency 类似，直接增加线程数量）&lt;/p&gt;&#xA;&lt;p&gt;当我们解决掉 end-point-concurrency，我们会发现系统的整体吞吐会有所提高，但是此时又会出现新的瓶颈，以我往常的经验来说，接下来的瓶颈应该会出现在  end-point-work 这个线程上，为嘛会出现在这个线程上呢？其实要是知道这个线程是用来干嘛的就很好理解了，这个现场是用来调度 end-point-concurrency 这个玩意掉，当 end-point-concurrency 线程多了，那么调度就会出现瓶颈，遗憾的是 end-point-work 是单线程，我们要解决这个的瓶颈，&lt;strong&gt;只能提升单核 cpu 的能力，或是增加 tikv 的数量&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;瓶颈&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TiDB CPU 一般会优先成为瓶颈&lt;/li&gt;&#xA;&lt;li&gt;TiKV 的 endpoint 线程&lt;/li&gt;&#xA;&lt;li&gt;grpc 线程&lt;/li&gt;&#xA;&lt;li&gt;TiKV 的 end-point-work 线程&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;优化&#xA;&lt;ul&gt;&#xA;&lt;li&gt;加 TiDB 节点，可以尝试在 TiKV 机器上添加（ TiKV CPU比较充足）&lt;/li&gt;&#xA;&lt;li&gt;调整 end-point-concurrency 参数，增大 endpoint 线程数量&lt;/li&gt;&#xA;&lt;li&gt;调整 grpc-concurrency 参数，增加 grpc 线程数量&lt;/li&gt;&#xA;&lt;li&gt;调大 racksdb cache&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;sysbench oltp 性能瓶颈定位就说这些，实际情况中 tidb 的瓶颈并不是一成不变的，需要根据实际情况去优化调整，要不然就不叫玄学了😄。&lt;/p&gt;&#xA;&lt;h2 id=&#34;sysbench-insert-&#34;&gt;sysbench insert 测试瓶颈定位&lt;/h2&gt;&#xA;&lt;p&gt;sysbench insert 脚本很简单，就是顺序写，那么我们先从 tikv 基本概念考虑，tikv 内的最小几本单元是 region, 并且是每个表肯定是对应这个不同的 region，那么加入我们的测试只正对一个表 insert，我们有再多的 tikv 也是没有卵用，（对这个问题，目前有相应的解决办法，具体我也不是太清楚）所以我们测试要保证表的数量一定要大于 tikv 节点的数量（当然越多越好了），这里实验的时候我是使用了 16个表，每个表预先 prepare 了 100w 的数据。&lt;/p&gt;&#xA;&lt;p&gt;运行 insert 脚本，同样我会先 top 看 tidb ／ tikv ／pd 的 cpu 使用情况。&lt;br&gt;&#xA;我们会很容易的发现 insert 的时候我们 TiDB 的 CPU 并不会首先成为瓶颈（并不绝对），但是发现 TiKV 的压力还是很大的，我们就需要去定位 TiKV 的瓶颈，如果 TiKV 压力也是很小，那么我们就要看一下是不是磁盘 IO 存在问题，查看磁盘 IO ，正常来说查看磁盘情况我使用 iostat&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-04-08%20at%209.58.10%20AM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们可以看到 sde 盘的 %util 在 70，也就是说挺忙的，但是还可以还没有达到瓶颈，正常来说超过了 90 以上，就可以认为这块盘已经被我们压榨的差不多了。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;划水了，insert 测试的详细定位过程后面在单独写一篇吧&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;summary-1&#34;&gt;Summary&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;瓶颈&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TiKV raftstore 线程&lt;/li&gt;&#xA;&lt;li&gt;磁盘 IO ，出现 stall 或是出现很多 IO wait&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;优化&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果在磁盘没有达到瓶颈的前提下，TiKV 机器的 CPU 还很富裕，可以单台多部署，一般单个 TiKV 实例对应一块盘&lt;/li&gt;&#xA;&lt;li&gt;磁盘 IO 出现瓶颈，可以调整压缩方式，用 CPU 资源换取 IO 资源&lt;/li&gt;&#xA;&lt;li&gt;发现系统的 IO 压力不大，但是 CPU资源已经吃光了，top -H 发现有大量的 bg 开头的线程（RocksDB 的 compaction 线程）在运行，这个时候可以考虑减少压缩用 IO 资源换取 CPU 资源&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;heading-1&#34;&gt;一点小提示&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sysbench 版本建议使用 1.0 及以上版本&lt;/li&gt;&#xA;&lt;li&gt;当集群 TiKV 节点数量大于 3 的时候，在 prepare 数据完成后，需要等待 TiKV 节点上的 * leader 以及 region 数量均匀分布后，在进行各种基准测试，可以通过pd-ctl 或是 http://hosts:port/pd/api/v1/stores 或是 Grafana 监控查看各个 TiKV 节点上 leader 和 region 的分布情况。&lt;/li&gt;&#xA;&lt;li&gt;当进行多轮测试的时候，当需要清理数据的时候，不要执行 DROP 操作，可以使用 Ansible 进行物理删除，然后在重启集群，重新 prepare 数据进行测试。&lt;/li&gt;&#xA;&lt;li&gt;当 TiDB , TiKV 都没有达到瓶颈的时候, 可以不断增大 Sysbench 线程数量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;heading-2&#34;&gt;最后说一点&lt;/h2&gt;&#xA;&lt;p&gt;以上只是一个小的示例，在进行实际性能测试的过程中，总是会出现各种各样的情况，出现的瓶颈的地方也不是一成不变的，我所谓的玄学并不是没有根据的胡乱调整，而是分析测试实际情况加上自己对 TiDB 系统的理解，进行合理调整部署拓扑以及配置参数。当然如果对 TiDB / TiKV / PD 程序的优化感兴趣，我们也可以很好的利用压测 + Grafan 监控 + Perf + &lt;a href=&#34;https://github.com/brendangregg/FlameGraph&#34;&gt;FlameGraph&lt;/a&gt; 定位程序内部的瓶颈。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-3&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-cn/tangliu-tool-1/&#34;&gt;工欲性能调优，必先利其器（1）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-cn/tangliu-tool-2/&#34;&gt;工欲性能调优，必先利其器（2）- 火焰图&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-cn/tidb-internal-1/&#34;&gt;三篇文章了解 TiDB 技术内幕 - 说存储&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://int64.me/2017/sysbench%E7%9A%84%E4%B8%80%E7%82%B9%E6%95%B4%E7%90%86.html&#34;&gt;sysbench 的一点整理&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/docs-cn/blob/master/op-guide/tune-tikv.md&#34;&gt;TiKV 性能参数调优&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>Percolator 论文笔记</title>
    <updated>2018-02-28T00:00:00Z</updated>
    <id>tag:int64.me,2018-02-28:/2018/Percolator 论文笔记.html</id>
    <link href="http://int64.me/2018/Percolator 论文笔记.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TiDB 的事务模型是参考 Google Percolator 事务模型，想去研究 TiDB 的事务模型，学习一下 Google Percolator 论文必不可少...&lt;/p&gt;&#xA;&lt;h2 id=&#34;percolator-&#34;&gt;Percolator 简介&lt;/h2&gt;&#xA;&lt;h3 id=&#34;heading&#34;&gt;背景&lt;/h3&gt;&#xA;&lt;p&gt;简单来说 Percolator 事务模型的出现是因为之前采用 MapReduce 设计的批量创建索引的系统不支持跨行事务以及不支持随机增量更新。于是乎 Percolator 就诞生了（ Google 还真是想啥有啥啊，实力真不是盖的 ）。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-1&#34;&gt;特性&lt;/h3&gt;&#xA;&lt;p&gt;Percolator的特点如下&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;为增量处理定制&lt;/li&gt;&#xA;&lt;li&gt;处理结果强一致&lt;/li&gt;&#xA;&lt;li&gt;针对大数据量（小数据量用传统的数据库即可）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Percolator 为可扩展的增量处理提供了两个主要抽象：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基于随机存取库的ACID事务&lt;/li&gt;&#xA;&lt;li&gt;观察者(observers)–一种用于处理增量计算的方式&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;heading-2&#34;&gt;延迟问题&lt;/h3&gt;&#xA;&lt;p&gt;由于 Percolator 在设计的时候追求的是大数据量而对延迟没有特定要求，所有基于 Percolator 事物模型设计的系统，延迟和传统 DBMS 等数据库系统相比还是有很大的差距的。主要原因还是锁的问题。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Percolator 使用一个 lazy 的方法去清理遗留下来的锁，比如一个 transactions 由于运行的机器挂掉了，这个 transactions 失败遗留下来的锁可能不会立刻清理，而是等待下一个使用到该数据的饿事务负责清理&lt;/li&gt;&#xA;&lt;li&gt;缺少全局 deadlock 检查，这样就使交易冲突的情况增多，事务重试的次数就会变多，延迟就会随之增大。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;heading-3&#34;&gt;设计&lt;/h2&gt;&#xA;&lt;h3 id=&#34;bigtable-&#34;&gt;Bigtable 概述&lt;/h3&gt;&#xA;&lt;p&gt;Percolator 是建立在 Bigtable 分布式系统的上层，Bigtable&lt;br&gt;&#xA;是一个稀疏的、分布式的、持久化存储的多维度排序 Map。Map 的索引是行关键字、列关键字以及时间戳，Bigtable 以 SSTable 格式存储数据，并且这些 SSTables 是被存储在 GFS 上。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-27%20at%2012.44.16%20AM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-4&#34;&gt;事务&lt;/h3&gt;&#xA;&lt;p&gt;Percolator 提供了跨行、跨表的、基于快照隔离的ACID事务。&lt;/p&gt;&#xA;&lt;h4 id=&#34;snapshop-isolation&#34;&gt;Snapshop isolation&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-27%20at%209.34.11%20AM.png&#34; alt=&#34;sanpshop isolation&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;如图，是基于 Snapshop isolation  的三个 transactions，每个 Transaction 都是开始与 a start timestamp, 并且结束与 a commit timestamp。在这个例子中：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;因为 transaction 2 的 start timestamp 是在transaction 1 commit timestamp 之前的，所以 transaction 2 不能够读到 transaction 1 提交的信息&lt;/li&gt;&#xA;&lt;li&gt;transaction 3 可以同时看到 transaction 1 和 transaction 2 的提交信息&lt;/li&gt;&#xA;&lt;li&gt;transaction 1 和 transaction 2 是并发的执行，如果他们写入同一项，这两个事务中至少又一个会执行失败&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;lock&#34;&gt;Lock&lt;/h4&gt;&#xA;&lt;p&gt;Bigtable 本身并没有提供便捷的冲突解决和锁管理，Percolator 必须自己维护一套独立的锁的管理机制。&lt;/p&gt;&#xA;&lt;p&gt;要求：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;容错，当机器出现故障的时候不影响正确性，如果在两阶段提交的过程中锁出现了丢失，可能将两个有冲突的事物都提交成功。&lt;/li&gt;&#xA;&lt;li&gt;高吞吐，上千台机器会同时请求获取锁。&lt;/li&gt;&#xA;&lt;li&gt;低延迟, 每个 Get() 操作都需要读取一次锁。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Percolator 需要做到：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;多副本，容错&lt;/li&gt;&#xA;&lt;li&gt;分布式以及负载均衡，处理负载&lt;/li&gt;&#xA;&lt;li&gt;数据持久化&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;BigTable 能够满足以上所有要求。所以 Percolator 在实现时，将实际的数据存于Bigtable中。&lt;/p&gt;&#xA;&lt;h3 id=&#34;columns-in-bigtable&#34;&gt;Columns in Bigtable&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-27%20at%2011.32.55%20PM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Percolator 在 Bigtable 上抽象了 5 Columns 去存储数据，如上图，其中有 3 和事务相关：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;c:lock&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;事务产生的锁，未提交的事务会写本项，会包含 primary lock 的位置。其映射关系为&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\({key,start_ts}=&gt;\)&lt;/span&gt;{primary_key,lock_type,..etc}&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;${key} 数据的key&#xA;${start_ts} 事务开始时间&#xA;${primary} 该事务的primary的引用. primary是在事务执行时，从待修改的 keys中 选择一个作为primary,其余的则作为secondary.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;c:write&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;已提交的数据信息，存储数据所对应的时间戳。其映射关系为&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\({key,commit_ts}=&gt;\)&lt;/span&gt;{start_ts}&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;${key} 数据的key&#xA;${commit_ts} 事务的提交时间&#xA;${start_ts} 该事务的开始时间,指向该数据在data中的实际存储位置。&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;c:data&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;具体存储数据集，映射关系为&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\({key,start_ts} =&gt; \)&lt;/span&gt;{value}&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;${key} 真实的key&#xA;${start_ts} 对应事务的开始时间&#xA;${value} 真实的数据值&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;-percolator-&#34;&gt;简述 Percolator 事务流程&lt;/h3&gt;&#xA;&lt;p&gt;事务提交采用两阶段提交。两阶段提交通过 client 来协调。&lt;/p&gt;&#xA;&lt;h4 id=&#34;prewrite&#34;&gt;Prewrite&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/prewrite.jpg&#34; alt=&#34;prewrite&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;图片 copy &lt;a href=&#34;http://andremouche.github.io/transaction/percolator.html&#34;&gt;雪姐 blog: Google Percolator 的事务模型&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;在提交的第一个阶段：其从 Oracle 获取代表当前物理时间的全局唯一时间戳作为当前事务的 start_ts，我们首先获取所有需要写入的 cell 的 lock（考虑到 client 故障情况，我们会任意指定一个 lock 为 primary，其余的作为 secondary），每个事务都会读取 meta 数据来检测事务是否存在冲突。&lt;/p&gt;&#xA;&lt;p&gt;有两种冲突的情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如果一个事务 A 看到 cell 的 write 列中已经存在一条记录，记录的时间戳晚于该事务开始的时间戳，那么说明存在写冲突，即说明有一个事务在 A 发起之后更新了 cell 的值，事务 A 需要 aborted。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如果事务看到 cell 的 lock 列中存在任意一条锁记录，不管时间戳为多少，直接 aborted。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;如果两种冲突都不存在，向 lock 列中写入上锁信息，并更新 data 列数据。&lt;/p&gt;&#xA;&lt;h4 id=&#34;commit&#34;&gt;Commit&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/commit.jpg&#34; alt=&#34;commit&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;图片 copy &lt;a href=&#34;http://andremouche.github.io/transaction/percolator.html&#34;&gt;雪姐 blog: Google Percolator 的事务模型&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;如果没有 cell 冲突，那么说明事务可以提交，进行下一个阶段 commit：首先 client 会向时间服务器申请一个 timestamp 作为 commit_ts，表示 commit 的时间。然后 client 会释放事务中涉及的所有 cell 的锁（清空 lock 列），释放顺序从 primary lock开始。&lt;/p&gt;&#xA;&lt;p&gt;释放锁之后便更新 write 列来使新的 read 能够读到本次事务的数据。write 列的数据表示：本次事务的数据已经成功更新至 cell 中，write 列中的数据包含了一个 timestamp，该 timestamp 表示本次事务数据的 timestamp，用户可以通过该 timestamp 来找到数据。一旦 primary 锁对应记录的 write 列数据可见了，代表该事务一定已经 commit 了，reader 此时能看到该事务的数据。&lt;/p&gt;&#xA;&lt;h4 id=&#34;get-operation&#34;&gt;Get operation&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/get.jpg&#34; alt=&#34;get&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;图片 copy &lt;a href=&#34;http://andremouche.github.io/transaction/percolator.html&#34;&gt;雪姐 blog: Google Percolator 的事务模型&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Get 操作首先检查[0,start_ts]时间区间内Lock是否存在，若存在，说明可能有其他 transaction 正在写这个 cell，所以这个读 transaction 需要等待 lock 释放掉。如果不存在有冲突的 lock,则获取在 write 中合法的最新提交记录指向的在 data 中的位置。&lt;/li&gt;&#xA;&lt;li&gt;从 data 中获取到相应的数据并返回。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;clean-lock&#34;&gt;clean lock&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/rollback.jpg&#34; alt=&#34;clean lock&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;图片 copy &lt;a href=&#34;http://andremouche.github.io/transaction/percolator.html&#34;&gt;雪姐 blog: Google Percolator 的事务模型&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;若客户端在 Commit 一个事务时，出现了异常，Prepare 时产生的锁会被留下。为避免将新事务 hang 住，Percolator 必须清理这些锁。&lt;/p&gt;&#xA;&lt;p&gt;Percolator 用 lazy 方式处理这些锁：当事务 A 在执行时，发现事务 B 造成的锁冲突，事务 A 将决定事务 B 是否失败，以及清理事务 B 的那些锁。&lt;br&gt;&#xA;对事务 A 而言，能准确地判断事务 B 是否成功是关键。Percolator 为每个事务设计了一个元素cell作为事务是否成功的同步标准，该元素产生的 lock 即为 primary lock。A 和 B 事务都能确定事务 B 的 primary lock（因为这个priarmy lock被写入了B事务其它所有涉及元素的lock里面）。执行一个清理 clean up 或者提交 commit 操作需要修改该primary lock，由于这些修改是基于 Bigtable 去做，所以只有一个清理或提交会成功。注意：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在B提交 commit 之前,它会先确保其 primary lock 被 write record 所替代（即往 primary 的 write 写提交数据，并删除对应的 lock）。&lt;/li&gt;&#xA;&lt;li&gt;在 A 清理 B 的锁之前，A 必须检查 B 的 primary 以确保 B 未被提交，如果 B 的 primary 存在，则 B 的锁可以被安全的清理掉。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;当客户端在执行两阶段提交的 commit 阶段失败时，事务依旧会留下一个提交点 commit point(至少一条记录会被写入 write 中)，但可能会留下一些 lock 未被处理掉。一个事务能够从其 primary lock 中获取到执行情况：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果 priarmy lock 已被 write 所替代，也就是说该事务已被提交，可以放心的清理 B 事务的所有 lock&lt;/li&gt;&#xA;&lt;li&gt;如果 primary lock 存在，事务被 roll back (因为我们总是最先提交 primary ,所以 primary 未被提交时，可以安全地执行回滚)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;heading-5&#34;&gt;案例&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-28%20at%2012.59.40%20AM.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;初始状态下，Bob 的帐户下有 &lt;span class=&#34;math inline&#34;&gt;\(10（首先查询 column write 获取最新时间戳数据,获取到 data@5,然后从 column data 里面获取时间戳为5的数据，即 \)&lt;/span&gt;10），Joe 的帐户下有 $2。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-28%20at%2012.59.46%20AM.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;转账开始，使用 stat timestamp=7 作为当前事务的开始时间戳，将 Bob 选为本事务的 primary，通过写入 Column Lock 锁定 Bob 的帐户，同时将数据 7:$3 写入到 Column,data 列。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-28%20at%2012.59.53%20AM.png&#34; alt=&#34;3&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;同样的，使用 stat timestamp=7，锁定 Joe 的帐户，并将 Joe 改变后的余额写入到 Column,data ,当前锁作为 secondary 并存储一个指向 primary 的引用（当失败时，能够快速定位到 primary 锁，并根据其状态异步清理）&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-28%20at%201.00.00%20AM.png&#34; alt=&#34;4&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;事务带着当前时间戳 commit timestamp=8 进入 commit 阶段：删除 primary 所在的 lock，并在 write 列中写入从提交时间戳指向数据存储的一个指针 commit_ts=&amp;gt;data @7。至此，读请求过来时将看到 Bob 的余额为3。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-28%20at%201.00.06%20AM.png&#34; alt=&#34;5&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;依次在 secondary 项中写入wirte并清理锁，整个事务提交结束。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;heading-6&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&#34;&gt;Large-scale Incremental Processing&lt;br&gt;&#xA;Using Distributed Transactions and Notifications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://andremouche.github.io/transaction/percolator.html&#34;&gt;雪姐 blog: Google Percolator 的事务模型&lt;/a&gt; - 很多描述是从雪姐 blog 直接 copy 过来&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/05194f4b29dd&#34;&gt;Percolator简单翻译与个人理解&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>MVCC In TiKV</title>
    <updated>2017-11-28T00:00:00Z</updated>
    <id>tag:int64.me,2017-11-28:/2017/MVCC In TiKV.html</id>
    <link href="http://int64.me/2017/MVCC In TiKV.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;很多数据库都会实现多版本控制（MVCC），TiKV 也不例外，刚好最近在看 TiKV，对于 MVCC 以及 TiKV 内是如何使用 MVCC 的做个简单笔记...&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;乐观锁和悲观锁&lt;/h2&gt;&#xA;&lt;h3 id=&#34;heading-1&#34;&gt;乐观锁&lt;/h3&gt;&#xA;&lt;p&gt;乐观锁呢，读写事务，在真正的提交之前，不加读/写锁，而是先看一下数据的版本/时间戳，等到真正提交的时候再看一下版本/时间戳，如果两次相同，说明别人期间没有对数据进行过修改，那么就可以放心提交。乐观体现在，访问数据时不提前加锁。在资源冲突不激烈的场合，用乐观锁性能较好。如果资源冲突严重，乐观锁的实现会导致事务提交的时候经常看到别人在他之前已经修改了数据，然后要进行回滚或者重试，还不如一上来就加锁。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-2&#34;&gt;悲观锁&lt;/h3&gt;&#xA;&lt;p&gt;一个读写事务在运行的过程中在访问数据之前先加读/写锁这种实现叫做悲观锁，悲观体现在，先加锁，独占数据，防止别人加锁。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;关于乐观锁悲观锁的解释 copy 自：&lt;a href=&#34;https://www.zhihu.com/question/27876575/answer/73330077&#34;&gt;吴镝大神知乎的回答&lt;/a&gt;, 感觉回答的最简洁贴切&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;heading-3&#34;&gt;并发控制&lt;/h2&gt;&#xA;&lt;h3 id=&#34;heading-4&#34;&gt;可串行化&lt;/h3&gt;&#xA;&lt;p&gt;多个事务的并发执行是正确的，当且仅当其结果与按某一次序串行地执行它们时的结果相同。我们称这种调度策略为可串行化（Serializable）的调度。&lt;/p&gt;&#xA;&lt;p&gt;可串行性是并发事务正确性的准则。按这个准则规定，一个给定的并发调度，当且仅当它是可串行化的，才认为是正确调度。DBMS的并发控制机制必须提供一定的手段来保证调度是可串行化的，目前DBMS普遍采用封锁方法实现并发操作调度的可串行性，从而保证调度的正确性。&lt;/p&gt;&#xA;&lt;p&gt;两段锁（Two-Phase Locking，简称2PL）协议就是保证并发调度可串行性的封锁协议。&lt;/p&gt;&#xA;&lt;h3 id=&#34;2pl&#34;&gt;2PL&lt;/h3&gt;&#xA;&lt;p&gt;两段锁（Two-Phase Locking，简称2PL）是指所有事务都必须分为两阶段对数据进行加锁和解锁：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;对任何数据进行读、写操作之前，首先要先申请并获得对该数据的封锁&lt;/li&gt;&#xA;&lt;li&gt;在释放一个封锁以后，事务不再获得任何其他封锁&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在“两段”锁协议中，事务分为两个阶段：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;第一阶段是获得封锁，也称为扩展阶段。这在阶段，事务可以申请获得任何数据项上的任何类型的锁，但是不能释放任何锁。&lt;/li&gt;&#xA;&lt;li&gt;第二阶段是释放封锁，也称为收缩阶段。在这阶段，事务可以释放任何数据项上的任何类型的琐，但是不能再申请任何琐。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;如图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202017-11-27%20at%2011.44.23%20PM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;2pl-&#34;&gt;2PL 一些缺点&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读锁和写锁会相互阻滞（block）。&lt;/li&gt;&#xA;&lt;li&gt;大部分事务都是只读（read-only）的，所以从事务序列（transaction-ordering）的角度来看是无害的。如果使用基于锁的隔离机制，而且如果有一段很长的读事务的话，在这段时间内这个对象就无法被改写，后面的事务就会被阻塞直到这个事务完成。这种机制对于并发性能来说影响很大。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;mvcc&#34;&gt;MVCC&lt;/h3&gt;&#xA;&lt;p&gt;MVCC - 多版本并发控制（Multi-Version Concurrency Control）, 在 MVCC 中，每当想要更改或者删除某个数据对象时，DBMS 不会在原地去删除或这修改这个已有的数据对象本身，而是创建一个该数据对象的新的版本，这样的话同时并发的读取操作仍旧可以读取老版本的数据，而写操作就可以同时进行。这个模式的好处在于，可以让读取操作不再阻塞，事实上根本就不需要锁。这是一种非常诱人的特型，以至于在很多主流的数据库中都采用了 MVCC 的实现，比如说 PostgreSQL，Oracle，Microsoft SQL Server 等。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;此处 copy 自&lt;a href=&#34;https://pingcap.com/blog-cn/MVCC-in-TiKV/&#34;&gt;TiKV 的 MVCC（Multi-Version Concurrency Control）机制&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;mvcc-in-tikv&#34;&gt;MVCC in TiKV&lt;/h2&gt;&#xA;&lt;p&gt;TiKV 目前的底层存储还是使用了 rocksdb， 也就是目前我们的所有数据也就是存在 rocksdb 内。目前 TiKV 会启动两个 rocksdb 实例，默认 rocksdb 实例将 KV 数据存储在内部的 default、write 和 lock 3 个 CF 内。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;default CF 存储的是真正的数据；&lt;/li&gt;&#xA;&lt;li&gt;write CF 存储的是数据的版本信息（MVCC）以及索引相关的数据；&lt;/li&gt;&#xA;&lt;li&gt;lock CF 存储的是锁信息。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Raft RocksDB 实例存储 Raft log。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;default CF 主要存储的是 raft log。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;rocksdb 的 cf 是一个逻辑划分数据库的能力，也就是说做到了想多隔离的存储，但是 rocksdb 提供跨 cf 的原子写操作，不同的 cf 共用同一个 WAL，但是使用不同 memtable 和 ssl。（具体 rocksdb 相关的知识可以查阅 rocksdb 相关文档）。也就是说会有一个单独的 cf 用来存储 MVCC 的版本信息。 TiKV 的 MVCC 实现是通过在 Key 后面添加 Version 来实现，简单来说，没有 MVCC 之前，可以把 TiKV 看做这样的：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;                Key1 -&amp;gt; Value&#xA;&#x9;            Key2 -&amp;gt; Value&#xA;&#x9;            ……&#xA;&#x9;            KeyN -&amp;gt; Value&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;有了 MVCC 之后，TiKV 的 Key 排列是这样的：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&#x9;            Key1-Version3 -&amp;gt; Value&#xA;&#x9;            Key1-Version2 -&amp;gt; Value&#xA;&#x9;            Key1-Version1 -&amp;gt; Value&#xA;&#x9;            ……&#xA;&#x9;            Key2-Version4 -&amp;gt; Value&#xA;&#x9;            Key2-Version3 -&amp;gt; Value&#xA;&#x9;            Key2-Version2 -&amp;gt; Value&#xA;&#x9;            Key2-Version1 -&amp;gt; Value&#xA;&#x9;            ……&#xA;&#x9;            KeyN-Version2 -&amp;gt; Value&#xA;&#x9;            KeyN-Version1 -&amp;gt; Value&#xA;&#x9;            ……&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意，对于同一个 Key 的多个版本，我们把版本号较大的放在前面，版本号小的放在后面，这样当用户通过一个 Key + Version 来获取 Value 的时候，可以将 Key 和 Version 构造出 MVCC 的 Key，也就是 Key-Version。然后可以直接 Seek(Key-Version)，定位到第一个大于等于这个 Key-Version 的位置。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;此处 copy 自申栎哥文章&lt;a href=&#34;https://pingcap.com/blog-cn/tidb-internal-1/&#34;&gt;三篇文章了解 TiDB 技术内幕 - 说存储&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;现在从代码看起：&lt;/p&gt;&#xA;&lt;p&gt;我们来看 TiKV 的 Storage pkg，可以看到这个 pkg 里面有个 MVCC pkg，没错具体的 MVCC 操作实现就是定义在 MVCC 这个 pkg 里面。&lt;/p&gt;&#xA;&lt;h3 id=&#34;-storage&#34;&gt;先看 Storage&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;pub struct Storage {&#xA;    engine: Box&amp;lt;Engine&amp;gt;,&#xA;    sendch: SyncSendCh&amp;lt;Msg&amp;gt;,&#xA;    handle: Arc&amp;lt;Mutex&amp;lt;StorageHandle&amp;gt;&amp;gt;,&#xA;    ...&#xA;}&#xA;impl Storage {&#xA; pub fn start(&amp;amp;mut self, config: &amp;amp;Config) -&amp;gt; Result&amp;lt;()&amp;gt; {&#xA;        let mut handle = self.handle.lock().unwrap();&#xA;        if handle.handle.is_some() {&#xA;            return Err(box_err!(&amp;quot;scheduler is already running&amp;quot;));&#xA;        }&#xA;&#xA;        let engine = self.engine.clone();&#xA;        let builder = thread::Builder::new().name(thd_name!(&amp;quot;storage-scheduler&amp;quot;));&#xA;        let rx = handle.receiver.take().unwrap();&#xA;        let sched_concurrency = config.scheduler_concurrency;&#xA;        let sched_worker_pool_size = config.scheduler_worker_pool_size;&#xA;        let sched_pending_write_threshold = config.scheduler_pending_write_threshold.0 as usize;&#xA;        let ch = self.sendch.clone();&#xA;        let h = builder.spawn(move || {&#xA;            let mut sched = Scheduler::new(&#xA;                engine,&#xA;                ch,&#xA;                sched_concurrency,&#xA;                sched_worker_pool_size,&#xA;                sched_pending_write_threshold,&#xA;            );&#xA;            if let Err(e) = sched.run(rx) {&#xA;                panic!(&amp;quot;scheduler run err:{:?}&amp;quot;, e);&#xA;            }&#xA;            info!(&amp;quot;scheduler stopped&amp;quot;);&#xA;        })?;&#xA;        handle.handle = Some(h);&#xA;&#xA;        Ok(())&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其实 Storage 是实际接受外部指令, Storage 内包含三个字段：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Engine，数据库操作的接口，raftkv 以及 rocksdb 实现了这个接口，具体实现可以看 engine/raftkv.rs, engine/rocksdb.rs&lt;/li&gt;&#xA;&lt;li&gt;SyncSendCh, 一个 channel 内部类型是 Msg, 用来存储 scheduler event 的 channel&lt;/li&gt;&#xA;&lt;li&gt;StorageHanle, 是处理从sench 接受到指令，通过 mio 来处理 IO&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;可以看到 Storage 最后启动了调度器，然后不断的接受客户端指令，然后在传给 scheduler, 然后调度器执行相应的过程或者调用相应的异步函数。在调度器中有两种操作类型，读和写。&lt;/p&gt;&#xA;&lt;h3 id=&#34;mvcc-mvccreader&#34;&gt;MVCC MVCCReader&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;pub struct MVCCReader {&#xA; ....&#xA;}&#xA;&#xA;impl MVCCReader{&#xA;    pub fn new() {...};&#xA;    pub fn get_statistics(&amp;amp;self) -&amp;gt; &amp;amp;Statistics {...}&#xA;    pub fn set_key_only(&amp;amp;mut self, key_only: bool) {...}&#xA;    pub fn load_data(&amp;amp;mut self, key: &amp;amp;Key, ts: u64) -&amp;gt; Result&amp;lt;Value&amp;gt; {...}&#xA;    pub fn load_lock(&amp;amp;mut self, key: &amp;amp;Key) -&amp;gt; Result&amp;lt;Option&amp;lt;Lock&amp;gt;&amp;gt; {...}&#xA;    pub fn get(&amp;amp;mut self, key: &amp;amp;Key, mut ts: u64) -&amp;gt; Result&amp;lt;Option&amp;lt;Value&amp;gt;&amp;gt; {...}&#xA;    pub fn get_txn_commit_info(&#xA;        &amp;amp;mut self,&#xA;        key: &amp;amp;Key,&#xA;        start_ts: u64,&#xA;    ) -&amp;gt; Result&amp;lt;Option&amp;lt;(u64, WriteType)&amp;gt;&amp;gt; {...}&#xA;    pub fn seek_ts(&amp;amp;mut self, ts: u64) -&amp;gt; Result&amp;lt;Option&amp;lt;Key&amp;gt;&amp;gt; {...}&#xA;    pub fn seek(&amp;amp;mut self, mut key: Key, ts: u64) -&amp;gt; Result&amp;lt;Option&amp;lt;(Key, Value)&amp;gt;&amp;gt; {...}&#xA;    pub fn reverse_seek(&amp;amp;mut self, mut key: Key, ts: u64) -&amp;gt; Result&amp;lt;Option&amp;lt;(Key, Value)&amp;gt;&amp;gt; {...}&#xA;    ...&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;看 MVCCReader 结构很容易理解，各种读的操作。&lt;/p&gt;&#xA;&lt;h3 id=&#34;mvcctxn&#34;&gt;MVCCTxn&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;pub struct MVCCTxn {&#xA;    reader: MVCCReader,&#xA;    start_ts: u64,&#xA;    writes: Vec&amp;lt;Modify&amp;gt;,&#xA;    write_size: usize,&#xA;}&#xA;impl MVCCTxn {&#xA;    pub fn prewrite(&#xA;        &amp;amp;mut self,&#xA;        mutation: Mutation,&#xA;        primary: &amp;amp;[u8],&#xA;        options: &amp;amp;Options,&#xA;    ) -&amp;gt; Result&amp;lt;()&amp;gt; {...}&#xA;&#xA;    pub fn commit(&amp;amp;mut self, key: &amp;amp;Key, commit_ts: u64) -&amp;gt; Result&amp;lt;()&amp;gt; {...}&#xA;    pub fn rollback(&amp;amp;mut self, key: &amp;amp;Key) -&amp;gt; Result&amp;lt;()&amp;gt; {...}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;MVCCTxn 实现了两段提交（2-Phase Commit，2PC），整个 TiKV 事务模型的核心。在一段事务中，由两个阶段组成。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Prewrite&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;选择一个 row 作为 primary row， 余下的作为 secondary row。 对primary row 上锁. 在上锁之前，会检查是否有其他同步的锁已经上到了这个 row 上 或者是是否经有在 startTS 之后的提交操作。这两种情况都会导致冲突，一旦都冲突发生，就会回滚（rollback）。 对于 secondary row 重复以上操作。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Commit&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Rollback 在Prewrite 过程中出现冲突的话就会被调用。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Garbage Collector&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;很容易发现，如果没有垃圾收集器（Gabage Collector） 来移除无效的版本的话，数据库中就会存有越来越多的 MVCC 版本。但是我们又不能仅仅移除某个 safe point 之前的所有版本。因为对于某个 key 来说，有可能只存在一个版本，那么这个版本就必须被保存下来。在TiKV中，如果在 safe point 前存在Put 或者Delete，那么说明之后所有的 writes 都是可以被移除的，不然的话只有Delete，Rollback和Lock 会被删除。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;此处部分 copy 自&lt;a href=&#34;https://pingcap.com/blog-cn/MVCC-in-TiKV/&#34;&gt;TiKV 的 MVCC（Multi-Version Concurrency Control）机制&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;heading-5&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Two-phase_locking&#34;&gt;Two-phase locking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/60278698&#34;&gt;OCC和MVCC的区别是什么？&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-cn/tidb-internal-1/&#34;&gt;三篇文章了解 TiDB 技术内幕 - 说存储&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-cn/MVCC-in-TiKV/&#34;&gt;TiKV 的 MVCC（Multi-Version Concurrency Control）机制&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>Spanner 论文笔记</title>
    <updated>2017-11-05T00:00:00Z</updated>
    <id>tag:int64.me,2017-11-05:/2017/Spanner 论文笔记.html</id>
    <link href="http://int64.me/2017/Spanner 论文笔记.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;刚到公司的时候，记得奇哥就推荐了几篇基础论文（尴尬，目前我还没有完全看完），Spanner 论文就是其中之一，同时 TiKV 的设计架构也是受到了 Spanner 的启发，在阅读 Spanner 论文的同时，记录些东西，方便以后回顾复习...&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;结构&lt;/h2&gt;&#xA;&lt;p&gt;一套 Spanner 系统称为一个 universe, Spanner 论文上说目前 google 总共部署了三套  Spanner，一个开发，一个测试，一个线上。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-8d4d85a54036697f.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上图是 Spanner 论文上的结构图，可以看出Spanner 是由多个 zone （管理部署的基本单元） 组成，一个数据中心中可以有多个 zone。 一个 zone 包含一个 zonemaster和一百或者几千个 spanserver。zonemaster 把数据分配给 spanserver，spanserver 把数据提供给客户端。客户端使用没个 zone 上的 location proxy 来定位提供服务的 spanserver，spanerver 提供具体的服务。（TiDB 的 PD 与 TiKV 之间的配合还真是有异曲同工之妙啊）。Universe master 主要是一个控制台，它显示了关于 zone 的各种状态信息，可以用于相互之间的调试。Placement driver 会周期性地与 spanserver 进行交互，来发现那些需要被转移的数据，或者是为了满足新的副本约束条件，或者是为了进行负载均衡。&lt;/p&gt;&#xA;&lt;h3 id=&#34;spanserver-&#34;&gt;spanserver 实现&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-b99c0dffe8361eb9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;从图中可以看出，每个 spanserver 负载管理 100 - 1000 个称为 tablet 的数据结构的实例。一个 tablet 就类似于 BigTable 中的 tablet，也实现了下面的映射: &lt;code&gt;(key:string, timestamp:int64)-&amp;gt;string&lt;/code&gt; 。&lt;/p&gt;&#xA;&lt;p&gt;spanserver 不同于 bigtable 的地方在于，spanserver 其实更像一个完整关系数据库，而不是一个纯粹的键值存储，spanserver 会为每一个数据分配一个时间戳（有点类似 MVCC），tablet 的状态存储在类似于 B-树的文件集合以及 WAL（write-ahead-log)中，并且都存放在 GFS 的升级版 Colossus 文件系统之上。（感觉结构有点复杂啊，也可能是我先了解了 TiKV 的设计，有点先入为主了）。&lt;/p&gt;&#xA;&lt;p&gt;再说 tablet 的上层，从图中可以看到，是用 Paxos 状态机来做副本管理（Paxos 算饭没有仔细研究过，钥匙又地方描述的有问题，欢迎指正）。论文里面讲到，目前每个 tablet 上实现了一个 Paxos 状态机，每次写操作的时候都需要写两份数据，一份落到 tablet 的日志中，一份是写入，Paxos 的日志中，目前Paxos 的 leader 实现了支持长寿命的 leader ，简单来说就是使用了租约的机制（lease TiKV 中 Raft leader 也是如此）。写操作必须在领导者上初始化 Paxos 协议，读操作可以直接从底层的任何副本的 tablet 中访问状态信息，只要这个副本足够新。副本的集合被称为一个 Paxos group。&lt;/p&gt;&#xA;&lt;p&gt;对于每个是领导者的副本而言，每个 spanserver 会实现一个锁表来实现并发控制。这个锁表包含了两阶段锁机制的状态:它把键的值域映射到锁状态上面。注意，采用一个长寿命的 Paxos 领导者，对于有效管理锁表而言是非常关键的。在 BigTable 和 Spanner 中，我们都专门为长事务做了设计，比如，对于报表操作，可能要持续几分钟，当存在冲突时，采用乐观并发控制机制会表现出很差的性能。对于那些需要同步的操作，比如事务型的读操作，需要获得锁表中的锁，而其他类型的操作则可以不理会锁表。&lt;/p&gt;&#xA;&lt;p&gt;对于每个扮演领导者角色的副本，每个 spanserver 也会实施一个事务管理器来支持分布式事务。这个事务管理器被用来实现一个 participant leader，该组内的其他副本则是作为 participant slaves。如果一个事务只包含一个 Paxos 组(对于许多事务而言都是如此)，它就可以绕过事务管理器，因为锁表和 Paxos 二者一起可以保证事务性。如果一个事务包含了多 于一个 Paxos 组，那些组的领导者之间会彼此协调合作完成两阶段提交。其中一个参与者组，会被选为协调者，该组的 participant leader 被称为 coordinator leader，该组的 participant slaves 被称为 coordinator slaves。每个事务管理器的状态，会被保存到底层的 Paxos 组。目前 TiKV 的事务好像都走的是两阶段提交，不知到要是也搞个事务管理器效果会如何？&lt;/p&gt;&#xA;&lt;h3 id=&#34;directory&#34;&gt;directory&lt;/h3&gt;&#xA;&lt;p&gt;Spanner 对具有公共前缀的键做了一个抽象，称为 directory。目前一个 directory 是数据存放的基本单位。。属于一个目录的所有数据，都具有相同的副本配置。 当数据在不同的 Paxos 组之间进行移动时，会一个目录一个目录地转移，如下图所示。Spanner 可能会移动一个目录从而减轻一个 Paxos 组的负担，也可能会把那些被频繁地一起访问的目录都放置到同一个组中，或者会把一个目录转移到距离访问者更近的地方。当客户端操作正在进行时，也可以进行目录的转移。我们可以预期在几秒内转移 50MB 的目录。&lt;/p&gt;&#xA;&lt;p&gt;directory 是数据复制和placement配置的基本单位。spanner中负载均衡的最小单位也是 directory，同时提供方法 MoveDir 可以手动将一个 directory 移动到指定的zone&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-192ba58099b34f11.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-1&#34;&gt;数据模型&lt;/h2&gt;&#xA;&lt;p&gt;spanner的行模型是 &lt;code&gt;(key:string, timestamp:int64) -&amp;gt; row content&lt;/code&gt;，可以看到跟big table的模型最大的不同是这里强化了row的概念，不再突出column；这样spanner的timestamp是赋给整行数据的，是有物理意义的，这使得spanner更像一个实现多版本并发的数据库，而在big table中，timestamp仅仅用于保存多个版本的key-value，跟并发完全无关；我觉得这也是为什么spanner称自己为semi-relational 数据库，而big table只称自己是semi-structure 数据库的原因。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-c784a00321761682.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Spanner 的数据模型不是纯粹关系型的，它的行必须有名称。更准确地说，每个表都需 要有包含一个或多个主键列的排序集合。这种需求，让 Spanner 看起来仍然有点像键值存储: 主键形成了一个行的名称，每个表都定义了从主键列到非主键列的映射。当一个行存在时，必须要求已经给行的一些键定义了一些值(即使是 NULL)。采用这种结构是很有用的，因为这可以让应用通过选择键来控制数据的局部性。&lt;/p&gt;&#xA;&lt;h3 id=&#34;truetime-api&#34;&gt;TrueTime API&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-d1557f77c3323255.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;rueTime API 是一个非常有创意的东西，可以同步全球的时间。TT.now()可以获得一个绝对时间TTinterval，这个值和UnixTime是相同的，同时还能够得到一个误差e。TT.after(t)和TT.before(t)是基于TT.now()实现的。那这个TrueTime API实现靠的是GFS和原子钟。之所以要用两种技术来处理，是因为导致这两个技术的失败的原因是不同的。GPS会有一个天线，电波干扰会导致其失灵。原子钟很稳定。当GPS失灵的时候，原子钟仍然能保证在相当长的时间内，不会出现偏差。实际部署的时候。每个数据中心需要部署一些Master机器，其他机器上需要有一个slave进程来从Master同步。有的Master用GPS，有的Master用原子钟。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-2&#34;&gt;并发控制&lt;/h2&gt;&#xA;&lt;p&gt;Spanner使用TrueTime来控制并发，实现外部一致性。支持以下几种事务。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读写事务&lt;/li&gt;&#xA;&lt;li&gt;只读事务&lt;/li&gt;&#xA;&lt;li&gt;快照读，客户端提供时间戳&lt;/li&gt;&#xA;&lt;li&gt;快照读，客户端提供时间范围&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-91fa02b85deaedff.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上表是Spanner现在支持的事务。单独的写操作都被实现为读写事务 ； 单独的非快照被实现为只读事务。事务总有失败的时候，如果失败，对于这两种操作会自己重试，无需应用自己实现重试循环。&lt;/p&gt;&#xA;&lt;p&gt;时间戳的设计大大提高了只读事务的性能。事务开始的时候，要声明这个事务里没有写操作，只读事务可不是一个简单的没有写操作的读写事务。它会用一个系统时间戳去读，所以对于同时的其他的写操作是没有Block的。而且只读事务可以在任意一台已经更新过的replica上面读。&lt;/p&gt;&#xA;&lt;p&gt;对于快照读操作，可以读取以前的数据，需要客户端指定一个时间戳或者一个时间范围。Spanner会找到一个已经充分更新好的replica上读取。&lt;/p&gt;&#xA;&lt;p&gt;还有一个有趣的特性的是，对于只读事务，如果执行到一半，该replica出现了错误。客户端没有必要在本地缓存刚刚读过的时间，因为是根据时间戳读取的。只要再用刚刚的时间戳读取，就可以获得一样的结果。&lt;/p&gt;&#xA;&lt;h3 id=&#34;paxos-&#34;&gt;Paxos 领导者租约&lt;/h3&gt;&#xA;&lt;p&gt;Spanner 的 Paxos 实现中使用了时间化的租约，来实现长时间的领导者地位(默认是 10秒)。一个潜在的领导者会发起请求，请求时间化的租约投票，在收到指定数量的投票后，这个领导者就可以确定自己拥有了一个租约。一个副本在成功完成一个写操作后，会隐式地延期自己的租约。对于一个领导者而言，如果它的租约快要到期了，就要显示地请求租约延期。另一个领导者的租约有个时间区间，这个时间区间的起点就是这个领导者获得指定数量的投票那一刻，时间区间的终点就是这个领导者失去指定数量的投票的那一刻(因为有些投票已经过期了)。Spanner 依赖于下面这些“不连贯性”:对于每个 Paxos 组，每个 Paxos 领 导者的租约时间区间，是和其他领导者的时间区间完全隔离的。&lt;/p&gt;&#xA;&lt;p&gt;Spanner 实现允许一个 Paxos 领导者通过把 slave 从租约投票中释放出来这种方式，实现领导者的退位。为了保持这种彼此隔离的不连贯性，Spanner 会对什么时候退位做出限制。把 smax 定义为一个领导者可以使用的最大的时间戳。在退位之前，一个领导者必须等到 TT.after(smax)是真。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-3&#34;&gt;为读写事务分配时间戳&lt;/h3&gt;&#xA;&lt;p&gt;事务读和写采用两段锁协议。当所有的锁都已经获得以后，在任何锁被释放之前，就可以给事务分配时间戳。对于一个给定的事务，Spanner 会为事务分配时间戳，这个时间戳是 Paxos 分配给 Paxos 写操作的，它代表了事务提交的时间。&lt;/p&gt;&#xA;&lt;p&gt;Spanner 依赖下面这些单调性:在每个 Paxos 组内，Spanner 会以单调增加的顺序给每个 Paxos 写操作分配时间戳，即使在跨越多个领导者时也是如此。一个单个的领导者副本，可以很容易地以单调增加的方式分配时间戳。在多个领导者之间就会强制实现彼此隔离的不连 贯:一个领导者必须只能分配属于它自己租约时间区间内的时间戳。要注意到，一旦一个时间戳 s 被分配，smax 就会被增加到 s，从而保证彼此隔离性(不连贯性)。&lt;/p&gt;&#xA;&lt;p&gt;Spanner 也会实现下面的外部一致性:如果一个事务 T2 在事务 T1 提交以后开始执行， 那么，事务 T2 的时间戳一定比事务 T1 的时间戳大。对于一个事务 Ti 而言，定义开始和提交事件eistart和eicommit，事务提交时间为si。对外部一致性的要求就变成了:&lt;br&gt;&#xA;tabs(e1commit )&amp;lt;tabs(e2start ) s1&amp;lt;s2。执行事务的协议和分配时间戳的协议，遵守两条规则，二者一起保证外部一致性。对于一个写操作 Ti 而言，担任协调者的领导者发出的提交请求的事件为eiserver 。&lt;/p&gt;&#xA;&lt;p&gt;Start. 为一个事务 Ti 担任协调者的领导者分配一个提交时间戳 si，不会小于 TT.now().latest 的值，TT.now().latest的值是在esierver事件之后计算得到的。要注意，担任参与者的领导者， 在这里不起作用。第 4.2.1 节描述了这些担任参与者的领导者是如何参与下一条规则的实现的。&lt;/p&gt;&#xA;&lt;p&gt;Commit Wait. 担任协调者的领导者，必须确保客户端不能看到任何被 Ti 提交的数据，直到 TT.after(si)为真。提交等待，就是要确保 si 会比 Ti 的绝对提交时间小。证明如下:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/1752522-fff83c4dbdc512f1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-4&#34;&gt;读写事务&lt;/h3&gt;&#xA;&lt;p&gt;正如BigTable一样，Spanner的事务是会将所有的写操作先缓存起来，在Commit的时候一次提交。这样的话，就读不出在同一个事务中写的数据了。不过这没有关系，因为Spanner的数据都是有版本的。&lt;/p&gt;&#xA;&lt;p&gt;在读写事务中使用wound-wait算法来避免死锁。当客户端发起一个读写事务的时候，首先是读操作，他先找到相关数据的leader replica，然后加上读锁，读取最近的数据。在客户端事务存活的时候会不断的向leader发心跳，防止超时。当客户端完成了所有的读操作，并且缓存了所有的写操作，就开始了两阶段提交。客户端闲置一个coordinator group，并给每一个leader发送coordinator的id和缓存的写数据。&lt;/p&gt;&#xA;&lt;p&gt;leader首先会上一个写锁，他要找一个比现有事务晚的时间戳。通过Paxos记录。每一个相关的都要给coordinator发送他自己准备的那个时间戳。&lt;/p&gt;&#xA;&lt;p&gt;Coordinatorleader一开始也会上个写锁，当大家发送时间戳给他之后，他就选择一个提交时间戳。这个提交的时间戳，必须比刚刚的所有时间戳晚，而且还要比TT.now()+误差时间 还有晚。这个Coordinator将这个信息记录到Paxos。&lt;/p&gt;&#xA;&lt;p&gt;在让replica写入数据生效之前，coordinator还有再等一会。需要等两倍时间误差。这段时间也刚好让Paxos来同步。因为等待之后，在任意机器上发起的下一个事务的开始时间，都比如不会比这个事务的结束时间早了。然后coordinator将提交时间戳发送给客户端还有其他的replica。他们记录日志，写入生效，释放锁。&lt;/p&gt;&#xA;&lt;h3 id=&#34;heading-5&#34;&gt;只读事务&lt;/h3&gt;&#xA;&lt;p&gt;对于只读事务，Spanner首先要指定一个读事务时间戳。还需要了解在这个读操作中，需要访问的所有的读的Key。Spanner可以自动确定Key的范围。&lt;/p&gt;&#xA;&lt;p&gt;如果Key的范围在一个Paxos group内。客户端可以发起一个只读请求给group leader。leader选一个时间戳，这个时间戳要比上一个事务的结束时间要大。然后读取相应的数据。这个事务可以满足外部一致性，读出的结果是最后一次写的结果，并且不会有不一致的数据。&lt;/p&gt;&#xA;&lt;p&gt;如果Key的范围在多个Paxos group内，就相对复杂一些。其中一个比较复杂的例子是，可以遍历所有的group leaders，寻找最近的事务发生的时间，并读取。客户端只要时间戳在TT.now().latest之后就可以满足要求了。&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading-6&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://static.googleusercontent.com/media/research.google.com/zh-CN//archive/spanner-osdi2012.pdf&#34;&gt;Spanner: Google’s Globally-Distributed Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://linbingdong.com/2017/02/10/%E5%85%A8%E7%90%83%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9AGoogle%20Spanner%EF%BC%88%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%89/&#34;&gt;spnner 论文中文版&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.voidcn.com/article/p-wxiysjtf-ho.html&#34;&gt;spanner与bigtable&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.jobbole.com/28096/&#34;&gt;Google全球级分布式数据库Spanner原理&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>Leader Transfer In TiKV</title>
    <updated>2017-10-28T00:00:00Z</updated>
    <id>tag:int64.me,2017-10-28:/2017/Leader Transfer In TiKV.html</id>
    <link href="http://int64.me/2017/Leader Transfer In TiKV.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;在 TiKV 中，PD 当发现 TiKV 实例上 region 出现 leader 不均匀的时候，会尝试将 leader 从数量比较多的地方 transfer 到其地方，具体调度指令由 PD 发出，TiKV 接收到 PD 的 transfer leader 指令，调用 raft 操作执行真正操作...&lt;/p&gt;&#xA;&lt;h2 id=&#34;-pd&#34;&gt;先看 PD&lt;/h2&gt;&#xA;&lt;p&gt;PD（Placement Driver）在 TiDB 集群里面主要负责 meta 信息存储，以及管理和调度 TiKV 集群， 所有可以想象 Transfer Leader 的命令显然是有 PD 发送到 TiKV。&lt;/p&gt;&#xA;&lt;p&gt;PD 给 TiKV 发送 Transfer Leader 命令，可以分为一下两类&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;人为干预调度&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;PD 提供 pd-ctl 命令行工具，或是通过 api 接口显示的将一个 region 的 leader 调度到某一个 store 上。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; operator add transfer-leader 1 2         // 把 region 1 的 leader 调度到 store 2&#xA;&amp;gt;&amp;gt; operator add transfer-region 1 2 3 4     // 把 region 1 调度到 store 2,3,4&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;pd-ctl 实际上也是请求 PD 的api，具体请求过程略，有兴趣的同学可以去研究一下 PD 的源码。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// pd/server/coordinator.go&#xA;func (c *coordinator) sendScheduleCommand(region *core.RegionInfo, step schedule.OperatorStep) {&#xA;        log.Infof(&amp;quot;[region %v] send schedule command: %s&amp;quot;, region.GetId(), step)&#xA;        switch s := step.(type) {&#xA;        case schedule.TransferLeader:&#xA;                cmd := &amp;amp;pdpb.RegionHeartbeatResponse{&#xA;                        TransferLeader: &amp;amp;pdpb.TransferLeader{&#xA;                                Peer: region.GetStorePeer(s.ToStore),&#xA;                        },&#xA;                }&#xA;        .....&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;从上边代码可以看到，其实 PD 的调度命令是通过 heartbeat 来进行传递的，PD 和 TiKV 之间是通过 grpc 通信，当收到到这个操作指令的时候，就会调用 grpc 的send 方法，将请求发送给 TiKV。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Leader 分布不均匀或是热点过于集中，PD 自身调度&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;PD 的主要作用就是负责管理和调度 TiKV， 如果 TiKV 各个节点上出现了 leader 分布补均匀或是热点 leader 过于集中在某一个 TiKV 节点上的时候，这时候 PD 就会作出干预，进行 transfer leader 等操作。PD 是根据每个 store 或是 leader peer 发送过来的心跳包，来作统计并决定执行哪些操作，每次收到 Region Leader 发来的心跳包时，PD 都会检查是否有对这个 Region 待进行的操作，通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 自己根据当前自身状态来定。（后面两句话直接 copy 自 &lt;a href=&#34;https://pingcap.com/blog-tidb-internal-3-zh&#34;&gt;https://pingcap.com/blog-tidb-internal-3-zh&lt;/a&gt;）。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;// HandleRegionHeartbeat processes RegionInfo reports from client.&#xA;func (c *RaftCluster) HandleRegionHeartbeat(region *core.RegionInfo) error {&#xA;        if err := c.cachedCluster.handleRegionHeartbeat(region); err != nil {&#xA;                return errors.Trace(err)&#xA;        }&#xA;&#xA;        // If the region peer count is 0, then we should not handle this.&#xA;        if len(region.GetPeers()) == 0 {&#xA;                log.Warnf(&amp;quot;invalid region, zero region peer count - %v&amp;quot;, region)&#xA;                return errors.Errorf(&amp;quot;invalid region, zero region peer count - %v&amp;quot;, region)&#xA;        }&#xA;&#xA;        c.coordinator.dispatch(region)&#xA;        return nil&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个函数处理来自 leader peer 的heartbeat， &lt;code&gt;handleRegionHeartbeat&lt;/code&gt; 主要负责更相关region 的信息， 我们主要还是关系 如何发送操作指令，想当然就是 &lt;code&gt;c.coordinator.dispatch(region) &lt;/code&gt; 这个函数干的事情了。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;func (c *coordinator) dispatch(region *core.RegionInfo) {&#xA;       // Check existed operator.&#xA;       if op := c.getOperator(region.GetId()); op != nil {&#xA;               timeout := op.IsTimeout()&#xA;               if step := op.Check(region); step != nil &amp;amp;&amp;amp; !timeout {&#xA;                       operatorCounter.WithLabelValues(op.Desc(), &amp;quot;check&amp;quot;).Inc()&#xA;                       c.sendScheduleCommand(region, step)&#xA;                       return&#xA;               }&#xA;               if op.IsFinish() {&#xA;                       log.Infof(&amp;quot;[region %v] operator finish: %s&amp;quot;, region.GetId(), op)&#xA;                       operatorCounter.WithLabelValues(op.Desc(), &amp;quot;finish&amp;quot;).Inc()&#xA;                       c.removeOperator(op)&#xA;               } else if timeout {&#xA;                       log.Infof(&amp;quot;[region %v] operator timeout: %s&amp;quot;, region.GetId(), op)&#xA;                       operatorCounter.WithLabelValues(op.Desc(), &amp;quot;timeout&amp;quot;).Inc()&#xA;                       c.removeOperator(op)&#xA;               }&#xA;       }&#xA;    ....&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到这个函数，先检查是否存在已有的操作，这个 operator 可以有好多种，比如 &lt;code&gt;AddReplica、RemoveReplica、TransferLeader&lt;/code&gt;,&lt;br&gt;&#xA;如果存在检查这个操作显示是到哪一步了，如果是没有结束并且没有超时，就会使用 &lt;code&gt;sendScheduleCommand&lt;/code&gt; 通过 grpc 向这个region 在此发送此次操作。 要是以及完成或是超时分别错处响应的处理并删除这个操作。&lt;/p&gt;&#xA;&lt;p&gt;在看 PD 如何将 Transfer leader 这个 opertor 加到 &lt;code&gt;c.operators&lt;/code&gt; 里面的&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;func (l *balanceLeaderScheduler) Schedule(cluster schedule.Cluster) *schedule.Operator {&#xA;        schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;schedule&amp;quot;).Inc()&#xA;        region, newLeader := scheduleTransferLeader(cluster, l.GetName(), l.selector)&#xA;        if region == nil {&#xA;                return nil&#xA;        }&#xA;&#xA;        // Skip hot regions.&#xA;        if cluster.IsRegionHot(region.GetId()) {&#xA;                schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;region_hot&amp;quot;).Inc()&#xA;                return nil&#xA;        }&#xA;&#xA;        source := cluster.GetStore(region.Leader.GetStoreId())&#xA;        target := cluster.GetStore(newLeader.GetStoreId())&#xA;        if !shouldBalance(source, target, core.LeaderKind) {&#xA;                schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;skip&amp;quot;).Inc()&#xA;                return nil&#xA;        }&#xA;        l.limit = adjustBalanceLimit(cluster, core.LeaderKind)&#xA;        schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;new_opeartor&amp;quot;).Inc()&#xA;        step := schedule.TransferLeader{FromStore: region.Leader.GetStoreId(), ToStore: newLeader.GetStoreId()}&#xA;        return schedule.NewOperator(&amp;quot;balance-leader&amp;quot;, region.GetId(), core.LeaderKind, step)&#xA;}&#xA;&#xA;...&#xA;func (c *coordinator) runScheduler(s *scheduleController) {&#xA;        defer c.wg.Done()&#xA;        defer s.Cleanup(c.cluster)&#xA;&#xA;        timer := time.NewTimer(s.GetInterval())&#xA;        defer timer.Stop()&#xA;&#xA;        for {&#xA;                select {&#xA;                case &amp;lt;-timer.C:&#xA;                        timer.Reset(s.GetInterval())&#xA;                        if !s.AllowSchedule() {&#xA;                                continue&#xA;                        }&#xA;                        if op := s.Schedule(c.cluster); op != nil {&#xA;                                c.addOperator(op)&#xA;                        }&#xA;&#xA;                case &amp;lt;-s.Ctx().Done():&#xA;                        log.Infof(&amp;quot;%v stopped: %v&amp;quot;, s.GetName(), s.Ctx().Err())&#xA;                        return&#xA;                }&#xA;        }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到&lt;code&gt;Schedule&lt;/code&gt;这个函数最后返回的是一个 &lt;code&gt;operator&lt;/code&gt; , &lt;code&gt;runScheduler&lt;/code&gt; 调用 &lt;code&gt; c.addOperator&lt;/code&gt; 将这个&lt;code&gt;operator&lt;/code&gt; 加到&lt;code&gt;c.operators&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;-tikv&#34;&gt;在看 TiKV&lt;/h2&gt;&#xA;&lt;p&gt;接着看 TiKV 从 PD 收到 transfer leader 指令后会做哪些操作。(刚入坑 Rust，看 TiKV 还有点费劲，可能有些地方理解的有问题，还望指出来)&lt;/p&gt;&#xA;&lt;p&gt;TiKV 首先是要接受到 PD 发送的命令，来看一个函数，这个函数是用来处理 PD 发送的命令&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;fn schedule_heartbeat_receiver(&amp;amp;mut self, handle: &amp;amp;Handle) {&#xA;        let ch = self.ch.clone();&#xA;        let store_id = self.store_id;&#xA;        let f = self.pd_client&#xA;            .handle_region_heartbeat_response(self.store_id, move |mut resp| {&#xA;                let region_id = resp.get_region_id();&#xA;                let epoch = resp.take_region_epoch();&#xA;                let peer = resp.take_target_peer();&#xA;&#xA;                if resp.has_change_peer() {&#xA;                   // more&#xA;                } else if resp.has_transfer_leader() {&#xA;                    PD_HEARTBEAT_COUNTER_VEC&#xA;                        .with_label_values(&amp;amp;[&amp;quot;transfer leader&amp;quot;])&#xA;                        .inc();&#xA;&#xA;                    let mut transfer_leader = resp.take_transfer_leader();&#xA;                    info!(&#xA;                        &amp;quot;[region {}] try to transfer leader from {:?} to {:?}&amp;quot;,&#xA;                        region_id,&#xA;                        peer,&#xA;                        transfer_leader.get_peer()&#xA;                    );&#xA;                    let req = new_transfer_leader_request(transfer_leader.take_peer());&#xA;                   send_admin_request(&amp;amp;ch, region_id, epoch, peer, req, None)&#xA;                } else {&#xA;                    PD_HEARTBEAT_COUNTER_VEC.with_label_values(&amp;amp;[&amp;quot;noop&amp;quot;]).inc();&#xA;                }&#xA;            })&#xA;    // more&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这段代码很好理解，就是先从 resp 中读取到 &lt;code&gt;region_id&lt;/code&gt;、&lt;code&gt;peer&lt;/code&gt;，然后在判断要执行的操作是什么，当执行的操作是 &lt;code&gt;transfer_leader&lt;/code&gt;的时候，先是更新一下监控，然后在从 resp 中获取到 &lt;code&gt;leader&lt;/code&gt; 该 &lt;code&gt;transfer&lt;/code&gt; 到什么地方, 在然后呢，就是发送这个命令去执行了。&lt;/p&gt;&#xA;&lt;p&gt;先看启动 启动 &lt;code&gt;transfer_leader&lt;/code&gt; 函数&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pub fn transfer_leader(&amp;amp;mut self, transferee: u64) {&#xA;     let mut m = Message::new();&#xA;     m.set_msg_type(MessageType::MsgTransferLeader);&#xA;     m.set_from(transferee);&#xA;     self.raft.step(m).is_ok();&#xA; }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个函数其实很简单，先设置一下消息类型，然后获取到目标 &lt;code&gt;leader&lt;/code&gt;，&lt;code&gt;transferee&lt;/code&gt; 就是目标&lt;code&gt;leader&lt;/code&gt;，当然自己就是当前 &lt;code&gt;leader&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在看处理过程&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;fn handle_transfer_leader(&amp;amp;mut self, m: &amp;amp;Message) {&#xA;    let lead_transferee = m.get_from();&#xA;    let last_lead_transferee = self.lead_transferee;&#xA;    if last_lead_transferee.is_some() {&#xA;        if last_lead_transferee.unwrap() == lead_transferee {&#xA;            info!(&#xA;                &amp;quot;{} [term {}] transfer leadership to {} is in progress, ignores request \&#xA;                 to same node {}&amp;quot;,&#xA;                self.tag,&#xA;                self.term,&#xA;                lead_transferee,&#xA;                lead_transferee&#xA;            );&#xA;            return;&#xA;        }&#xA;        self.abort_leader_transfer();&#xA;        info!(&#xA;            &amp;quot;{} [term {}] abort previous transferring leadership to {}&amp;quot;,&#xA;            self.tag,&#xA;            self.term,&#xA;            last_lead_transferee.unwrap()&#xA;        );&#xA;    }&#xA;    if lead_transferee == self.id {&#xA;        debug!(&#xA;            &amp;quot;{} is already leader. Ignored transferring leadership to self&amp;quot;,&#xA;            self.tag&#xA;        );&#xA;        return;&#xA;    }&#xA;    // Transfer leadership to third party.&#xA;    info!(&#xA;        &amp;quot;{} [term {}] starts to transfer leadership to {}&amp;quot;,&#xA;        self.tag,&#xA;        self.term,&#xA;        lead_transferee&#xA;    );&#xA;    // Transfer leadership should be finished in one electionTimeout&#xA;    // so reset r.electionElapsed.&#xA;    self.election_elapsed = 0;&#xA;    self.lead_transferee = Some(lead_transferee);&#xA;    if self.prs[&amp;amp;m.get_from()].matched == self.raft_log.last_index() {&#xA;        self.send_timeout_now(lead_transferee);&#xA;        info!(&#xA;            &amp;quot;{} sends MsgTimeoutNow to {} immediately as {} already has up-to-date log&amp;quot;,&#xA;            self.tag,&#xA;            lead_transferee,&#xA;            lead_transferee&#xA;        );&#xA;    } else {&#xA;        self.send_append(lead_transferee);&#xA;    }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这段代码稍有点长，我们可以一步一步的来看， 首先是进行一些检查，第一步是检查是否已经有 &lt;code&gt;transfer leader&lt;/code&gt; 在执行，如果已经正在  &lt;code&gt;transfer leader&lt;/code&gt; 并且目标 &lt;code&gt;leader&lt;/code&gt; 相同的话，就退出这次操作，如果目标不同的话，那就 调用&lt;code&gt; self.abort_leader_transfer();&lt;/code&gt; 这个函数放弃上一次正在执行的 &lt;code&gt;transfer leader&lt;/code&gt;  操作。 紧接就是判断 目标 &lt;code&gt;leader&lt;/code&gt;是不是自己，要是自己那就直接退出就好了，因为不需要&lt;code&gt;transfer leader&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;下一步就是将目标leader保存在&lt;code&gt;leadTransferee&lt;/code&gt;中，标示着有&lt;code&gt;transfer&lt;/code&gt;正在进行，后续如果有请求&lt;code&gt;propose&lt;/code&gt;进来，会检查这个&lt;code&gt;lead_transferee&lt;/code&gt; 是不是存在，如果存在，其他操作就无法成功，也就是无法进行写操作。&lt;/p&gt;&#xA;&lt;p&gt;下一步就是检查 &lt;code&gt;transferee&lt;/code&gt; 和&lt;code&gt;leader&lt;/code&gt;的&lt;code&gt;log&lt;/code&gt;是否一样新&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果&lt;code&gt;log&lt;/code&gt; 一致的话就会给&lt;code&gt;transferee&lt;/code&gt;发送&lt;code&gt;MsgTimeoutNow&lt;/code&gt;类型的消息，告诉&lt;code&gt;transferee&lt;/code&gt;可以立即选主，不需要等到&lt;code&gt;election timeout&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;如果 &lt;code&gt;log&lt;/code&gt; 不一致，就会给 &lt;code&gt;lead_transferee&lt;/code&gt;  发送一个&lt;code&gt;append&lt;/code&gt; 的请求，追加 &lt;code&gt;log&lt;/code&gt;。 ，leader在收到响应 &lt;code&gt;MsgAppResp&lt;/code&gt;后,如果发现目前正处于&lt;code&gt;transfer leader&lt;/code&gt; 过程中并且 &lt;code&gt;transferee&lt;/code&gt;已经日志最新，则同样，给&lt;code&gt;transferee&lt;/code&gt;发送&lt;code&gt;MsgTimeoutNow&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6/blog-placement-driver-zh&#34;&gt;TiKV 源码解析系列 - Placement Driver&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-tidb-internal-3-zh&#34;&gt;三篇文章了解 TiDB 技术内幕 - 谈调度&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27895034&#34;&gt;etcd raft如何实现leadership transfer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/pd&#34;&gt;PD&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/tikv&#34;&gt;TiKV&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</summary>
    <author>
      <name>cwen</name>
    </author>
  </entry>
</feed>