<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>cwen</title>
  <id>http://int64.me</id>
  <updated>2017-07-05T01:10:43+08:00</updated>
  <subtitle>沉稳，不乏可爱</subtitle>
  <link href="http://int64.me"></link>
  <entry>
    <title>rust 笔记 - 结构体</title>
    <updated>2017-07-05T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-05:/2017/rust 笔记 - 结构体.html</id>
    <content type="html">&lt;p&gt;入坑 rust&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;结构体&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// 定义&#xA; struct User {&#xA;    username: String,&#xA;    email: String,&#xA;    sign_in_count: u64,&#xA;    active: bool,&#xA;}&#xA;// 声明使用&#xA;let user1 = User {&#xA;    email: String::from(&amp;quot;someone@example.com&amp;quot;),&#xA;    username: String::from(&amp;quot;someusername123&amp;quot;),&#xA;    active: true,&#xA;    sign_in_count: 1,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;为了从结构体中获取某个值，可以使用点号。如果我们只想要用户的邮箱地址，可以用user1.email。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;通过衍生 trait 增加实用功能&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#[derive(Debug)]&#xA;struct Rectangle {&#xA;    length: u32,&#xA;    width: u32,&#xA;}&#xA;&#xA;fn main() {&#xA;    let rect1 = Rectangle { length: 50, width: 30 };&#xA;&#xA;    println!(&amp;quot;rect1 is {:?}&amp;quot;, rect1); // {} Display , {:?} Debug&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;方法&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#[derive(Debug)]&#xA;struct Rectangle {&#xA;    length: u32,&#xA;    width: u32,&#xA;}&#xA;&#xA;impl Rectangle {&#xA;    fn area(&amp;amp;self) -&amp;gt; u32 {&#xA;        self.length * self.width&#xA;    }&#xA;}&#xA;&#xA;fn main() {&#xA;    let rect1 = Rectangle { length: 50, width: 30 };&#xA;&#xA;    println!(&#xA;        &amp;quot;The area of the rectangle is {} square pixels.&amp;quot;,&#xA;        rect1.area()&#xA;    );&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;方法的第一个参数可以是 &amp;amp;self / self / &amp;amp;mut self(可变引用)&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;关联函数&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;impl块的另一个好用的功能是：允许在impl块中定义不以self作为参数的函数。这被称为关联函数（associated functions），因为他们与结构体相关联。即便如此他们也是函数而不是方法，因为他们并不作用于一个结构体的实例。你已经使用过一个关联函数了：String::from。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;关联函数经常被用作返回一个结构体新实例的构造函数。例如我们可以提供一个关联函数，它接受一个维度参数并且用来作为长和宽，这样可以更轻松的创建一个正方形Rectangle而不必指定两次同样的值：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;impl Rectangle {&#xA;    fn square(size: u32) -&amp;gt; Rectangle {&#xA;        Rectangle { length: size, width: size }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;使用结构体名和::语法来调用这个关联函数：比如let sq = Rectangle::square(3);。这个方法位于结构体的命名空间中：::语法用于关联函数和模块创建的命名空间。&lt;/p&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 结构体.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>rust 笔记 - 所有权 &amp;&amp; 引用</title>
    <updated>2017-07-03T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-03:/2017/rust 笔记 - 所有权 &amp;&amp; 引用.html</id>
    <content type="html">&lt;p&gt;入坑 rust&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;所有权&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;规则：&#xA;1. 每一个值都被它的所有者（owner）变量拥有。&#xA;2. 值在任意时刻只能被一个所有者拥有。&#xA;3. 当所有者离开作用域，这个值将被丢弃。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;变量作用域&lt;/h3&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当变量进入作用域，它就是有效的。&lt;/li&gt;&#xA;&lt;li&gt;这一直持续到它离开作用域为止。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;{                      // s is not valid here, it’s not yet declared&#xA;    let s = &amp;quot;hello&amp;quot;;   // s is valid from this point forward&#xA;&#xA;    // do stuff with s&#xA;}                      // this scope is now over, and s is no longer valid&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;String 类型&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;基础类型大多数都是存储在栈上并且在离开作用域的时候被移出栈，String 类型是存储在堆上的类型，以 String 类型研究 Rust 如何清理数据都。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;先说 String 数据移动&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let s1 = String::from(&amp;quot;hello&amp;quot;);&#xA;let s2 = s1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;https://kaisery.github.io/trpl-zh-cn/img/trpl04-02.svg&#34; alt=&#34;内存操作图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;String::form 从堆上分配一块内存存储数据，然后s1指针指向数据内存，当将 s1 赋值给 s2 的时候，不会复制数据，只是将 s2 的指针同样指向之前分配的数据块，同事s1将数据的控制权移交给s2, s1也就无法被继续操作。&#xA;但是对于栈上的数据，就是会直接copy数据，并不会存在这样的控制权移交的情况。栈上的数据实际是拥有copy trait，如果一个类型拥有Copy trait，一个旧的变量在（重新）赋值后仍然可用。Rust 不允许自身或其任何部分实现了Drop trait 的类型使用Copy trait。如果我们对其值离开作用域时需要特殊处理的类型使用Copy注解，将会出现一个编译时错误。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;所有权与函数&lt;/h3&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let s = String::from(&amp;quot;hello&amp;quot;);  // s comes into scope.&#xA;&#xA;    takes_ownership(s);             // s&#39;s value moves into the function...&#xA;                                    // ... and so is no longer valid here.&#xA;    let x = 5;                      // x comes into scope.&#xA;&#xA;    makes_copy(x);                  // x would move into the function,&#xA;                                    // but i32 is Copy, so it’s okay to still&#xA;                                    // use x afterward.&#xA;&#xA;} // Here, x goes out of scope, then s. But since s&#39;s value was moved, nothing&#xA;  // special happens.&#xA;&#xA;fn takes_ownership(some_string: String) { // some_string comes into scope.&#xA;    println!(&amp;quot;{}&amp;quot;, some_string);&#xA;} // Here, some_string goes out of scope and `drop` is called. The backing&#xA;  // memory is freed.&#xA;&#xA;fn makes_copy(some_integer: i32) { // some_integer comes into scope.&#xA;    println!(&amp;quot;{}&amp;quot;, some_integer);&#xA;} // Here, some_integer goes out of scope. Nothing special happens.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;返回值与作用域&lt;/h3&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let s1 = gives_ownership();         // gives_ownership moves its return&#xA;                                        // value into s1.&#xA;&#xA;    let s2 = String::from(&amp;quot;hello&amp;quot;);     // s2 comes into scope.&#xA;&#xA;    let s3 = takes_and_gives_back(s2);  // s2 is moved into&#xA;                                        // takes_and_gives_back, which also&#xA;                                        // moves its return value into s3.&#xA;} // Here, s3 goes out of scope and is dropped. s2 goes out of scope but was&#xA;  // moved, so nothing happens. s1 goes out of scope and is dropped.&#xA;&#xA;fn gives_ownership() -&amp;gt; String {             // gives_ownership will move its&#xA;                                             // return value into the function&#xA;                                             // that calls it.&#xA;&#xA;    let some_string = String::from(&amp;quot;hello&amp;quot;); // some_string comes into scope.&#xA;&#xA;    some_string                              // some_string is returned and&#xA;                                             // moves out to the ```callfn main() {&#xA;    let s1 = String::from(&amp;quot;hello&amp;quot;);&#xA;&#xA;    let len = calculate_length(&amp;amp;s1);&#xA;&#xA;    println!(&amp;quot;The length of &#39;{}&#39; is {}.&amp;quot;, s1, len);&#xA;}&#xA;&#xA;fn calculate_length(s: &amp;amp;String) -&amp;gt; usize {&#xA;    s.len()&#xA;}&#xA;                                             // function.&#xA;}&#xA;&#xA;// takes_and_gives_back will take a String and return one.&#xA;fn takes_and_gives_back(a_string: String) -&amp;gt; String { // a_string comes into&#xA;                                                      // scope.&#xA;&#xA;    a_string  // a_string is returned and moves out to the calling function.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;引用&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let s1 = String::from(&amp;quot;hello&amp;quot;);&#xA;&#xA;    let len = calculate_length(&amp;amp;s1);&#xA;&#xA;    println!(&amp;quot;The length of &#39;{}&#39; is {}.&amp;quot;, s1, len);&#xA;}&#xA;&#xA;fn calculate_length(s: &amp;amp;String) -&amp;gt; usize {&#xA;    s.len()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;https://kaisery.github.io/trpl-zh-cn/img/trpl04-05.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;可变引用&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;使用 mut 修饰，不过可变引用有一个很大的限制：在特定作用域中的特定数据有且只有一个可变引用，我们也不能在拥有不可变引用的同时拥有可变引用。不可变引用的用户可不希望在它的眼皮底下值突然就被改变了！然而，多个不可变引用是没有问题的因为没有哪个读取数据的人有能力影响其他人读取到的数据。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;引用的规则&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;简要的概括一下对引用的讨论：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在任意给定时间，只能拥有如下中的一个:一个可变引用;任意数量的不可变引用。&lt;/li&gt;&#xA;&lt;li&gt;引用必须总是有效的。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 所有权 &amp;&amp; 引用.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>rust 笔记 - 函数 &amp;&amp; 控制流</title>
    <updated>2017-07-02T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-02:/2017/rust 笔记 - 函数 &amp;&amp; 控制流.html</id>
    <content type="html">&lt;p&gt;入坑 rust&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;函数&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Rust 代码使用 snake case 作为函数和变量名称的规范风格，在 snake case 中，所有字母都是小写并使用下划线分隔单词。Rust 中的函数定义以fn开始并在函数名后跟一对括号。大括号告诉编译器哪里是函数体的开始和结尾。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    another_function(5);&#xA;}&#xA;&#xA;fn another_function(x: i32) {&#xA;    println!(&amp;quot;The value of x is: {}&amp;quot;, x);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;语句和表达式&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;语句执行一些操作但不返回的指令&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let x = 4;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;表达式计算并产生一个值。函数调用是一个表达式。宏调用是一个表达式。我们用来创新建作用域的大括号（代码块），{}，也是一个表达式&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let x = 5;&#xA;&#xA;    let y = {&#xA;        let x = 3;&#xA;        x + 1&#xA;    };&#xA;&#xA;    println!(&amp;quot;The value of y is: {}&amp;quot;, y);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;函数返回值&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;可以向调用它的代码返回值。并不对返回值命名，不过会在一个箭头（-&amp;gt;）后声明它的类型。在 Rust 中，函数的返回值等同于函数体最后一个表达式的值。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn five() -&amp;gt; i32 {&#xA;    5&#xA;}&#xA;&#xA;fn main() {&#xA;    let x = five();&#xA;&#xA;    println!(&amp;quot;The value of x is: {}&amp;quot;, x);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;if 表达式&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;与大多数编程语言类似，if 用来控制分支，代码中的条件必须是bool&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let number = 6;&#xA;    if number % 4 == 0 {&#xA;        println!(&amp;quot;number is divisible by 4&amp;quot;);&#xA;    } else if number % 3 == 0 {&#xA;        println!(&amp;quot;number is divisible by 3&amp;quot;);&#xA;    } else if number % 2 == 0 {&#xA;        println!(&amp;quot;number is divisible by 2&amp;quot;);&#xA;    } else {&#xA;        println!(&amp;quot;number is not divisible by 4, 3, or 2&amp;quot;);&#xA;    }&#xA;    // 当 else if 过多的时候就该尝试重构代码了(match替换)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;来点不一样的，let 语句中使用 if&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let condition = true;&#xA;    let number = if condition {&#xA;        5&#xA;    } else {&#xA;        6&#xA;    };&#xA;    println!(&amp;quot;The value of number is: {}&amp;quot;, number);&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;注意点： if的每个分支的可能的返回值都必须是相同类型；&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;循环&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Rust 有三种循环类型：loop、while和for。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;loop 循环&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;loop关键字告诉 Rust 一遍又一遍的执行一段代码直到你明确要求停止(比如break)。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let mut index = 0;&#xA;    loop {&#xA;        println!(&amp;quot;again!&amp;quot;);&#xA;        index = index + 1;&#xA;        if index &amp;gt;= 10 {&#xA;            println!(&amp;quot;done&amp;quot;);&#xA;            break;&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;while 循环 &amp;amp;&amp;amp; for 循环&lt;/h3&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let a = [10, 20, 30, 40, 50];&#xA;    let mut index = 0;&#xA;    // while 循环&#xA;    while index &amp;lt; 5 {&#xA;        println!(&amp;quot;the value is: {}&amp;quot;, a[index]);&#xA;&#xA;        index = index + 1;&#xA;    }&#xA;    // for 循环&#xA;    for element in a.iter() {&#xA;        println!(&amp;quot;the value is: {}&amp;quot;, element);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 函数 &amp;&amp; 控制流.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>rust 笔记 - 变量 &amp;&amp; 数据类型</title>
    <updated>2017-07-02T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-02:/2017/rust 笔记 - 变量 &amp;&amp; 数据类型.html</id>
    <content type="html">&lt;p&gt;入坑 rust&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;变量&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;rust 变量默认不可变，使用 let 声明，当改变强制改变的时候，rust编译器将报错&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let x = 5;&#xA;    println!(&amp;quot; x = {}&amp;quot;, x);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;通过变量名之前加 mut 来使变量可变&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let mut x = 5;&#xA;    println!(&amp;quot;The value of x is: {}&amp;quot;, x);&#xA;    x = 6;&#xA;    println!(&amp;quot;The value of x is: {}&amp;quot;, x);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;常量&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;使用 const 声明， 绑定到一个名称不允许改变的值&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;const MAX_POINTS: u32 = 100_000;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;与变量的区别：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不允许对常量使用 mut：常量不光默认不能变，它总是不能变。&lt;/li&gt;&#xA;&lt;li&gt;声明常量使用 const 关键字而不是 let，而且必须注明值的类型。&lt;/li&gt;&#xA;&lt;li&gt;常量可以在任何作用域声明，包括全局作用域，这在一个值需要被很多部分的代码用到时很有用。&lt;/li&gt;&#xA;&lt;li&gt;最后一个区别是常量只能用于常量表达式，而不能作为函数调用的结果，或任何其他只在运行时计算的值。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;数据类型&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Rust 有四种基本的标量类型：整型、浮点型、布尔类型和字符类型， Rust 有两个原生的复合类型：元组（tuple）和数组（array）。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;元组&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;元组可以将其他类型组合进一个复合类型的主要方式。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let tup: (i32, f64, u8) = (500, 6.4, 1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;tup变量绑定了整个元组，因为元组被认为是一个单独的复合元素。为了从元组中获取单个的值，可以使用模式匹配（pattern matching）来解构（destructure ）元组，像这样：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let tup = (500, 6.4, 1);&#xA;&#xA;    let (x, y, z) = tup;&#xA;&#xA;    println!(&amp;quot;The value of y is: {}&amp;quot;, y);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;除了使用模式匹配解构之外，也可以使用点号（.）后跟值的索引来直接访问他们。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;数组&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;另一个获取一个多个值集合的方式是数组（array）。与元组不同，数组中的每个元素的类型必须相同。Rust 中的数组与一些其他语言中的数组不同，因为 Rust 中的数组是固定长度的：一旦声明，他们的长度不能增长或缩小。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rust 中数组的值位于中括号中的逗号分隔的列表中：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let a = [1, 2, 3, 4, 5];&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 变量 &amp;&amp; 数据类型.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>mysql 配置半同步复制</title>
    <updated>2017-03-16T00:00:00Z</updated>
    <id>tag:int64.me,2017-03-16:/2017/mysql 配置半同步复制.html</id>
    <content type="html">&lt;p&gt;整理一下 mysql 开启半同步复制的操作步骤&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;配置异步复制&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;示例 IP&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;12.34.56.789- Master Database&#xA;12.23.34.456- Slave Database&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;配置 master&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;修改配置文件&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sudo vim /etc/mysql/my.conf&#xA;&#xA;// 修改以下配置&#xA;server-id               = 1&#xA;log_bin                 = /var/log/mysql/mysql-bin.log&#xA;binlog_do_db            = newdatabase  // 可选 ; 设置同步的数据库&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;当然这些参数你也可以在 mysql 客户端修改 eg: set global server_id=1;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;重启 mysql&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sudo service mysql restart&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;设置给给予从库权限&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;GRANT REPLICATION SLAVE ON *.* TO &#39;slave_user&#39;@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;&#xA;FLUSH PRIVILEGES;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;读取 master binlog pos&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SHOW MASTER STATUS;&#xA;+------------------+----------+--------------+------------------+&#xA;| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |&#xA;+------------------+----------+--------------+------------------+&#xA;| mysql-bin.000001 |      107 | newdatabase  |                  |&#xA;+------------------+----------+--------------+------------------+&#xA;1 row in set (0.00 sec)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;如果同步的数据库有数据, 先从master dump-&amp;gt;load进 slave; 这样做的时候 binlog pos 读取 dump 文件上&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;配置 slave&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;先创建需要同步的 database&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;CREATE DATABASE newdatabase;&#xA;EXIT;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;修改配置文件&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sudo vim /etc/mysql/my.conf&#xA;&#xA;// 修改以下配置&#xA;server-id               = 2    // 区别 master&#xA;relay-log               = /var/log/mysql/mysql-relay-bin.log&#xA;log_bin                 = /var/log/mysql/mysql-bin.log&#xA;binlog_do_db            = newdatabase&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;重启 mysql&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sudo service mysql restart&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;设置 slave 同步master binlog pos&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;CHANGE MASTER TO MASTER_HOST=&#39;12.34.56.789&#39;,MASTER_USER=&#39;slave_user&#39;, MASTER_PASSWORD=&#39;password&#39;, MASTER_LOG_FILE=&#39;mysql-bin.000001&#39;, MASTER_LOG_POS=  107;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;开启同步&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;START SLAVE;&#xA;&#xA;// 检查同步是否成功&#xA;SHOW SLAVE STATUS\G&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;如果在连接的问题，你可以尝试从开始使用命令跳过它&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1; SLAVE START;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;开启半同步&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;master install 半同步插件&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; install plugin rpl_semi_sync_master soname &#39;semisync_master.so&#39;;&#xA;// 查看是否加载插件&#xA;mysql&amp;gt; show plugins;&#xA;rpl_semi_sync_master   | ACTIVE  | REPLICATION     | semisync_master.so | GPL&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;slave install 半同步插件&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; install plugin rpl_semi_sync_slave soname &#39;semisync_slave.so&#39;;&#xA;&#xA;// 查看是否加载插件&#xA;mysql&amp;gt; show plugins;&#xA;rpl_semi_sync_slave    | ACTIVE  | REPLICATION    | semisync_slave.so | GPL&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;启动插件&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// master&#xA;set global rpl_semi_sync_master_enabled = on;&#xA;&#xA;// slave&#xA;set global rpl_semi_sync_slave_enabled = on;&#xA;stop slave IO_THREAD;&#xA;start slave IO_THREAD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;检查状态&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;show status like &#39;%Rpl_semi_sync%&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;解释几个重要的&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Rpl_semi_sync_master_status&#x9;是否启用了半同步&#xA;Rpl_semi_sync_master_clients&#x9;半同步模式下Slave一共有多少个&#xA;Rpl_semi_sync_master_no_tx&#x9;往slave发送失败的事务数量&#xA;Rpl_semi_sync_master_yes_tx&#x9;往slave发送成功的事务数量&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;半同步几个参数设置&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;show variables like &#39;%Rpl%&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;参数解释&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;rpl_semi_sync_master_timeout&#x9;Master等待slave响应的时间，单位是毫秒，默认值是10秒，超过这个时间，slave无响应，环境架构将自动转换为异步复制&#xA;rpl_semi_sync_master_trace_level&#x9;监控等级，一共4个等级（1,16,32,64），后续补充详细。&#xA;rpl_semi_sync_master_wait_no_slave&#x9;是否允许master 每个事物提交后都要等待slave的receipt信号。默认为on ，每一个事务都会等待，如果slave当掉后，当slave追赶上master的日志时，可以自动的切换为半同步方式，如果为off,则slave追赶上后，也不会采用半同步的方式复制了，需要手工配置。&#xA;rpl_stop_slave_timeout&#xA;控制stop slave 的执行时间，在重放一个大的事务的时候,突然执行stop slave ,命令 stop slave会执行很久,这个时候可能产生死锁或阻塞,严重影响性能，mysql 5.6可以通过rpl_stop_slave_timeout参数控制stop slave 的执行时间&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-master-slave-replication-in-mysql&#34;&gt;How To Set Up Master Slave Replication in MySQL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.mamicode.com/info-detail-576734.html&#34;&gt;Mysql5.6.21半同步&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/mysql 配置半同步复制.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>sysbench的一点整理</title>
    <updated>2017-02-09T00:00:00Z</updated>
    <id>tag:int64.me,2017-02-09:/2017/sysbench的一点整理.html</id>
    <content type="html">&lt;p&gt;还记得刚到公司的第一个任务就是搞性能测试，断断续续也是搞了很久，sysbench这个工具也是用了有一段时间了，不敢说熟练，但是也是踩了一些坑，在此做些整理，欢迎诸位指正补充&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;sysbench主要包括一下几种方式的测试：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;cpu性能&lt;/li&gt;&#xA;&lt;li&gt;磁盘io性能&lt;/li&gt;&#xA;&lt;li&gt;调度程序性能&lt;/li&gt;&#xA;&lt;li&gt;内存分配及传输速度&lt;/li&gt;&#xA;&lt;li&gt;POSIX线程性能&lt;/li&gt;&#xA;&lt;li&gt;数据库性能(OLTP基准测试)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h2&gt;先说安装&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;一般我是直接从github上copy下来，自己编译&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/akopytov/sysbench.git&#xA;// 如果使用0.5 版本: git branch 0.5&#xA;./autogen.sh&#xA;./configure&#xA;make&#xA;make install&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;详细安装说明参考 &lt;a href=&#34;https://github.com/akopytov/sysbench&#34;&gt;readme&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;只说 oltp&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;sysbench 的 oltp 主要用于评估测试各种不同系统参数下的数据库负载情况。目前sysbench的数据库测试支持 Mysql、PostgreSQL、Oracle (我的任务主要是做 mysql &amp;amp; tidb 的对比测试), 相比 0.4 版本，后续的版本 oltp 测试主要结合了 lua 脚本，不需要修改源码，通过自定义lua脚本就可以实现不同业务类型的测试。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;参数&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;sysbench 版本&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sysbench --version&#xA;sysbench 1.0.1-7fe53e4　       　&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;具体参数&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sysbench --help&#xA;Usage:&#xA;  sysbench [options]... [testname] [command]&#xA;&#xA;Commands implemented by most tests: prepare run cleanup help&#xA;&#xA;General options:&#xA;  --threads=N                     创建测试线程的数量, 默认为 1&#xA;  --events=N                      事件最大数量,默认为 0 ,不限制&#xA;  --time=N                        最大执行时间，单位是 s ,默认是 0 ,不限制&#xA;  --forced-shutdown=STRING        超过max-time强制中断, 默认是 off&#xA;  --thread-stack-size=SIZE        每个线程的堆栈大小, 默认是 64k&#xA;  --rate=N                        average transactions rate. 0 for unlimited rate [0]&#xA;  --report-interval=N             报告中间统计信息间隔, 0 代表禁止, 默认为 0&#xA;  --report-checkpoints=[LIST,...] 转储完全统计信息并在指定时间点复位所有计数器。 参数是逗号分隔值的列表，表示从必须执行报告检查点的测试开始所经过的时间（以秒为单位）。 默认情况下，报告检查点处于关闭状态&#xA;  --debug[=on|off]                是否显示更多的调试信息, 默认是off&#xA;  --validate[=on|off]             在可能情况下执行验证检查, 默认是off。&#xA;  --help[=on|off]                 输出 help 信息, 并退出&#xA;  --version[=on|off]              输出版本信息, 并退出&#xA;  --config-file=FILENAME          配置文件&#xA;  --tx-rate=N                     deprecated alias for --rate [0]&#xA;  --max-requests=N                deprecated alias for --events [0]&#xA;  --max-time=N                    deprecated alias for --time [0]&#xA;  --num-threads=N                 deprecated alias for --threads [1]&#xA;&#xA;Pseudo-Random Numbers Generator options:&#xA;  --rand-type=STRING 分布的随机数{uniform(均匀分布),Gaussian(高斯分布),special(空间分布)}。默认是special&#xA;  --rand-spec-iter=N 产生数的迭代次数。默认是12&#xA;  --rand-spec-pct=N  值的百分比被视为’special’ (for special distribution)。默认是1&#xA;  --rand-spec-res=N  &#39;special&#39;的百分比值。默认是75&#xA;  --rand-seed=N      seed for random number generator. When 0, the current time is used as a RNG seed. [0]&#xA;  --rand-pareto-h=N  参数h用于 pareto 分布[0.2]&#xA;&#xA;Log options:&#xA;  --verbosity=N verbosity level {5 - debug, 0 - only critical messages} [3]&#xA;&#xA;  --percentile=N       percentile to calculate in latency statistics (1-100). Use the special value of 0 to disable percentile calculations [95]&#xA;  --histogram[=on|off] print latency histogram in report [off]&#xA;&#xA;General database options:&#xA;&#xA;  --db-driver=STRING  specifies database driver to use (&#39;help&#39; to get list of available drivers)&#xA;  --db-ps-mode=STRING prepared statements usage mode {auto, disable} [auto]&#xA;  --db-debug[=on|off] print database-specific debug information [off]&#xA;General database options:&#xA;&#xA;  --db-driver=STRING  specifies database driver to use (&#39;help&#39; to get list of available drivers)&#xA;  --db-ps-mode=STRING prepared statements usage mode {auto, disable} [auto]&#xA;  --db-debug[=on|off] print database-specific debug information [off]&#xA;&#xA;&#xA;Compiled-in database drivers:&#xA;  mysql - MySQL driver&#xA;&#xA;mysql options:&#xA;  --mysql-host=[LIST,...]          MySQL server host [localhost]&#xA;  --mysql-port=[LIST,...]          MySQL server port [3306]&#xA;  --mysql-socket=[LIST,...]        MySQL socket&#xA;  --mysql-user=STRING              MySQL user [sbtest]&#xA;  --mysql-password=STRING          MySQL password []&#xA;  --mysql-db=STRING                MySQL database name [sbtest]&#xA;  --mysql-ssl[=on|off]             use SSL connections, if available in the client library [off]&#xA;  --mysql-ssl-cipher=STRING        use specific cipher for SSL connections []&#xA;  --mysql-compression[=on|off]     use compression, if available in the client library [off]&#xA;  --mysql-debug[=on|off]           trace all client library calls [off]&#xA;  --mysql-ignore-errors=[LIST,...] list of errors to ignore, or &amp;quot;all&amp;quot; [1213,1020,1205]&#xA;  --mysql-dry-run[=on|off]         Dry run, pretend that all MySQL client API calls are successful without executing them [off]&#xA;&#xA;Compiled-in tests:&#xA;  fileio - File I/O test&#xA;  cpu - CPU performance test&#xA;  memory - Memory functions speed test&#xA;  threads - Threads subsystem performance test&#xA;  mutex - Mutex performance test&#xA;&#xA;See &#39;sysbench &amp;lt;testname&amp;gt; help&#39; for a list of options for each test.&#xA;&#xA;sysbench ./lua/oltp_read_write.lua help&#xA;&#xA;oltp_read_write.lua options:&#xA;  --distinct_ranges=N           Number of SELECT DISTINCT queries per transaction [1]&#xA;  --sum_ranges=N                Number of SELECT SUM() queries per transaction [1]&#xA;  --skip_trx[=on|off]           Don&#39;t start explicit transactions and execute all queries as in the AUTOCOMMIT mode [off]&#xA;  --secondary[=on|off]          Use a secondary index in place of the PRIMARY KEY [off]&#xA;  --create_secondary[=on|off]   Create a secondary index in addition to the PRIMARY KEY [on]&#xA;  --index_updates=N             Number of UPDATE index queries per transaction [1]&#xA;  --range_size=N                Range size for range SELECT queries [100]&#xA;  --auto_inc[=on|off]           Use AUTO_INCREMENT column as Primary Key (for MySQL), or its alternatives in other DBMS. When disabled, use client-generated IDs [on]&#xA;  --delete_inserts=N            Number of DELETE/INSERT combination per transaction [1]&#xA;  --tables=N                    Number of tables [1]&#xA;  --mysql_storage_engine=STRING Storage engine, if MySQL is used [innodb]&#xA;  --non_index_updates=N         Number of UPDATE non-index queries per transaction [1]&#xA;  --table_size=N                Number of rows per table [10000]&#xA;  --pgsql_variant=STRING        Use this PostgreSQL variant when running with the PostgreSQL driver. The only currently supported variant is &#39;redshift&#39;. When enabled, create_secondary is automatically disabled, and delete_inserts is set to 0&#xA;  --simple_ranges=N             Number of simple range SELECT queries per transaction [1]&#xA;  --order_ranges=N              Number of SELECT ORDER BY queries per transaction [1]&#xA;  --range_selects[=on|off]      Enable/disable all range SELECT queries [on]&#xA;  --point_selects=N             Number of point SELECT queries per transaction [10]&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;参数太多实在不想一句句翻译了&amp;hellip;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;开测&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;sysbench的测试流程&lt;/p&gt;&#xA;&#xA;&lt;p&gt;prepare(准备数据) -&amp;gt; run(运行测试) -&amp;gt; cleanup(清理数据)&#xA;目前社区提供的lua脚步&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;bulk_insert.lua&#xA;oltp_common.lua&#xA;oltp_delete.lua&#xA;oltp_insert.lua&#xA;oltp_point_select.lua&#xA;oltp_read_only.lua&#xA;oltp_read_write.lua&#xA;oltp_update_index.lua&#xA;oltp_update_non_index.lua&#xA;oltp_write_only.lua&#xA;select_random_points.lua&#xA;select_random_ranges.lua&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;以 &lt;code&gt;oltp_read_only.lua&lt;/code&gt; 为例&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;./sysbench ./lua/oltp_read_only.lua \&#xA;    --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=root --mysql-password=000000 \&#xA;    --mysql-db=test --tables=10 --table-size=10000 \&#xA;    --report-interval=10 \&#xA;    --threads=128 --time=120 \&#xA;    prepare/run/cleanup&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;结果解读&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;sysbench 1.0.1-7fe53e4 (using bundled LuaJIT 2.1.0-beta2)&#xA;&#xA;Running the test with following options:&#xA;Number of threads: 128&#xA;Report intermediate results every 10 second(s)&#xA;Initializing random number generator from current time&#xA;&#xA;&#xA;Initializing worker threads...&#xA;&#xA;Threads started!&#xA;&#xA;[ 10s ] thds: 128 tps: 1208.30 qps: 19436.82 (r/w/o: 17007.47/0.00/2429.35) lat (ms,95%): 158.63 err/s: 0.00 reconn/s: 0.00&#xA;[ 20s ] thds: 128 tps: 1264.26 qps: 20233.57 (r/w/o: 17705.05/0.00/2528.52) lat (ms,95%): 153.02 err/s: 0.00 reconn/s: 0.00&#xA;[ 30s ] thds: 128 tps: 1273.70 qps: 20375.11 (r/w/o: 17827.81/0.00/2547.30) lat (ms,95%): 150.29 err/s: 0.00 reconn/s: 0.00&#xA;[ 40s ] thds: 128 tps: 1287.20 qps: 20598.39 (r/w/o: 18023.89/0.00/2574.50) lat (ms,95%): 147.61 err/s: 0.00 reconn/s: 0.00&#xA;[ 50s ] thds: 128 tps: 1281.13 qps: 20491.35 (r/w/o: 17929.10/0.00/2562.26) lat (ms,95%): 150.29 err/s: 0.00 reconn/s: 0.00&#xA;[ 60s ] thds: 128 tps: 1267.04 qps: 20276.48 (r/w/o: 17742.41/0.00/2534.07) lat (ms,95%): 150.29 err/s: 0.00 reconn/s: 0.00&#xA;[ 70s ] thds: 128 tps: 1257.80 qps: 20127.47 (r/w/o: 17611.96/0.00/2515.51) lat (ms,95%): 153.02 err/s: 0.00 reconn/s: 0.00&#xA;[ 80s ] thds: 128 tps: 1243.93 qps: 19894.40 (r/w/o: 17406.43/0.00/2487.96) lat (ms,95%): 155.80 err/s: 0.00 reconn/s: 0.00&#xA;[ 90s ] thds: 128 tps: 1237.60 qps: 19807.67 (r/w/o: 17332.67/0.00/2475.00) lat (ms,95%): 155.80 err/s: 0.00 reconn/s: 0.00&#xA;[ 100s ] thds: 128 tps: 1053.60 qps: 16850.29 (r/w/o: 14742.89/0.00/2107.40) lat (ms,95%): 193.38 err/s: 0.00 reconn/s: 0.00&#xA;[ 110s ] thds: 128 tps: 1001.41 qps: 16021.33 (r/w/o: 14018.60/0.00/2002.73) lat (ms,95%): 207.82 err/s: 0.00 reconn/s: 0.00&#xA;[ 120s ] thds: 128 tps: 859.76 qps: 13750.85 (r/w/o: 12034.73/0.00/1716.12) lat (ms,95%): 235.74 err/s: 0.00 reconn/s: 0.00&#xA;SQL statistics:&#xA;    queries performed:&#xA;        read:                            1994860    // 总 select 数量&#xA;        write:                           0          // 总update、insert、delete语句数量&#xA;        other:                           284980     //commit、unlock tables以及其他mutex的数量&#xA;        total:                           2279840&#xA;    transactions:                        142490 (1186.20 per sec.)   //通常需要关注的数字(TPS)&#xA;    queries:                             2279840 (18979.13 per sec.) //通常需要关注的数字(QPS)&#xA;    ignored errors:                      0      (0.00 per sec.)  //忽略的错误数&#xA;    reconnects:                          0      (0.00 per sec.)&#xA;&#xA;General statistics:&#xA;    total time:                          120.1216s  //即time指定的压测实际&#xA;    total number of events:              142490     //总的事件数，一般与transactions相同&#xA;&#xA;Latency (ms):&#xA;         min:                                  8.52&#xA;         avg:                                107.84&#xA;         max:                                480.08&#xA;         95th percentile:                    170.48  //95%的语句的平均响应时间&#xA;         sum:                            15365843.76&#xA;&#xA;Threads fairness:&#xA;    events (avg/stddev):           1113.2031/14.76&#xA;    execution time (avg/stddev):   120.0457/0.04&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;我们一般关注的指标主要有:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;response time avg: 平均响应时间。（后面的95%的大小可以通过&amp;ndash;percentile=98的方式去更改）&lt;/li&gt;&#xA;&lt;li&gt;transactions: 精确的说是这一项后面的TPS 。但如果使用了-skip-trx=on，这项事务数恒为0，需要用total number of events 去除以总时间，得到tps（其实还可以分为读tps和写tps）&lt;/li&gt;&#xA;&lt;li&gt;queries: 用它除以总时间，得到吞吐量QPS&lt;/li&gt;&#xA;&lt;li&gt;当然还有一些系统层面的cpu,io,mem相关指标&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;建议&lt;/h3&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;sysbench 在最近刚升级了最新版(以上使用的就是最新版),有很多改进之处,让我最惊喜的是prepare数据相比之前变为多线程,准备数据更快, 降低了在prepare数据上耗费的时间(虽然之前自己用别的办法加速prepare数据,但是方法比较挫,这里就不做介绍了)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;注意新版本相比 1.0 和 0.5 有许多参数的改变&#xA;当然你也可以指定自己定义的lua脚步,实现不同业务类型的测试&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/akopytov/sysbench&#34;&gt;github doc&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://mingxinglai.com/cn/2013/07/sysbench/&#34;&gt;sysbench 0.5使用手册&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://seanlook.com/2016/03/28/mysql-sysbench/&#34;&gt;使用sysbench对mysql压力测试&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/sysbench的一点整理.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>负载均衡的一点整理</title>
    <updated>2016-11-25T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-25:/2016/负载均衡的一点整理.html</id>
    <content type="html">&lt;p&gt;刚接到一个调研各云厂商的负载均衡情况的小任务，可是小菜鸟对与负载均衡也是一知半解,就先花点时间冲冲电&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;从单机网站到分布式网站，很重要的区别就是业务拆分以及分布式部署，但是每个部署的独立业务还存在单点的问题和访问统一入口问题，为解决单点故障，我们可以采取冗余的方式。将相同的应用部署到多台机器上。解决访问统一入口问题，我们可以在集群前面增加负载均衡设备，实现流量分发。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;解决的问题&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;提供故障转移，实现高可用；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;通过添加或减少服务器数量，提供网站伸缩性（扩展性）；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;原理 : 其实就是根据一些转发算法，讲请求分发到不同的节点上去执行&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;负载均衡原理&lt;/h2&gt;&#xA;&#xA;&lt;h4&gt;DNS&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;通过使用域名解析实现负载均衡，配置多个A 记录，这些A记录对应的服务器构成集群。大型网站总是部分使用DNS解析，作为第一级负载均衡。 显而易见，使用这种方式的负载均衡的控制权更在域名商那里，不易拓展，并且用这种方式的负载不能很好的分流，有可能造成所有的请求都集中到一个节点上，但是作为第一层的负载均衡的确是个好办法。　　　　&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;HTTP&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;当http代理（比如浏览器）向web服务器请求某个URL后，web服务器可以通过http响应头信息中的Location标记来返回一个新的URL。这意味着HTTP代理需要继续请求这个新的URL，完成自动跳转。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;IP&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;在网络层通过修改请求目标地址进行负载均衡。&#xA;用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为，获得的真实ip地址，不需要经过用户进程处理。&#xA;真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的ip地址，发送给用户浏览器。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213195925966-1272593644.png&#34; alt=&#34;示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;链路层&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;在通信协议的数据链路层修改mac地址，进行负载均衡。&#xA;数据分发时，不修改ip地址，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。&#xA;实际处理服务器ip和数据请求目的ip一致，不需要经过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR模式）。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;混合　　&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;其实这就显而易见了，当单一的负载均衡方式无法很好的解决现有的问题，那么我们就可以把他们结合在一起使用，这也很符合当下的发展潮流啊&amp;hellip;   具体的结合方式有很多，例如　我们可以考虑分层，在每一层采用不同的方式来进行负载均衡，在最外层使用&#xA;DNS负载均衡，在使用反向代理来做缓存以及动态请求分发 ，最后在是应用负载均衡(IP/DR), 分流到对应的应用集群　　&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213200106747-94797427.png&#34; alt=&#34;混合一&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213200117825-1452672107.png&#34; alt=&#34;混合二&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;具体实现　　　&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;四层　　&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;LVS  (Linux Virtual Server) 基于IP层的负载均衡调度技术，它在操作系统核心层上，将来自IP层的TCP/UDP请求均衡地转移到不同的 服务器，从而将一组服务器构成一个高性能、高可用的虚拟服务器。&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;抗负载能力强，因为lvs工作方式的逻辑是非常之简单，而且工作在网络4层仅做请求分发之用，没有流量，所以在效率上基本不需要太过考虑。&lt;/li&gt;&#xA;&lt;li&gt;配置性低，这通常是一大劣势，但同时也是一大优势，因为没有太多可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。&lt;/li&gt;&#xA;&lt;li&gt;工作稳定，因为其本身抗负载能力很强，所以稳定性高也是顺理成章，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，节点出现故障的话，lvs会自动判别，所以系统整体是非常稳定的。&lt;/li&gt;&#xA;&lt;li&gt;无流量，上面已经有所提及了。lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。&lt;/li&gt;&#xA;&lt;li&gt;基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等.&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;日PV小于1000万，的时候不需要考虑 LVS , 大多时候LVS + Keepalived配合使用(阿里云),LVS提 供负载均衡，keepalived提供健康检查，故障转移，提高系统的可用性！采用这样的架构以后 很容易对现有系统进行扩展，只要在后端添加或者减少realserver，只要更改lvs的 配置文件，并能实现无缝配置变更！。　　&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;七层　&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;HaProxy&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;HAProxy是工作在网络7层之上。&lt;/li&gt;&#xA;&lt;li&gt;能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作&lt;/li&gt;&#xA;&lt;li&gt;支持url检测后端的服务器出问题的检测会有很好的帮助。&lt;/li&gt;&#xA;&lt;li&gt;更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现&lt;/li&gt;&#xA;&lt;li&gt;单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。&lt;/li&gt;&#xA;&lt;li&gt;HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nignx&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；&lt;/li&gt;&#xA;&lt;li&gt;Nginx对网络的依赖比较小；&lt;/li&gt;&#xA;&lt;li&gt;Nginx安装和配置比较简单，测试起来比较方便；&lt;/li&gt;&#xA;&lt;li&gt;也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；&lt;/li&gt;&#xA;&lt;li&gt;Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；&lt;/li&gt;&#xA;&lt;li&gt;Nginx对请求的异步处理可以帮助节点服务器减轻负载；&lt;/li&gt;&#xA;&lt;li&gt;Nginx能支持http和Email，这样就在适用范围上面小很多；&lt;/li&gt;&#xA;&lt;li&gt;不支持Session的保持、对Big request header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡算法。&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;F5 &amp;hellip; 牛逼的物理负载均衡设备　&#xA;土豪配备，性能那是必须的　　&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;选择　　&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;第一阶段：利用Nginx或者HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是 仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或者HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择&lt;/p&gt;&#xA;&#xA;&lt;p&gt;第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用F5就是首要选择，Nginx此时就作为LVS或者 F5的节点来使用，具体LVS或者F5的是选择是根据公司规模，人才以及资金能力来选择的，这里也不做详谈，但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。&#xA;最终形成比较理想的状态为：F5/LVS&amp;lt;—&amp;gt;Haproxy&amp;lt;—&amp;gt;Squid/Varnish&amp;lt;—&amp;gt;AppServer。&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;LVS/HaProxy/Nignx 的相关介绍摘自网上, 感谢作者，其实网上的介绍都是这样, 我也不知道谁是第一作者了，所以此处就不标注出处了, 望作者原谅&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;负载均衡算法　　&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;随机&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;请求随机分配到各个服务器。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;轮询&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;将所有请求，依次分发到每台服务器上，适合服务器硬件同相同的场景。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最少连接&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;优先将请求发给拥有最少连接数的后端服务器，常用于长连接服务，例如数据库连接等服务。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;源地址&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;将请求的源地址进行hash运算，并结合后端的服务器的权重派发请求至某匹配的服务器，这可以使得同一个客户端IP的请求始终被派发至某特定的服务器。该方式适合负载均衡无cookie功能的TCP协议。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;加权　　&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在轮询，随机，最少链接，Hash’等算法的基础上，通过加权的方式，进行负载服务器分配。　　&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;del&gt;又到凌晨一点，说好今天早睡的&amp;hellip;&lt;/del&gt;　　　&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考　&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1_(%E8%AE%A1%E7%AE%97%E6%9C%BA)&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/itfly8/p/5043435.html&#34;&gt;大型网站架构系列：负载均衡详解&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://liubo.loan/2016/08/04/Nginx-LVS-HAProxy%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%BD%AF%E4%BB%B6/&#34;&gt;Nginx/LVS/HAProxy负载均衡软件&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/负载均衡的一点整理.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>分布式事务2PC &amp;&amp; 3PC</title>
    <updated>2016-11-22T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-22:/2016/分布式事务2PC &amp;&amp; 3PC.html</id>
    <content type="html">&lt;p&gt;二阶段提交（Two-phase Commit）是指，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol)&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为： 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 (from Wikipedia)&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;2PC&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;阶段1：请求阶段（commit-request phase，或称表决阶段，voting phase）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。&lt;/li&gt;&#xA;&lt;li&gt;各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个&amp;rdquo;同意&amp;rdquo;消息；如果参与者节点的事务操作实际执行失败，则它返回一个&amp;rdquo;中止&amp;rdquo;消息。&#xA;有时候，第一阶段也被称作投票阶段，即各参与者投票是否要继续接下来的提交操作。。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;阶段2：提交阶段（commit phase）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;成功&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/success.png&#34; alt=&#34;成功算示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当协调者节点从所有参与者节点获得的相应消息都为&amp;rdquo;同意&amp;rdquo;时：&lt;/li&gt;&#xA;&lt;li&gt;协调者节点向所有参与者节点发出&amp;rdquo;正式提交&amp;rdquo;的请求。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点正式完成操作，并释放在整个事务期间内占用的资源。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点向协调者节点发送&amp;rdquo;完成&amp;rdquo;消息。&lt;/li&gt;&#xA;&lt;li&gt;协调者节点收到所有参与者节点反馈的&amp;rdquo;完成&amp;rdquo;消息后，完成事务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;失败&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/fail.png&#34; alt=&#34;失败算法示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果任一参与者节点在第一阶段返回的响应消息为&amp;rdquo;终止&amp;rdquo;，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：&lt;/li&gt;&#xA;&lt;li&gt;协调者节点向所有参与者节点发出&amp;rdquo;回滚操作&amp;rdquo;的请求。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点向协调者节点发送&amp;rdquo;回滚完成&amp;rdquo;消息。&lt;/li&gt;&#xA;&lt;li&gt;协调者节点收到所有参与者节点反馈的&amp;rdquo;回滚完成&amp;rdquo;消息后，取消事务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;现实生活中其实很多地方都在使用 2PC ：&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;组织者组织出游，给每个参与者发送出游确认邮件,每个参与者回复去或是不去给组织者，如果都回复ok，那么就可以出游，要是有一个人回复NO, 那么这次出游就取消(使用了2PC)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;2PC 存在的问题&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;同步阻塞问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;它的执行过程中间，节点都处于阻塞状态。即节点之间在等待对方的相应消息时，它将什么也做不了。特别是，当一个节点在已经占有了某项资源的情况下，为了等待其他节点的响应消息而陷入阻塞状态时，当第三个节点尝试访问该节点占有的资源时，这个节点也将连带陷入阻塞状态&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单点故障&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据不一致问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;情形一: 协调者挂了，参与者没挂(单点故障，不会造成数据不一致)&lt;/li&gt;&#xA;&lt;li&gt;情形二: 参与者挂了, 协调者没挂(不会造成数据不一致)&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;挂了的参与者不会恢复， 不会造成数据不一致&lt;/li&gt;&#xA;&lt;li&gt;挂了的参与者恢复过来，如果之前有未完成的事务，直接取消掉，然后询问协调者目前我应该怎么做，协调者就会比对自己的事务执行记录和该参与者的事务执行记录，告诉他应该怎么做来保持数据的一致性&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;参与者和协调者都挂了&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;都在第一阶段挂了, 参与者都没有执行 commit, 在剩余的参与者中重新选出一个协调者，新的协调者在重新询问是 commit or roolback&lt;/li&gt;&#xA;&lt;li&gt;都在第二阶段挂了, 挂了的参与者在挂掉之前没有收到协调者的指令, 或者接到指令还没有来得及进行 commit or roolback 操作，这种情形下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况。只要有机器执行了abort（roolback）操作或者第一阶段返回的信息是No的话，那就直接执行roolback操作。如果没有人执行abort操作，但是有机器执行了commit操作，那么就直接执行commit操作。这样，当挂掉的参与者恢复之后，只要按照协调者的指示进行事务的commit还是roolback操作就可以了。因为挂掉的机器并没有做commit或者roolback操作，而没有挂掉的机器们和新的协调者又执行了同样的操作，那么这种情况不会导致数据不一致现象。&lt;/li&gt;&#xA;&lt;li&gt;第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行commit或者roolback操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是commit那还好，和其他的机器保持一致了，万一他执行的是roolback操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！ &lt;strong&gt;2PC 无法解决这个问题，这个问题有可能导致数据不一致的&lt;/strong&gt; ，于是就有了3PC(三阶段提交)&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h2&gt;3PC&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;三阶段提交（英语：Three-phase commit），也叫三阶段提交协议（英语：Three-phase commit protocol），是在计算机网络及数据库的范畴下，使得一个分布式系统内的所有节点能够执行事务的提交的一种分布式算法。三阶段提交是为解决两阶段提交协议|的缺点而设计的。&#xA;与两阶段提交不同的是，三阶段提交是“非阻塞”协议。三阶段提交在两阶段提交的第一阶段与第二阶段之间插入了一个准备阶段，使得原先在两阶段提交中，参与者在投票之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题[1]得以解决。 举例来说，假设有一个决策小组由一个主持人负责与多位组员以电话联络方式协调是否通过一个提案，以两阶段提交来说，主持人收到一个提案请求，打电话跟每个组员询问是否通过并统计回复，然后将最后决定打电话通知各组员。要是主持人在跟第一位组员通完电话后失忆，而第一位组员在得知结果并执行后老人痴呆，那么即使重新选出主持人，也没人知道最后的提案决定是什么，也许是通过，也许是驳回，不管大家选择哪一种决定，都有可能与第一位组员已执行过的真实决定不一致，老板就会不开心认为决策小组沟通有问题而解雇。三阶段提交即是引入了另一个步骤，主持人打电话跟组员通知请准备通过提案，以避免没人知道真实决定而造成决定不一致的失业危机。为什么能够解决二阶段提交的问题呢？回到刚刚提到的状况，在主持人通知完第一位组员请准备通过后两人意外失忆，即使没人知道全体在第一阶段的决定为何，全体决策组员仍可以重新协调过程或直接否决，不会有不一致决定而失业。那么当主持人通知完全体组员请准备通过并得到大家的再次确定后进入第三阶段，当主持人通知第一位组员请通过提案后两人意外失忆，这时候其他组员再重新选出主持人后，仍可以知道目前至少是处于准备通过提案阶段，表示第一阶段大家都已经决定要通过了，此时便可以直接通过。(from Wikipedia)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Three-phase_commit_diagram.png&#34; alt=&#34;算法示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;存在的问题&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。&#xA;所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4&#34;&gt;wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://coolshell.cn/articles/10910.html&#34;&gt;分布式系统的事务处理&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.hollischuang.com/archives/681&#34;&gt;关于分布式事务、两阶段提交协议、三阶提交协议&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.hollischuang.com/archives/1580&#34;&gt;深入理解分布式系统的2PC和3PC&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/分布式事务2PC &amp;&amp; 3PC.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>CAP初窥</title>
    <updated>2016-11-21T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-21:/2016/CAP初窥.html</id>
    <content type="html">&lt;p&gt;初入 pingcap ，我这枚小菜鸟对分布式理论却一窍不通，表示很是捉急，借我司 CTO 为新员工科普分布式系统知识之际，自己也花点时间学习学习, 首先先从 &lt;code&gt;CAP&lt;/code&gt; 定理入手&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;ACID&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;传统数据库设计思想, 追求强一致性&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A: Atomicity (原子性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;事务里的操作要么全部执行要不全部不执行&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;C: Consistency(一致性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;事务前后的数据都符合业务里的不变性约束&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I: isolation(隔离性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;表示并发事务之间读数据互相影响的程度&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;D: durability(持久性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;事务提交后就进行了持久化, 不在丢失&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;BASE&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;大多数 nosql 数据库的设计思路, 追求高可用&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BA: Basically Available(基本可用)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;S: Soft Stat(软状态)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;允许事务的一些状态暴露出来, 即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;E: Eventually consistent(最终一致性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ACID和BASE代表了两种截然相反的设计哲学，分处一致性-可用性分布图谱的两极&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;CAP&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;柏克莱加州大学（University of California, Berkeley）的计算机科学家埃里克·布鲁尔在2000年的分布式计算原则研讨会（Symposium on Principles of Distributed Computing（PODC））上提出的这个猜想 在2002年，麻省理工学院（MIT）的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为一个定理。&#xA;它指出对于一个分布式计算系统来说，不可能同时满足以下三点：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一致性(Consistency)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;向分布式系统给发送请求,一定返回最新的数据&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可用性(Availablity)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;向分布式系统写、读等请求的时候，一定会得到合理的响应，这个响应不应该是错误也不应该是请求超时&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;网络分区容忍性(Partition tolerance)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;分布式系统中，当部分节点无法互通出现网络分区现象，但是整个系统还是可以对外提供服务&lt;/p&gt;&#xA;&#xA;&lt;p&gt;由于当前的网络硬件肯定&#xA;会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。&#xA;以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择&#xA;根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失性质。(from Wikipedia)&#xA;具体选择AP,还是CP 都是由具体场景来做决择。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;CP 栗子: 2PC(两阶段提交)&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;两阶段提交, ACID 思想在分布式系统中的延伸，保证数据的强一致性。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;阶段一: 请求阶段&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;阶段二: 提交阶段&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2PC协议存在许多明细的问题, 如参与者挂了，或是协调者挂了等,今晚好困, 2PC问题可待我仔细思考学习一下，还有我司 CTO 提到的拜占庭问题&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;AP 栗子: BASE&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性,&#xA;BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。大多数的 nosql 数据库就是基于BASE设计的，如redis、mongodb等&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Last But Not Least&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;CAP 定理告诉我们, &amp;ldquo;在分区存在的情况下, 呈现完美的数据一致性和可用性&amp;rdquo; 是不可能的, 分区在很多情况下并不是经常出现的, 在没有分区的情况下, 我们应该尽量保证CA，在发生分区的时候, 我们应该具体场景具体分析，选择CP or AP&amp;hellip;&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed&#34;&gt;CAP Twelve Years Later: How the &amp;ldquo;Rules&amp;rdquo; Have Changed&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gLtO0vY_M78&#34;&gt;CAP Theorem Distributed Systems in One Lesson&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/CAP初窥.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>go笔记 - 并发</title>
    <updated>2016-11-07T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-07:/2016/go笔记 - 并发.html</id>
    <content type="html">&lt;p&gt;Goroutine 的那些事&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;并发与并行&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;并发未必并行，“并发”指的是程序的结构，“并行”指的是程序运行时的状态&#xA;并行指物理上同时执行，并发指能够让多个任务在逻辑上交织执行的程序设计&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/bingxin_bingfa.png&#34; alt=&#34;并行&amp;amp;并发&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;并行&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;物理上的同时发生&#xA;并行(parallelism)是指同时发生的两个并发事件，具有并发的含义，而并发则不一定并行。&#xA;并行，就是同时执行的意思，无需过度解读。判断程序是否处于并行的状态，就看同一时刻是否有超过一个“工作单位”在运行就好了。所以，单线程永远无法达到并行状态。&#xA;要达到并行状态，最简单的就是利用多线程和多进程。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;并发&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;逻辑上的并行(逻辑上的同时发生)&#xA;并发性(concurrency)，又称共行性，是指能处理多个同时性活动的能力，并发事件之间不一定要同一时刻发生。&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/bingfa.jpg&#34; alt=&#34;并发&#34; /&gt;&#xA;&amp;gt; task1, task2 是两段不同的代码，比如两个函数，其中黑色块代表某段代码正在执行。注意，这里从始至终，在任何一个时间点上都只有一段代码在执行，但是，由于 task1 和 task2 在重叠的时间段内执行，所以这是一个支持并发的设计。与并行不同，单核单线程能支持并发。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;来个比喻：并发和并行的区别就是一个人同时吃三个馒头和三个人同时吃三个馒头。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;了解更多&lt;/h4&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://talks.golang.org/2012/waza.slide#1&#34;&gt;并发不是并行&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/&#34;&gt;并发与并行&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;golang 并发概述&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/goroutine_control.png&#34; alt=&#34;基本关系示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Processor(简称P)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;作用类似CPU核，用于控制可同时并发执行的任务数量，每个工作线程都必须绑定一个有效P才被允许执行任务，否则只能休眠，直到有空闲的P时才被唤醒。P还为线程提供执行资源，比如对象分配内存，本地任务队列等。线程独享所绑定的P资源，可在无锁状态下执行高效操作。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Goroutine(简称G)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;基本上，线程内的一切都是以G方式运行，包括运行时相关服务，以及main.main入口函数。G并非执行体，它仅仅保存并发任务状态，为并发任务提供所需栈内存空间。G任务创建后被放置在P本地队列或是全局队列，等待工作线程调度执行  。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;系统线程(简称M)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;与P绑定，以调度循环方式不停的执行G并发任务。M通过修改寄存器，将执行栈指向G自带栈内存，并在此空间内分配堆栈帧，执行任务函数。当需要中途切换时，只要将相关寄存器值保存回G空间即可维护状态，任何M都可据此回复执行。线程负责执行，不在持有状态，这是并发任务跨线程调度，实现多路复用到更本所在&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;尽管P/M构成执行组合体，但两者数量并非一一对应。通常情况下P数量相对恒定，默认与CPU数量相同，但是也可以更多或是更少，而M则是调度器按需创建。例如，当M应陷入系统调用而长时间阻塞时，P就会被监控线程夺回，去创建(或唤醒)一个M去执行其他任务，如此M的数量就会增长。&#xA;应为G初始栈只有2KB，且创建只是在用户空间简单的对象分配，远比进入内核态分配的线程要简单的多。调度器让多个M进入调度循环，不停获取并执行任务，所以我们才能创建成千上万个并发任务&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;初始化&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;调度器初始化函数(schedinit) 除了内存分配、垃圾回收等操作外，针对自身的初始化：设置MaxMcount(最大M数量1.6wei)、GOMAXPROCS(最大P数量)。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1.5之后GOMAXPROCS由默认的1改为CPU Cores&lt;/p&gt;&#xA;&#xA;&lt;p&gt;schedinit 内需要调整P数量(procesize) , 默认也只有schedinit， 以及startTheWorld会调用procesize函数。在调度器初始化阶段，所有P对象都是新建的。除分配给主线程的外，其他都被放在空闲链表内。而startTheWorld会激活全部有本地任务的所有P对象。 在完成调度器初始化后，引导过程才创建并运行main goroutine&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在运行的过程中也可以通过runtime.GOMAXPROCS函数修改P的数量，但是代价很大 ，需要STW，然后在startTheWold，并激活所有有任务的P&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;任务&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;编译器将go func 翻译成newproc调用&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;package main&#xA;&#xA;func add(x, y int) int {&#xA;&#x9;z := x + y&#xA;    return z&#xA;}&#xA;&#xA;func main() {&#xA;&#x9;x := 0x100&#xA;    y := 0x200&#xA;    go add(x, y)&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;go build -o test test.go&#xA;go tool objdump -s &amp;quot;main\.main&amp;quot; test&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/test_goroutine.png&#34; alt=&#34;反汇编代码&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/diaoyongzhan.png&#34; alt=&#34;调用栈&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;没看懂  &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;type g struct {&#xA;&#x9;stack &#x9;&#x9;stack // 执行栈&#xA;    sched &#x9;   gobuf // 用于保存执行现场&#xA;    goid         inti64   // 唯一序号&#xA;    gopc        uintptr // 调用者 PC/IP&#xA;    startpc     uintptr // 任务函数&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;newproc 先获取第一参数地址，然后获取调用方PC/IP寄存器值    ，接着用G0栈创建G(newproc1), newproc1  负责创建G(具体过程我也看不太懂) 。首先G对象默认会复用，除去P本地的复用链表外，还有全局链表在多个P之间共享&lt;/p&gt;&#xA;&#xA;&lt;p&gt;当goroutine 执行完毕，调度器相关函数会将G对象放回P复用链表&lt;/p&gt;&#xA;&#xA;&lt;p&gt;默认使用2K栈空间，并且都被allg引用。为了垃圾回收遍历扫描需要，以便获取指针引用，收缩栈空间。&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;G复用方式 ，G不释放，由垃圾回收调用shrinkstack将其栈空间回收&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;在获取G对象后， newproc1会进行一系列初始化操作， 毕竟不管新建还是复用，这些参数都必须争取设置。同时， 相关执行参数会被拷贝到G的栈空间， 因为它和当前任务不在有任何关系，各自使用独立的栈空间。 毕竟&amp;rdquo;go func(&amp;hellip;)&amp;rdquo;  语句仅仅创建并发任务，当前流程会继续自己的逻辑  。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;创建完毕的G任务会优先放入P本地队列等待执行， 这属于无锁操作 。 如果P本地过队列满了，就会放在全局队列，因为需要加锁，所有速度比较慢&lt;/p&gt;&#xA;&#xA;&lt;p&gt;任务队列从分为三级，按优先级从高到低分别是P.runnext(优先队列) , P.runq(本地队列) , Sched.runq   有点CPU多级缓存的意思&lt;/p&gt;&#xA;&#xA;&lt;p&gt;往全局队列添加任务，需要加锁，runqputslow      慢&lt;/p&gt;&#xA;&#xA;&lt;p&gt;如果本地队列已满， 一次性转移半数到全局队列。因为其他P可能正饿着呢。这也正好解释了newproc1最后常识wakep唤醒其他M/P去执行任务的意图，重复利用多核优势&lt;/p&gt;&#xA;&#xA;&lt;p&gt;G状态切换过程&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/g_status.png&#34; alt=&#34;G状态切换过程&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;线程&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;当newproc1 成功创建G任务后，会尝试wakep唤醒M执行任务&lt;/p&gt;&#xA;&#xA;&lt;p&gt;与G对象复用类似， 这个过程同样闲置和新建两种方式&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;type m struct {&#xA;&#x9;g0 &#x9;&#x9;&#x9;*g                         // 提供系统栈空间&#xA;    mstartfn func()                   // 启动函数&#xA;    cury &#x9;&#x9;*g &#x9;&#x9;&#x9;&#x9;&#x9;&#x9;  // 当前运行 G&#xA;    p &#x9;&#x9;&#x9; puintptr &#x9;&#x9;&#x9;&#x9; // 绑定 P&#xA;    nextp &#x9;   puintptr    &#x9;&#x9;&#x9; // 临时存放 P&#xA;    spinning    bool   &#x9;&#x9;&#x9;&#x9;  /自旋状态  (不懂啥意思)&#xA;    park &#x9;    note   &#x9;&#x9;&#x9;&#x9;&#x9;// 休眠锁&#xA;    schedlink  muintptr  &#x9;&#x9;&#x9;// 链表&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;M 最特别的就是自带一个名为g0，默认8KB栈内存的G对象属性。 它的栈内存地址被传给newosproc函数， 作为系统线程默堆栈空间(并非所有系统都支持)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在进程执行过程中，有两类代码需要运行。一：用户逻辑，直接使用G栈内存，二： 运行时管理指令，它并不方便直接使用用户栈上执行，因为这需要处理与用户逻辑现场有关的一大堆事务&lt;/p&gt;&#xA;&#xA;&lt;p&gt;例如， G线程可在中途暂停，放回队列后由其他M获取执行。 如不更改执行栈，那可能会造成多个线程共享内存，从而引发混乱。 另外，在执行垃圾回收操作的时候 ， 如何收缩依旧被线程持有的G栈空间？为此， 当需要执行管理指令时，会将线程临时切换到g0， 与用户逻辑彻底隔离&lt;/p&gt;&#xA;&#xA;&lt;p&gt;M初始化操作会检查已有数量， 如超出最大限制(默认 10000）会导致进程崩溃。所有M被添加到allm链表，且不被释放&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;执行&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;M 执行G并发任务有两个起点：线程启动函数mstart， 还有就是stopm休眠后再度回复调度循环&lt;/p&gt;&#xA;&#xA;&lt;p&gt;准备进入工作状态的M必须绑定一个有效的P， nextp临时持有待绑定P对象。因为在未正确执行前，并不适合设置相关属性。P为M提供cache，以便为执行提供对象内存分配&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一切就绪后， M进入核心调度循环，这是一个由schedule，execute，goroutine fn， goexitt 函数构成的逻辑循环。就算M在休眠后，也只是从“断点”恢复&lt;/p&gt;&#xA;&#xA;&lt;p&gt;调度函数获得可用的G后，交给execute去执行。同时，还检查环境开关来决定是否参与垃圾回收&lt;/p&gt;&#xA;&#xA;&lt;p&gt;执行结束后，清理操作，然后在此进入调度循环，&lt;/p&gt;&#xA;&#xA;&lt;p&gt;findrunnable&lt;/p&gt;&#xA;&#xA;&lt;p&gt;为了找到可以运行的G任务，findrunnable 可谓费尽心机。本地队列、全局队列、网络任务，甚至从其他P任务队列偷取。所有目的就是为了尽快的完成所有任务，充分发挥多核并行能力。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;按查找流程，我们依次查看不同优先级的获取方式。首先是本地队列 ， 其中P.runnext 优先级最高 。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在检查全局队列时，除了返回一个可用的G外， 还会批量转移一批到P本地队列 ，毕竟不能每次加锁去操作全局队列&lt;/p&gt;&#xA;&#xA;&lt;p&gt;通过引入P，实现了一种叫做work-stealing的调度算法：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个P维护一个G队列；&lt;/li&gt;&#xA;&lt;li&gt;当一个G被创建出来，或者变为可执行状态时，就把他放到P的可执行队列中；&lt;/li&gt;&#xA;&lt;li&gt;当一个G执行结束时，P会从队列中把该G取出；如果此时P的队列为空,而且全局也队列也无法获取G，即没有其他G可以执行， 就随机选择另外一个P，从其可执行的G队列中偷取一半。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;执行过程总结&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Goroutine调度是在P中进行，每当runtime需要进行调度时，会调用schedule()函数， 该函数在proc.go文件中定义。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;schedule()函数首先调用runqget()从当前P的队列中取一个可以执行的G。 如果队列为空，继续调用findrunnable()函数。findrunnable()函数会按照以下顺序来取得G：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;调用runqget()从当前P的队列中取G（和schedule()中的调用相同）；&lt;/li&gt;&#xA;&lt;li&gt;调用globrunqget()从全局队列中取可执行的G；&lt;/li&gt;&#xA;&lt;li&gt;调用netpoll()取异步调用结束的G，该次调用为非阻塞调用，直接返回；&lt;/li&gt;&#xA;&lt;li&gt;调用runqsteal()从其他P的队列中“偷”。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;如果以上四步都没能获取成功，就继续执行一些低优先级的工作：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果处于垃圾回收标记阶段，就进行垃圾回收的标记工作；&lt;/li&gt;&#xA;&lt;li&gt;再次调用globrunqget()从全局队列中取可执行的G；&lt;/li&gt;&#xA;&lt;li&gt;再次调用netpoll()取异步调用结束的G，该次调用为阻塞调用。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;如果还没有获得G，就停止当前M的执行，返回findrunnable()函数开头重新执行。 如果findrunnable()正常返回一个G，shedule()函数会调用execute()函数执行该G。 execute()函数会调用gogo()函数（在汇编源文件asm_XXX.s中定义，XXX代表系统架构），gogo() 函数会从G.sched结构中恢复出G上次被调度器暂停时的寄存器现场（SP、PC等），然后继续执行。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;连续栈&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;实现方式也是先分配一块固定大小的栈，在栈空间不足时，分配一块更大的栈，并把旧的栈全部拷贝到新栈中。 这样避免了Split Stacks方法可能导致的频繁内存分配和释放。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;系统调用&lt;/h2&gt;&#xA;&#xA;&lt;h2&gt;监控&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;释放闲置超过5分钟的span物理内存&lt;/li&gt;&#xA;&lt;li&gt;如果超过2分钟没有垃圾回收，强制执行&lt;/li&gt;&#xA;&lt;li&gt;将长时间未处理的netpoll结果添加到任务队列&lt;/li&gt;&#xA;&lt;li&gt;向长时间运行到G任务发出抢占调度&lt;/li&gt;&#xA;&lt;li&gt;收回因syscall长时间阻塞的P&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在进入垃圾回收状态时，sysmon会自动进入休眠，所以我们才会在syscall里看到很多唤醒指令。另外，startTheWorld也会做唤醒处理。保证监控线程正常运行。对内存分配、垃圾回收和并发调度都非常重要&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;抢占调度&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;所谓抢占调度要比你想象的简单许多，远不实你以为的“抢占式多任务操作系统”那种样子。因为Golang调度器并没有真正意义的时间片概念，只是在目标G上设置一个抢占标志，当该任务调用某个函数时，被编译器安插的指令就会检查这个标志，从而决定是否暂停当前任务&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/qyuhen/book&#34;&gt;1.5源码分析&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://talks.golang.org/2012/waza.slide#1&#34;&gt;并发不是并行&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/&#34;&gt;并发与并行&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/go笔记 - 并发.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
</feed>