<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>cwen&#39;s blog</title>
  <id>http://int64.me</id>
  <updated>2016-11-25T18:15:47+08:00</updated>
  <subtitle>沉稳，不乏可爱</subtitle>
  <link href="http://int64.me"></link>
  <entry>
    <title>负载均衡的一点整理</title>
    <updated>2016-11-25T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-25:/2016/负载均衡的一点整理.html</id>
    <content type="html">&lt;p&gt;刚接到一个调研各云厂商的负载均衡情况的小任务，可是小菜鸟对与负载均衡也是一知半解,就先花点时间冲冲电&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;从单机网站到分布式网站，很重要的区别就是业务拆分以及分布式部署，但是每个部署的独立业务还存在单点的问题和访问统一入口问题，为解决单点故障，我们可以采取冗余的方式。将相同的应用部署到多台机器上。解决访问统一入口问题，我们可以在集群前面增加负载均衡设备，实现流量分发。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;解决的问题&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;提供故障转移，实现高可用；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;通过添加或减少服务器数量，提供网站伸缩性（扩展性）；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;原理 : 其实就是根据一些转发算法，讲请求分发到不同的节点上去执行&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;负载均衡原理&lt;/h2&gt;&#xA;&#xA;&lt;h4&gt;DNS&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;通过使用域名解析实现负载均衡，配置多个A 记录，这些A记录对应的服务器构成集群。大型网站总是部分使用DNS解析，作为第一级负载均衡。 显而易见，使用这种方式的负载均衡的控制权更在域名商那里，不易拓展，并且用这种方式的负载不能很好的分流，有可能造成所有的请求都集中到一个节点上，但是作为第一层的负载均衡的确是个好办法。　　　　&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;HTTP&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;当http代理（比如浏览器）向web服务器请求某个URL后，web服务器可以通过http响应头信息中的Location标记来返回一个新的URL。这意味着HTTP代理需要继续请求这个新的URL，完成自动跳转。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;IP&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;在网络层通过修改请求目标地址进行负载均衡。&#xA;用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为，获得的真实ip地址，不需要经过用户进程处理。&#xA;真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的ip地址，发送给用户浏览器。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213195925966-1272593644.png&#34; alt=&#34;示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;链路层&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;在通信协议的数据链路层修改mac地址，进行负载均衡。&#xA;数据分发时，不修改ip地址，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。&#xA;实际处理服务器ip和数据请求目的ip一致，不需要经过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR模式）。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;混合　　&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;其实这就显而易见了，当单一的负载均衡方式无法很好的解决现有的问题，那么我们就可以把他们结合在一起使用，这也很符合当下的发展潮流啊&amp;hellip;   具体的结合方式有很多，例如　我们可以考虑分层，在每一层采用不同的方式来进行负载均衡，在最外层使用&#xA;DNS负载均衡，在使用反向代理来做缓存以及动态请求分发 ，最后在是应用负载均衡(IP/DR), 分流到对应的应用集群　　&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213200106747-94797427.png&#34; alt=&#34;混合一&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213200117825-1452672107.png&#34; alt=&#34;混合二&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;具体实现　　　&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;四层　　&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;LVS  (Linux Virtual Server) 基于IP层的负载均衡调度技术，它在操作系统核心层上，将来自IP层的TCP/UDP请求均衡地转移到不同的 服务器，从而将一组服务器构成一个高性能、高可用的虚拟服务器。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;抗负载能力强，因为lvs工作方式的逻辑是非常之简单，而且工作在网络4层仅做请求分发之用，没有流量，所以在效率上基本不需要太过考虑。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;配置性低，这通常是一大劣势，但同时也是一大优势，因为没有太多可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;工作稳定，因为其本身抗负载能力很强，所以稳定性高也是顺理成章，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，节点出现故障的话，lvs会自动判别，所以系统整体是非常稳定的。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;无流量，上面已经有所提及了。lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;日PV小于1000万，的时候不需要考虑 LVS , 大多时候LVS + Keepalived配合使用(阿里云),LVS提 供负载均衡，keepalived提供健康检查，故障转移，提高系统的可用性！采用这样的架构以后 很容易对现有系统进行扩展，只要在后端添加或者减少realserver，只要更改lvs的 配置文件，并能实现无缝配置变更！。　　&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;七层　&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;HaProxy&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;HAProxy是工作在网络7层之上。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;支持url检测后端的服务器出问题的检测会有很好的帮助。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nignx&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nginx对网络的依赖比较小；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nginx安装和配置比较简单，测试起来比较方便；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nginx对请求的异步处理可以帮助节点服务器减轻负载；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;Nginx能支持http和Email，这样就在适用范围上面小很多；&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;不支持Session的保持、对Big request header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡算法。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;F5 &amp;hellip; 牛逼的物理负载均衡设备　&#xA;土豪配备，性能那是必须的　　&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;选择　　&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;第一阶段：利用Nginx或者HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是 仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或者HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择&lt;/p&gt;&#xA;&#xA;&lt;p&gt;第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用F5就是首要选择，Nginx此时就作为LVS或者 F5的节点来使用，具体LVS或者F5的是选择是根据公司规模，人才以及资金能力来选择的，这里也不做详谈，但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。&#xA;最终形成比较理想的状态为：F5/LVS&amp;lt;—&amp;gt;Haproxy&amp;lt;—&amp;gt;Squid/Varnish&amp;lt;—&amp;gt;AppServer。&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;LVS/HaProxy/Nignx 的相关介绍摘自网上, 感谢作者，其实网上的介绍都是这也我也不知道谁是第一作者了，所以此处就不标注出处了, 望作者原理　　　　&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;负载均衡算法　　&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;随机&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;请求随机分配到各个服务器。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;轮询&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;将所有请求，依次分发到每台服务器上，适合服务器硬件同相同的场景。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最少连接&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;优先将请求发给拥有最少连接数的后端服务器，常用于长连接服务，例如数据库连接等服务。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;源地址&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;将请求的源地址进行hash运算，并结合后端的服务器的权重派发请求至某匹配的服务器，这可以使得同一个客户端IP的请求始终被派发至某特定的服务器。该方式适合负载均衡无cookie功能的TCP协议。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;加权　　&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在轮询，随机，最少链接，Hash’等算法的基础上，通过加权的方式，进行负载服务器分配。　　&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;del&gt;又到凌晨一点，说好今天早睡的&amp;hellip;&lt;/del&gt;　　　&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考　&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1_(%E8%AE%A1%E7%AE%97%E6%9C%BA&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/itfly8/p/5043435.html&#34;&gt;大型网站架构系列：负载均衡详解&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://liubo.loan/2016/08/04/Nginx-LVS-HAProxy%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%BD%AF%E4%BB%B6/&#34;&gt;Nginx/LVS/HAProxy负载均衡软件&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/负载均衡的一点整理.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>分布式事务2PC &amp;&amp; 3PC</title>
    <updated>2016-11-22T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-22:/2016/分布式事务2PC &amp;&amp; 3PC.html</id>
    <content type="html">&lt;p&gt;二阶段提交（Two-phase Commit）是指，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol)&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为： 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 (from Wikipedia)&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;2PC&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;阶段1：请求阶段（commit-request phase，或称表决阶段，voting phase）&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个&amp;rdquo;同意&amp;rdquo;消息；如果参与者节点的事务操作实际执行失败，则它返回一个&amp;rdquo;中止&amp;rdquo;消息。&#xA;有时候，第一阶段也被称作投票阶段，即各参与者投票是否要继续接下来的提交操作。。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;阶段2：提交阶段（commit phase）&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;成功&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/success.png&#34; alt=&#34;成功算示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当协调者节点从所有参与者节点获得的相应消息都为&amp;rdquo;同意&amp;rdquo;时：&lt;/li&gt;&#xA;&lt;li&gt;协调者节点向所有参与者节点发出&amp;rdquo;正式提交&amp;rdquo;的请求。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点正式完成操作，并释放在整个事务期间内占用的资源。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点向协调者节点发送&amp;rdquo;完成&amp;rdquo;消息。&lt;/li&gt;&#xA;&lt;li&gt;协调者节点收到所有参与者节点反馈的&amp;rdquo;完成&amp;rdquo;消息后，完成事务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;失败&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/fail.png&#34; alt=&#34;失败算法示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果任一参与者节点在第一阶段返回的响应消息为&amp;rdquo;终止&amp;rdquo;，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：&lt;/li&gt;&#xA;&lt;li&gt;协调者节点向所有参与者节点发出&amp;rdquo;回滚操作&amp;rdquo;的请求。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。&lt;/li&gt;&#xA;&lt;li&gt;参与者节点向协调者节点发送&amp;rdquo;回滚完成&amp;rdquo;消息。&lt;/li&gt;&#xA;&lt;li&gt;协调者节点收到所有参与者节点反馈的&amp;rdquo;回滚完成&amp;rdquo;消息后，取消事务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;现实生活中其实很多地方都在使用 2PC ：&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;组织者组织出游，给每个参与者发送出游确认邮件,每个参与者回复去或是不去给组织者，如果都回复ok，那么就可以出游，要是有一个人回复NO, 那么这次出游就取消(使用了2PC)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;2PC 存在的问题&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;同步阻塞问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;它的执行过程中间，节点都处于阻塞状态。即节点之间在等待对方的相应消息时，它将什么也做不了。特别是，当一个节点在已经占有了某项资源的情况下，为了等待其他节点的响应消息而陷入阻塞状态时，当第三个节点尝试访问该节点占有的资源时，这个节点也将连带陷入阻塞状态&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单点故障&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;数据不一致问题&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;情形一: 协调者挂了，参与者没挂(单点故障，不会造成数据不一致)&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;情形二: 参与者挂了, 协调者没挂(不会造成数据不一致)&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;挂了的参与者不会恢复， 不会造成数据不一致&lt;/li&gt;&#xA;&lt;li&gt;挂了的参与者恢复过来，如果之前有未完成的事务，直接取消掉，然后询问协调者目前我应该怎么做，协调者就会比对自己的事务执行记录和该参与者的事务执行记录，告诉他应该怎么做来保持数据的一致性&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;参与者和协调者都挂了&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;都在第一阶段挂了, 参与者都没有执行 commit, 在剩余的参与者中重新选出一个协调者，新的协调者在重新询问是 commit or roolback&lt;/li&gt;&#xA;&lt;li&gt;都在第二阶段挂了, 挂了的参与者在挂掉之前没有收到协调者的指令, 或者接到指令还没有来得及进行 commit or roolback 操作，这种情形下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况。只要有机器执行了abort（roolback）操作或者第一阶段返回的信息是No的话，那就直接执行roolback操作。如果没有人执行abort操作，但是有机器执行了commit操作，那么就直接执行commit操作。这样，当挂掉的参与者恢复之后，只要按照协调者的指示进行事务的commit还是roolback操作就可以了。因为挂掉的机器并没有做commit或者roolback操作，而没有挂掉的机器们和新的协调者又执行了同样的操作，那么这种情况不会导致数据不一致现象。&lt;/li&gt;&#xA;&lt;li&gt;第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行commit或者roolback操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是commit那还好，和其他的机器保持一致了，万一他执行的是roolback操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！ &lt;strong&gt;2PC 无法解决这个问题，这个问题有可能导致数据不一致的&lt;/strong&gt; ，于是就有了3PC(三阶段提交)&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;3PC&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;三阶段提交（英语：Three-phase commit），也叫三阶段提交协议（英语：Three-phase commit protocol），是在计算机网络及数据库的范畴下，使得一个分布式系统内的所有节点能够执行事务的提交的一种分布式算法。三阶段提交是为解决两阶段提交协议|的缺点而设计的。&#xA;与两阶段提交不同的是，三阶段提交是“非阻塞”协议。三阶段提交在两阶段提交的第一阶段与第二阶段之间插入了一个准备阶段，使得原先在两阶段提交中，参与者在投票之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题[1]得以解决。 举例来说，假设有一个决策小组由一个主持人负责与多位组员以电话联络方式协调是否通过一个提案，以两阶段提交来说，主持人收到一个提案请求，打电话跟每个组员询问是否通过并统计回复，然后将最后决定打电话通知各组员。要是主持人在跟第一位组员通完电话后失忆，而第一位组员在得知结果并执行后老人痴呆，那么即使重新选出主持人，也没人知道最后的提案决定是什么，也许是通过，也许是驳回，不管大家选择哪一种决定，都有可能与第一位组员已执行过的真实决定不一致，老板就会不开心认为决策小组沟通有问题而解雇。三阶段提交即是引入了另一个步骤，主持人打电话跟组员通知请准备通过提案，以避免没人知道真实决定而造成决定不一致的失业危机。为什么能够解决二阶段提交的问题呢？回到刚刚提到的状况，在主持人通知完第一位组员请准备通过后两人意外失忆，即使没人知道全体在第一阶段的决定为何，全体决策组员仍可以重新协调过程或直接否决，不会有不一致决定而失业。那么当主持人通知完全体组员请准备通过并得到大家的再次确定后进入第三阶段，当主持人通知第一位组员请通过提案后两人意外失忆，这时候其他组员再重新选出主持人后，仍可以知道目前至少是处于准备通过提案阶段，表示第一阶段大家都已经决定要通过了，此时便可以直接通过。(from Wikipedia)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Three-phase_commit_diagram.png&#34; alt=&#34;算法示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;存在的问题&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。&#xA;所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4&#34;&gt;wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://coolshell.cn/articles/10910.html&#34;&gt;分布式系统的事务处理&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.hollischuang.com/archives/681&#34;&gt;关于分布式事务、两阶段提交协议、三阶提交协议&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.hollischuang.com/archives/1580&#34;&gt;深入理解分布式系统的2PC和3PC&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/分布式事务2PC &amp;&amp; 3PC.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>CAP初窥</title>
    <updated>2016-11-21T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-21:/2016/CAP初窥.html</id>
    <content type="html">&lt;p&gt;初入 pingcap ，我这枚小菜鸟对分布式理论却一窍不通，表示很是捉急，借我司 CTO 为新员工科普分布式系统知识之际，自己也花点时间学习学习, 首先先从 &lt;code&gt;CAP&lt;/code&gt; 定理入手&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;ACID&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;传统数据库设计思想, 追求强一致性&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A: Atomicity (原子性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;事务里的操作要么全部执行要不全部不执行&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;C: Consistency(一致性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;事务前后的数据都符合业务里的不变性约束&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I: isolation(隔离性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;表示并发事务之间读数据互相影响的程度&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;D: durability(持久性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;事务提交后就进行了持久化, 不在丢失&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;BASE&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;大多数 nosql 数据库的设计思路, 追求高可用&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BA: Basically Available(基本可用)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;S: Soft Stat(软状态)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;允许事务的一些状态暴露出来, 即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;E: Eventually consistent(最终一致性)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况&lt;/p&gt;&#xA;&#xA;&lt;p&gt;ACID和BASE代表了两种截然相反的设计哲学，分处一致性-可用性分布图谱的两极&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;CAP&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;柏克莱加州大学（University of California, Berkeley）的计算机科学家埃里克·布鲁尔在2000年的分布式计算原则研讨会（Symposium on Principles of Distributed Computing（PODC））上提出的这个猜想 在2002年，麻省理工学院（MIT）的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为一个定理。&#xA;它指出对于一个分布式计算系统来说，不可能同时满足以下三点：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一致性(Consistency)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;向分布式系统给发送请求,一定返回最新的数据&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可用性(Availablity)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;向分布式系统写、读等请求的时候，一定会得到合理的响应，这个响应不应该是错误也不应该是请求超时&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;网络分区容忍性(Partition tolerance)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;分布式系统中，当部分节点无法互通出现网络分区现象，但是整个系统还是可以对外提供服务&lt;/p&gt;&#xA;&#xA;&lt;p&gt;由于当前的网络硬件肯定&#xA;会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。&#xA;以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择&#xA;根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失性质。(from Wikipedia)&#xA;具体选择AP,还是CP 都是由具体场景来做决择。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;CP 栗子: 2PC(两阶段提交)&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;两阶段提交, ACID 思想在分布式系统中的延伸，保证数据的强一致性。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;阶段一: 请求阶段&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;阶段二: 提交阶段&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2PC协议存在许多明细的问题, 如参与者挂了，或是协调者挂了等,今晚好困, 2PC问题可待我仔细思考学习一下，还有我司 CTO 提到的拜占庭问题&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;AP 栗子: BASE&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性,&#xA;BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。大多数的 nosql 数据库就是基于BASE设计的，如redis、mongodb等&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Last But Not Least&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;CAP 定理告诉我们, &amp;ldquo;在分区存在的情况下, 呈现完美的数据一致性和可用性&amp;rdquo; 是不可能的, 分区在很多情况下并不是经常出现的, 在没有分区的情况下, 我们应该尽量保证CA，在发生分区的时候, 我们应该具体场景具体分析，选择CP or AP&amp;hellip;&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed&#34;&gt;CAP Twelve Years Later: How the &amp;ldquo;Rules&amp;rdquo; Have Changed&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gLtO0vY_M78&#34;&gt;CAP Theorem Distributed Systems in One Lesson&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/CAP初窥.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>go笔记-并发</title>
    <updated>2016-11-07T00:00:00Z</updated>
    <id>tag:int64.me,2016-11-07:/2016/go笔记-并发.html</id>
    <content type="html">&lt;p&gt;Goroutine 的那些事&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;并发与并行&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;并发未必并行，“并发”指的是程序的结构，“并行”指的是程序运行时的状态&#xA;并行指物理上同时执行，并发指能够让多个任务在逻辑上交织执行的程序设计&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/bingxin_bingfa.png&#34; alt=&#34;并行&amp;amp;并发&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;并行&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;物理上的同时发生&#xA;并行(parallelism)是指同时发生的两个并发事件，具有并发的含义，而并发则不一定并行。&#xA;并行，就是同时执行的意思，无需过度解读。判断程序是否处于并行的状态，就看同一时刻是否有超过一个“工作单位”在运行就好了。所以，单线程永远无法达到并行状态。&#xA;要达到并行状态，最简单的就是利用多线程和多进程。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;并发&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;逻辑上的并行(逻辑上的同时发生)&#xA;并发性(concurrency)，又称共行性，是指能处理多个同时性活动的能力，并发事件之间不一定要同一时刻发生。&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/bingfa.jpg&#34; alt=&#34;并发&#34; /&gt;&#xA;&amp;gt; task1, task2 是两段不同的代码，比如两个函数，其中黑色块代表某段代码正在执行。注意，这里从始至终，在任何一个时间点上都只有一段代码在执行，但是，由于 task1 和 task2 在重叠的时间段内执行，所以这是一个支持并发的设计。与并行不同，单核单线程能支持并发。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;来个比喻：并发和并行的区别就是一个人同时吃三个馒头和三个人同时吃三个馒头。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;了解更多&lt;/h4&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://talks.golang.org/2012/waza.slide#1&#34;&gt;并发不是并行&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/&#34;&gt;并发与并行&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;golang 并发概述&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/goroutine_control.png&#34; alt=&#34;基本关系示意图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Processor(简称P)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;作用类似CPU核，用于控制可同时并发执行的任务数量，每个工作线程都必须绑定一个有效P才被允许执行任务，否则只能休眠，直到有空闲的P时才被唤醒。P还为线程提供执行资源，比如对象分配内存，本地任务队列等。线程独享所绑定的P资源，可在无锁状态下执行高效操作。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Goroutine(简称G)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;基本上，线程内的一切都是以G方式运行，包括运行时相关服务，以及main.main入口函数。G并非执行体，它仅仅保存并发任务状态，为并发任务提供所需栈内存空间。G任务创建后被放置在P本地队列或是全局队列，等待工作线程调度执行  。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;系统线程(简称M)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;与P绑定，以调度循环方式不停的执行G并发任务。M通过修改寄存器，将执行栈指向G自带栈内存，并在此空间内分配堆栈帧，执行任务函数。当需要中途切换时，只要将相关寄存器值保存回G空间即可维护状态，任何M都可据此回复执行。线程负责执行，不在持有状态，这是并发任务跨线程调度，实现多路复用到更本所在&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;尽管P/M构成执行组合体，但两者数量并非一一对应。通常情况下P数量相对恒定，默认与CPU数量相同，但是也可以更多或是更少，而M则是调度器按需创建。例如，当M应陷入系统调用而长时间阻塞时，P就会被监控线程夺回，去创建(或唤醒)一个M去执行其他任务，如此M的数量就会增长。&#xA;应为G初始栈只有2KB，且创建只是在用户空间简单的对象分配，远比进入内核态分配的线程要简单的多。调度器让多个M进入调度循环，不停获取并执行任务，所以我们才能创建成千上万个并发任务&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;初始化&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;调度器初始化函数(schedinit) 除了内存分配、垃圾回收等操作外，针对自身的初始化：设置MaxMcount(最大M数量1.6wei)、GOMAXPROCS(最大P数量)。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1.5之后GOMAXPROCS由默认的1改为CPU Cores&lt;/p&gt;&#xA;&#xA;&lt;p&gt;schedinit 内需要调整P数量(procesize) , 默认也只有schedinit， 以及startTheWorld会调用procesize函数。在调度器初始化阶段，所有P对象都是新建的。除分配给主线程的外，其他都被放在空闲链表内。而startTheWorld会激活全部有本地任务的所有P对象。 在完成调度器初始化后，引导过程才创建并运行main goroutine&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在运行的过程中也可以通过runtime.GOMAXPROCS函数修改P的数量，但是代价很大 ，需要STW，然后在startTheWold，并激活所有有任务的P&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;任务&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;编译器将go func 翻译成newproc调用&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;package main&#xA;&#xA;func add(x, y int) int {&#xA;&#x9;z := x + y&#xA;    return z&#xA;}&#xA;&#xA;func main() {&#xA;&#x9;x := 0x100&#xA;    y := 0x200&#xA;    go add(x, y)&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;go build -o test test.go&#xA;go tool objdump -s &amp;quot;main\.main&amp;quot; test&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/test_goroutine.png&#34; alt=&#34;反汇编代码&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/diaoyongzhan.png&#34; alt=&#34;调用栈&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;没看懂  &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;type g struct {&#xA;&#x9;stack &#x9;&#x9;stack // 执行栈&#xA;    sched &#x9;   gobuf // 用于保存执行现场&#xA;    goid         inti64   // 唯一序号&#xA;    gopc        uintptr // 调用者 PC/IP&#xA;    startpc     uintptr // 任务函数&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;newproc 先获取第一参数地址，然后获取调用方PC/IP寄存器值    ，接着用G0栈创建G(newproc1), newproc1  负责创建G(具体过程我也看不太懂) 。首先G对象默认会复用，除去P本地的复用链表外，还有全局链表在多个P之间共享&lt;/p&gt;&#xA;&#xA;&lt;p&gt;当goroutine 执行完毕，调度器相关函数会将G对象放回P复用链表&lt;/p&gt;&#xA;&#xA;&lt;p&gt;默认使用2K栈空间，并且都被allg引用。为了垃圾回收遍历扫描需要，以便获取指针引用，收缩栈空间。&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;G复用方式 ，G不释放，由垃圾回收调用shrinkstack将其栈空间回收&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;在获取G对象后， newproc1会进行一系列初始化操作， 毕竟不管新建还是复用，这些参数都必须争取设置。同时， 相关执行参数会被拷贝到G的栈空间， 因为它和当前任务不在有任何关系，各自使用独立的栈空间。 毕竟&amp;rdquo;go func(&amp;hellip;)&amp;rdquo;  语句仅仅创建并发任务，当前流程会继续自己的逻辑  。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;创建完毕的G任务会优先放入P本地队列等待执行， 这属于无锁操作 。 如果P本地过队列满了，就会放在全局队列，因为需要加锁，所有速度比较慢&lt;/p&gt;&#xA;&#xA;&lt;p&gt;任务队列从分为三级，按优先级从高到低分别是P.runnext(优先队列) , P.runq(本地队列) , Sched.runq   有点CPU多级缓存的意思&lt;/p&gt;&#xA;&#xA;&lt;p&gt;往全局队列添加任务，需要加锁，runqputslow      慢&lt;/p&gt;&#xA;&#xA;&lt;p&gt;如果本地队列已满， 一次性转移半数到全局队列。因为其他P可能正饿着呢。这也正好解释了newproc1最后常识wakep唤醒其他M/P去执行任务的意图，重复利用多核优势&lt;/p&gt;&#xA;&#xA;&lt;p&gt;G状态切换过程&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/g_status.png&#34; alt=&#34;G状态切换过程&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;线程&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;当newproc1 成功创建G任务后，会尝试wakep唤醒M执行任务&lt;/p&gt;&#xA;&#xA;&lt;p&gt;与G对象复用类似， 这个过程同样闲置和新建两种方式&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;type m struct {&#xA;&#x9;g0 &#x9;&#x9;&#x9;*g                         // 提供系统栈空间&#xA;    mstartfn func()                   // 启动函数&#xA;    cury &#x9;&#x9;*g &#x9;&#x9;&#x9;&#x9;&#x9;&#x9;  // 当前运行 G&#xA;    p &#x9;&#x9;&#x9; puintptr &#x9;&#x9;&#x9;&#x9; // 绑定 P&#xA;    nextp &#x9;   puintptr    &#x9;&#x9;&#x9; // 临时存放 P&#xA;    spinning    bool   &#x9;&#x9;&#x9;&#x9;  /自旋状态  (不懂啥意思)&#xA;    park &#x9;    note   &#x9;&#x9;&#x9;&#x9;&#x9;// 休眠锁&#xA;    schedlink  muintptr  &#x9;&#x9;&#x9;// 链表&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;M 最特别的就是自带一个名为g0，默认8KB栈内存的G对象属性。 它的栈内存地址被传给newosproc函数， 作为系统线程默堆栈空间(并非所有系统都支持)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在进程执行过程中，有两类代码需要运行。一：用户逻辑，直接使用G栈内存，二： 运行时管理指令，它并不方便直接使用用户栈上执行，因为这需要处理与用户逻辑现场有关的一大堆事务&lt;/p&gt;&#xA;&#xA;&lt;p&gt;例如， G线程可在中途暂停，放回队列后由其他M获取执行。 如不更改执行栈，那可能会造成多个线程共享内存，从而引发混乱。 另外，在执行垃圾回收操作的时候 ， 如何收缩依旧被线程持有的G栈空间？为此， 当需要执行管理指令时，会将线程临时切换到g0， 与用户逻辑彻底隔离&lt;/p&gt;&#xA;&#xA;&lt;p&gt;M初始化操作会检查已有数量， 如超出最大限制(默认 10000）会导致进程崩溃。所有M被添加到allm链表，且不被释放&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;执行&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;M 执行G并发任务有两个起点：线程启动函数mstart， 还有就是stopm休眠后再度回复调度循环&lt;/p&gt;&#xA;&#xA;&lt;p&gt;准备进入工作状态的M必须绑定一个有效的P， nextp临时持有待绑定P对象。因为在未正确执行前，并不适合设置相关属性。P为M提供cache，以便为执行提供对象内存分配&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一切就绪后， M进入核心调度循环，这是一个由schedule，execute，goroutine fn， goexitt 函数构成的逻辑循环。就算M在休眠后，也只是从“断点”恢复&lt;/p&gt;&#xA;&#xA;&lt;p&gt;调度函数获得可用的G后，交给execute去执行。同时，还检查环境开关来决定是否参与垃圾回收&lt;/p&gt;&#xA;&#xA;&lt;p&gt;执行结束后，清理操作，然后在此进入调度循环，&lt;/p&gt;&#xA;&#xA;&lt;p&gt;findrunnable&lt;/p&gt;&#xA;&#xA;&lt;p&gt;为了找到可以运行的G任务，findrunnable 可谓费尽心机。本地队列、全局队列、网络任务，甚至从其他P任务队列偷取。所有目的就是为了尽快的完成所有任务，充分发挥多核并行能力。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;按查找流程，我们依次查看不同优先级的获取方式。首先是本地队列 ， 其中P.runnext 优先级最高 。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在检查全局队列时，除了返回一个可用的G外， 还会批量转移一批到P本地队列 ，毕竟不能每次加锁去操作全局队列&lt;/p&gt;&#xA;&#xA;&lt;p&gt;通过引入P，实现了一种叫做work-stealing的调度算法：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个P维护一个G队列；&lt;/li&gt;&#xA;&lt;li&gt;当一个G被创建出来，或者变为可执行状态时，就把他放到P的可执行队列中；&lt;/li&gt;&#xA;&lt;li&gt;当一个G执行结束时，P会从队列中把该G取出；如果此时P的队列为空,而且全局也队列也无法获取G，即没有其他G可以执行， 就随机选择另外一个P，从其可执行的G队列中偷取一半。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;执行过程总结&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Goroutine调度是在P中进行，每当runtime需要进行调度时，会调用schedule()函数， 该函数在proc.go文件中定义。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;schedule()函数首先调用runqget()从当前P的队列中取一个可以执行的G。 如果队列为空，继续调用findrunnable()函数。findrunnable()函数会按照以下顺序来取得G：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;调用runqget()从当前P的队列中取G（和schedule()中的调用相同）；&lt;/li&gt;&#xA;&lt;li&gt;调用globrunqget()从全局队列中取可执行的G；&lt;/li&gt;&#xA;&lt;li&gt;调用netpoll()取异步调用结束的G，该次调用为非阻塞调用，直接返回；&lt;/li&gt;&#xA;&lt;li&gt;调用runqsteal()从其他P的队列中“偷”。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;如果以上四步都没能获取成功，就继续执行一些低优先级的工作：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果处于垃圾回收标记阶段，就进行垃圾回收的标记工作；&lt;/li&gt;&#xA;&lt;li&gt;再次调用globrunqget()从全局队列中取可执行的G；&lt;/li&gt;&#xA;&lt;li&gt;再次调用netpoll()取异步调用结束的G，该次调用为阻塞调用。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;如果还没有获得G，就停止当前M的执行，返回findrunnable()函数开头重新执行。 如果findrunnable()正常返回一个G，shedule()函数会调用execute()函数执行该G。 execute()函数会调用gogo()函数（在汇编源文件asm_XXX.s中定义，XXX代表系统架构），gogo() 函数会从G.sched结构中恢复出G上次被调度器暂停时的寄存器现场（SP、PC等），然后继续执行。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;连续栈&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;实现方式也是先分配一块固定大小的栈，在栈空间不足时，分配一块更大的栈，并把旧的栈全部拷贝到新栈中。 这样避免了Split Stacks方法可能导致的频繁内存分配和释放。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;系统调用&lt;/h2&gt;&#xA;&#xA;&lt;h2&gt;监控&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;释放闲置超过5分钟的span物理内存&lt;/li&gt;&#xA;&lt;li&gt;如果超过2分钟没有垃圾回收，强制执行&lt;/li&gt;&#xA;&lt;li&gt;将长时间未处理的netpoll结果添加到任务队列&lt;/li&gt;&#xA;&lt;li&gt;向长时间运行到G任务发出抢占调度&lt;/li&gt;&#xA;&lt;li&gt;收回因syscall长时间阻塞的P&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在进入垃圾回收状态时，sysmon会自动进入休眠，所以我们才会在syscall里看到很多唤醒指令。另外，startTheWorld也会做唤醒处理。保证监控线程正常运行。对内存分配、垃圾回收和并发调度都非常重要&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;抢占调度&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;所谓抢占调度要比你想象的简单许多，远不实你以为的“抢占式多任务操作系统”那种样子。因为Golang调度器并没有真正意义的时间片概念，只是在目标G上设置一个抢占标志，当该任务调用某个函数时，被编译器安插的指令就会检查这个标志，从而决定是否暂停当前任务&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/qyuhen/book&#34;&gt;1.5源码分析&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://talks.golang.org/2012/waza.slide#1&#34;&gt;并发不是并行&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/&#34;&gt;并发与并行&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/go笔记-并发.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>ljgo - 静态博客引擎(0.1.0-beta版)</title>
    <updated>2016-09-08T00:00:00Z</updated>
    <id>tag:int64.me,2016-09-08:/2016/ljgo - 静态博客引擎(0.1.0-beta版).html</id>
    <content type="html">&lt;p&gt;ljgo 是使用GO 语言实现的简单静态博客引擎, 编译速度快、安装简单。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;目前版本 0.1.0-beta&lt;/h4&gt;&#xA;&#xA;&lt;h2&gt;安装&lt;/h2&gt;&#xA;&#xA;&lt;h4&gt;源码安装&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;go运行环境安装请自行google&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;go get -u github.com/cwen-coder/ljgo&#xA;make install&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4&gt;直接下载编译好的可执行文件&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;下载地址 ： &lt;a href=&#34;https://github.com/cwen-coder/ljgo/releases&#34;&gt;ljgo&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;快速入门&lt;/h2&gt;&#xA;&#xA;&lt;h4&gt;新建站点&lt;/h4&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;ljgo new example.com&#xA;#执行完毕后，会在生成example.com文件夹&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;example.com&lt;/code&gt; 文件夹目录结构&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;- config.yml    // 站点配置文件&#xA;- source // 保存文章目录&#xA;- - | - - about.md // 关于页面内容&#xA;- - | - - article.md // 演示文章内容&#xA;- themes  // 保存所有主题&#xA;- - | - - default // 站点默认主题&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;config.yml&lt;/code&gt; 配置格式&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;site:&#xA;    title: 网站标题&#xA;    introduce: 网站描述&#xA;    limit: 每页可显示的文章数目&#xA;    theme: 网站主题目录   ＃eg: themes/default&#xA;    url: 站点域名&#xA;    comment: 评论插件变量(默认为Disqus账户名)&#xA;    github: github.com 地址 # 可选&#xA;    facebook: facebook 地址  # 可选&#xA;    twitter: twitter 地址  # 可选&#xA;serve:&#xA;    addr: ljgo serve 监听地址 # eg: &amp;quot;localhost:3000&amp;quot;&#xA;&#xA;publish:&#xA;    cmd: |&#xA;        ljgo publish 命令将会执行的脚本&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;创建文章&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在source目录中建立任意.md文件（可置于子文件夹），使用如下格式：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;title: 文章标题&#xA;author: 文章作者&#xA;date: 2016-08-02&#xA;update: 2016-08-02&#xA;tags:&#xA;    - 设计&#xA;    - 写作&#xA;&#xA;---&#xA;&#xA;文章预览内容&#xA;    &amp;lt;!--more--&amp;gt;&#xA;文章其它内容&#xA;(文章的全部内容＝预览＋其他)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4&gt;生成静态页面&lt;/h4&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;ljgo build&#xA;# 执行完毕在站点文件下生成public文件夹，包含所有静态文件&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;dl&gt;&#xA;&lt;dt&gt;在站点文件夹中直接执行 &lt;code&gt;ljgo build&lt;/code&gt; ， 或是在站点文件夹外执行但是得指定站点路径 eg&lt;/dt&gt;&#xA;&lt;dd&gt;&lt;code&gt;ljgo build example.com&lt;/code&gt;&#xA;&lt;code&gt;ljgo serve&lt;/code&gt; &lt;code&gt;ljgo publis&lt;/code&gt; 都是同样的使用姿势&lt;/dd&gt;&#xA;&lt;/dl&gt;&#xA;&#xA;&lt;h4&gt;本地预览&lt;/h4&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;ligo serve&#xA;# 打来浏览器, 访问你在站点配置中填入的端口地址&#xA;# 默认是 http://localhost:3000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;当然你也可以直接将 &lt;code&gt;ljgo serve&lt;/code&gt; 运行在 &lt;code&gt;vps&lt;/code&gt; 上&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;部署&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;你可以使用 &lt;a href=&#34;https://pages.github.com/&#34;&gt;github pages&lt;/a&gt; 等服务，或者放到你的自己的vps下，因为是纯静态文件,不需要php/mysql/java等环境的支持&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;ljgo publish&#xA;# 执行站点配置中填写的发布脚本&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;eg : 使用 &lt;code&gt;github&lt;/code&gt;服务， 初始化好 &lt;code&gt;public&lt;/code&gt;  文件夹后，我们只需要在 &lt;code&gt;config.yml&lt;/code&gt; 文件中的填写如下内容：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;publish:&#xA;    cmd: |&#xA;        git add -A&#xA;        git commit -m &amp;quot;update&amp;quot;&#xA;        git push origin&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这样我们在每次编辑完博客后直接运行 &lt;code&gt;ljgo publish&lt;/code&gt; 就一切ok&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;关于主题&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;由于自己比较懒，目前的默认主题是从 &lt;a href=&#34;https://startbootstrap.com&#34;&gt;start bootstrapt&lt;/a&gt; 中的 &lt;a href=&#34;https://startbootstrap.com/template-overviews/clean-blog/&#34;&gt;clean-blog&lt;/a&gt; 修改而来&#xA;当导入其他主题，需要把主题文件夹复制到 &lt;code&gt;example.com/themes/&lt;/code&gt; 文件夹下，并修改站点配置 &lt;code&gt;config.yml&lt;/code&gt; 中主题路径&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;十分欢迎大家贡献第三方主题 👏&lt;/h4&gt;&#xA;&#xA;&lt;h2&gt;正在使用&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cwen.pw&#34;&gt;cwen&amp;rsquo;s blog&lt;/a&gt;           - me&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;期待更多的用户&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;反馈贡献&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;非常欢迎任何人的任何贡献。如有问题可报告至 &lt;a href=&#34;https://github.com/cwen-coder/ljgo/issues&#34;&gt;https://github.com/cwen-coder/ljgo/issues&lt;/a&gt;。&#xA;或是直接发邮件To me &lt;a href=&#34;mailto:yincwengo@gmail.com&#34;&gt;yincwengo@gmail.com&lt;/a&gt;&lt;/p&gt;&#xA;</content>
    <link href="http://int64.me/2016/ljgo - 静态博客引擎(0.1.0-beta版).html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>go笔记-GC</title>
    <updated>2016-08-20T00:00:00Z</updated>
    <id>tag:int64.me,2016-08-20:/2016/go笔记-GC.html</id>
    <content type="html">&lt;p&gt;GO “非分代的、非紧缩、写屏障、并发标记清理”&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;并发清理： 垃圾回收(清理过程)与用户逻辑并发执行&#xA;  三色并发标记 :  标记与用户逻辑并发执行&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;一般常用垃圾回收方法&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;引用计数&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;这是最简单的一种垃圾回收算法，和之前提到的智能指针异曲同工。对每个对象维护一个 引用计数 ，当引用该对象的对象被销毁或更新时被引用对象的引用计数自动减一，当被引用对象被创建或被赋值给其他对象时引用计数自动加一。当引用计数为0时则立即回收对象。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;优点&lt;/h4&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;是实现简单，并且内存的回收很及时。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h4&gt;缺点&lt;/h4&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;频繁更新引用计数降低了性能&#xA;循环引用问题&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;标记-清除&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;该方法分为两步， 标记 从根变量开始迭代得遍历所有被引用的对象，对能够通过应用遍历访问到的对象都进行标记为“被引用”；标记完成后进行 清除 操作，对没有标记过的内存进行回收（回收同时可能伴有碎片整理操作）。这种方法解决了引用计数的不足，但是也有比较明显的问题：每次启动垃圾回收都会暂停当前所有的正常代码执行，回收是系统响应能力大大降低！当然后续也出现了很多mark&amp;amp;sweep算法的变种（如 三色标记法 ）优化了这个问题。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分代收集&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;经过大量实际观察得知，在面向对象编程语言中，绝大多数对象的生命周期都非常短。分代收集的基本思想是，将堆划分为两个或多个称为 代（generation） 的空间。新创建的对象存放在称为 新生代（young generation） 中（一般来说，新生代的大小会比 老年代 小很多），随着垃圾回收的重复执行，生命周期较长的对象会被 提升（promotion） 到老年代中。因此，新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生，分别用于对各自空间中的对象执行垃圾回收。新生代垃圾回收的速度非常快，比老年代快几个数量级，即使新生代垃圾回收的频率更高，执行效率也仍然比老年代垃圾回收强，这是因为大多数对象的生命周期都很短，根本无需提升到老年代。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;三色并发标记 (1.5之后使用GC方法)&lt;/h2&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;In a tri-color collector, every object is either white, grey, or black and we view the heap as a graph of connected objects. At the start of a GC cycle all objects are white. The GC visits all roots, which are objects directly accessible by the application such as globals and things on the stack, and colors these grey. The GC then chooses a grey object, blackens it, and then scans it for pointers to other objects. When this scan finds a pointer to a white object, it turns that object grey. This process repeats until there are no more grey objects. At this point, white objects are known to be unreachable and can be reused.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;这是让标记与用户代码并发的基本保障， 基本原理：&#xA;* 起初所有对象都是白色&#xA;* 扫描所有可达对象，标记为灰色，放入待处理队列&#xA;* 从队列提取灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色&#xA;* 写屏障监控对象内存修改，从新标色或是放入队列&lt;/p&gt;&#xA;&#xA;&lt;p&gt;当完成所有的扫描和标记的工作后，剩余不是白色就是黑色，分别代表要回收和活跃对象，清理操作只需要把白色对象回收内存回收就好&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Animation_of_tri-color_garbage_collection.gif&#34; alt=&#34;三色并发标记&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;增量&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;三色标记的目的，主要是用于做增量的垃圾回收。注意到，如果只有黑色和白色两种颜色，那么回收过程将不能中断，必须一次性完成，期间用户程序是不能运行的。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;而使用三色标记，即使在标记过程中对象的引用关系发生了改变，例如分配内存并修改对象属性域的值，只要满足黑色对象不引用白色对象的约束条件，垃圾回收器就可以继续正常工作。于是每次并不需要将回收过程全部执行完，只是处理一部分后停下来，后续会慢慢再次触发的回收过程，实现增量回收。相当于是把垃圾回收过程打散，减少停顿时间。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;写屏障 (write barrier)&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;如果是STW的，三色标记没有什么问题。但是如果允许用户代码跟垃圾回收同时运行，需要维护一条约束条件：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;黑色对象绝对不能引用白色对象&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;为什么不能让黑色引用白色？因为黑色对象是活跃对象，它引用的对象是也应该属于活跃的，不应该被清理。但是，由于在三色标记算法中，黑色对象已经处理完毕，它不会被重复扫描。那么，这个对象引用的白色对象将没有机会被着色，最终会被误当作垃圾清理。&#xA;STW中，一个对象，只有它引用的对象全标记后才会标记为黑色。所以黑色对象要么引用的黑色对象，要么引用的灰色对象。不会出现黑色引用白色对象。&#xA;对于垃圾回收和用户代码并行的场景，用户代码可能会修改已经标记为黑色的对象，让它引用白色对象。看一个例子来说明这个问题：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;stack -&amp;gt; A.ref -&amp;gt; B&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;A是从栈对象直接可达，将它标记为灰色。此时B是白色对象。假设这个时候用户代码执行：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;localRef = A.ref&#xA;A.ref = NULL&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;localRef是栈上面的一个黑色对象，前一行赋值语句使得它引用到B对象。后一行A.ref被置为空之后，A将不再引用到B。A是灰色但是不再引用到B了，B不会着色。localRef是黑色，处理完毕的对象，引用了B但是不会被再次处理。于是B将永远不再有机会被标记，它会被误当作垃圾清理掉！&lt;/p&gt;&#xA;&#xA;&lt;p&gt;如果实现满足这种约束条件呢？write barrier!&#xA;来自wiki的对这个术语的解释：&amp;rdquo;A write barrier in a garbage collector is a fragment of code emitted by the compiler immediately before every store operation to ensure that (e.g.) generational invariants are maintained.&amp;rdquo; 即是说，在每一处内存写操作的前面，编译器会生成的一小段代码段，来确保不要打破一些约束条件。&#xA;增量和分代，都需要维护一个write barrier。&#xA;先看分代的垃圾回收，跨越不同分代之间的引用，需要特别注意。通常情况下，大多数的交叉引用应该是由新生代对象引用老生代对象。当我们回收新生代的时候，这没有什么问题。但是当我们回收老生代的时候，如果只扫描老生代不扫描新生代，则老生代中的一些对象可能被误当作不可达对象回收掉！为了处理这种情况，可以做一个约定&amp;ndash;如果回收老生代，那么比它年轻的新生代都要一起回收一遍。另外一种交叉引用是老生代对象引用到新生代对象，这时就需要write barrier了，所有的这种类型引用都应该记录下来，放到一个集合中，标记的时候要处理这个集合。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;再看三色标记中，黑色对象不能引用白色对象。这就是一个约束条件，write barrier就是要维护这条约束。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;go1.5  GC 实现过程&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/gc.png&#34; alt=&#34;gc 过程&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;Go1.5垃圾回收的实现被划分为五个阶段：&lt;/h4&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GCoff 垃圾回收关闭状态&lt;/li&gt;&#xA;&lt;li&gt;GCscan 扫描阶段&lt;/li&gt;&#xA;&lt;li&gt;GCmark 标记阶段，write barrier生效&lt;/li&gt;&#xA;&lt;li&gt;GCmarktermination 标记结束阶段，STW，分配黑色对象&lt;/li&gt;&#xA;&lt;li&gt;GCsweep 清扫阶段&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/gogc.png&#34; alt=&#34;gc  过程&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;控制器&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;全程参与并发回收任务， 记录相关状态数据， 动态调整运行策略，影响并发标记工作单元的工作模式和数量， 平衡CPU资源占用。当回收结束时，参与next_gc 回收阀值设置，调整垃圾回收触发频率&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;过程&lt;/h4&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;初始化&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;设置 &lt;code&gt;gcprecent(GOGC)&lt;/code&gt; 和 &lt;code&gt;next_gc&lt;/code&gt; 阀值&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;启动&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在为对象分配堆内存后，&lt;code&gt;mallocgo&lt;/code&gt; 函数会检查垃圾回收触发条件，并依照相关状态启动或参与辅助回收&#xA;垃圾回收默认以全并发，但可用环境变量或事参数禁用并发标记和并发清理，gc goroutine 一直循环，直到符合触发条件时被唤醒&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;标记&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;分俩步骤&#xA;&amp;gt; 扫描 ：遍历相关内存区域，依照指针标记找出灰色可达对象，加入队列 。扫描函数 (gcscan_m) 启动时，用户代码和标记函数 (MarkWorker) 都在运行&#xA;&amp;gt; 标记 ： 将灰色对象从队列中取出，将其应用对象标记为灰色，自身标记为黑色。 并发标记由多个MarkWorker goroutine 共同完成，它们在回收任务完成前绑定到 P ， 然后进入休眠状态，知道被调度器唤醒&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;清理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;清理未被标记的白色对象 ，将其内存回收&lt;/p&gt;&#xA;&#xA;&lt;p&gt;并发清理本质上是一个死循环，被唤醒后开始执行清理任务。 通过遍历所有span 对象，触发内存回收器的回收操作。任务完成后，再次休眠，等待下次任务&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;监控&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;模拟情景：服务重启，海量服务重新接入，瞬间分配大量对象，将垃圾回收触发阀值next_gc推到一个很大的值。而当服务正常后，因活跃对象远小于该阀值，造成垃圾回收迟迟无法触发，大量白色对象无法回收，造成隐形内存泄漏。同样情景也有可能由于某个算法在短期内大量使用临时变量造成 。&#xA;这个时候只有forcegc介入，才能将next_gc恢复正常， 监控服务sysmon每隔两分钟检查一次垃圾回收状态，如果超过两分钟未曾触发，就会强制执行gc&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;gc 过程中几种辅助结构&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;parfor 并行任务框架 ： 关注的是任务的分配和调度，自身不具备执行能力。它将多个任务分组交给多个执行线程。然后在执行过程中重新平衡线程的任务分配，确保整个任务在最短的时间内完成&#xA;缓存队列： workbuf 无锁栈节点，本身是一个缓存容器&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h3&gt;问题&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;go程序内存占用大的问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;我们模拟大量的用户请求访问后台服务，这时各服务模块能观察到明显的内存占用上升。但是当停止压测时，内存占用并未发生明显的下降。花了很长时间定位问题，使用gprof等各种方法，依然没有发现原因。最后发现原来这时正常的…主要的原因有两个，&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一是go的垃圾回收有个触发阈值，这个阈值会随着每次内存使用变大而逐渐增大（如初始阈值是10MB则下一次就是20MB，再下一次就成为了40MB…），如果长时间没有触发gc go会主动触发一次（2min）。高峰时内存使用量上去后，除非持续申请内存，靠阈值触发gc已经基本不可能，而是要等最多2min主动gc开始才能触发gc。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;第二个原因是go语言在向系统交还内存时只是告诉系统这些内存不需要使用了，可以回收；同时操作系统会采取“拖延症”策略，并不是立即回收，而是等到系统内存紧张时才会开始回收这样该程序又重新申请内存时就可以获得极快的分配速度。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;gc时间长的问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;对于对用户响应事件有要求的后端程序，golang gc时的stop the world兼职是噩梦。根据上文的介绍，1.5版本的go再完成上述改进后应该gc性能会提升不少，但是所有的垃圾回收型语言都难免在gc时面临性能下降，对此我们对于应该尽量避免频繁创建临时堆对象（如&amp;amp;abc{}, new, make等）以减少垃圾收集时的扫描时间，对于需要频繁使用的临时对象考虑直接通过数组缓存进行重用；很多人采用cgo的方法自己管理内存而绕开垃圾收集，这种方法除非迫不得已个人是不推荐的（容易造成不可预知的问题），当然迫不得已的情况下还是可以考虑的，这招带来的效果还是很明显的~&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;goroutine泄露的问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;我们的一个服务需要处理很多长连接请求，实现时，对于每个长连接请求各开了一个读取和写入协程，全部采用endless for loop不停地处理收发数据。当连接被远端关闭后，如果不对这两个协程做处理，他们依然会一直运行，并且占用的channel也不会被释放…这里就必须十分注意，在不使用协程后一定要把他依赖的channel close并通过再协程中判断channel是否关闭以保证其退出。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;如何测量GC&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ go build -gcflags &amp;quot;-l&amp;quot; -o test test.go&#xA;$ GODEBUG=&amp;quot;gctrace=1&amp;quot; ./test&#xA;&#xA;gctrace: setting gctrace=1 causes the garbage collector to emit a single line to standard&#xA;error at each collection, summarizing the amount of memory collected and the&#xA;length of the pause. Setting gctrace=2 emits the same summary but also&#xA;repeats each collection.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;之前说了那么多，那如何测量gc的之星效率，判断它到底是否对程序的运行造成了影响呢？ 第一种方式是设置godebug的环境变量，比如运行GODEBUG=gctrace=1 ./myserver，如果要想对于输出结果了解，还需要对于gc的原理进行更进一步的深入分析，这篇文章的好处在于，清晰的之处了golang的gc时间是由哪些因素决定的，因此也可以针对性的采取不同的方式提升gc的时间：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;根据之前的分析也可以知道，golang中的gc是使用标记清楚法，所以gc的总时间为：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tgc = Tseq + Tmark + Tsweep(T表示time)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tseq表示是停止用户的 goroutine 和做一些准备活动（通常很小）需要的时间&#xA;Tmark 是堆标记时间，标记发生在所有用户 goroutine 停止时，因此可以显著地影响处理的延迟&#xA;Tsweep 是堆清除时间，清除通常与正常的程序运行同时发生，所以对延迟来说是不太关键的&#xA;之后粒度进一步细分，具体的概念还是有些不太懂：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;与Tmark相关的：1 垃圾回收过程中，堆中活动对象的数量，2 带有指针的活动对象占据的内存总量 3 活动对象中的指针数量。&#xA;与Tsweep相关的：1 堆内存的总量 2 堆中的垃圾总量&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;如何进行gc调优（gopher大会 Danny）&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;硬性参数&lt;/p&gt;&#xA;&#xA;&lt;p&gt;涉及算法的问题，总是会有些参数。GOGC参数主要控制的是下一次gc开始的时候的内存使用量。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;比如当前的程序使用了4M的对内存（这里说的是堆内存），即是说程序当前reachable的内存为4m，当程序占用的内存达到reachable*(1+GOGC/100)=8M的时候，gc就会被触发，开始进行相关的gc操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;如何对GOGC的参数进行设置，要根据生产情况中的实际场景来定，比如GOGC参数提升，来减少GC的频率。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;参考&lt;/h3&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.golang.org/go15gc&#34;&gt;go15gc&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://talks.golang.org/2015/go-gc.pdf&#34;&gt;https://talks.golang.org/2015/go-gc.pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://dave.cheney.net/tag/godebug&#34;&gt;http://dave.cheney.net/tag/godebug&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/qyuhen/book&#34;&gt;1.5源码分析&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.open-open.com/lib/view/open1435846881544.html&#34;&gt;golang gc 探究&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://wangzhezhe.github.io/blog/2016/04/30/golang-gc/&#34;&gt;golang gc 基本知识&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.oschina.net/translate/debugging-performance-issues-in-go-programs&#34;&gt;go 性能调试问题&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2016/go笔记-GC.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>context 包解读</title>
    <updated>2016-07-31T00:00:00Z</updated>
    <id>tag:int64.me,2016-07-31:/2016/context 包解读.html</id>
    <content type="html">&lt;p&gt;&lt;code&gt;context&lt;/code&gt; 包困扰我好久，之前在  &lt;code&gt;watch etcd&lt;/code&gt; 的时候首次上手使用这个包，当时并不理解这个包的作用，只知道可以用来关闭 &lt;code&gt;watch&lt;/code&gt; ， 后来被大牛吐槽了，决定深入探究一番。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;简介&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;golang&lt;/code&gt; 中的创建一个新的 &lt;code&gt;goroutine&lt;/code&gt; , 并不会返回像c语言类似的pid，所有我们不能从外部杀死某个goroutine，所有我就得让它自己结束，之前我们用 &lt;code&gt;channel ＋ select&lt;/code&gt; 的方式，来解决这个问题，但是有些场景实现起来比较麻烦，例如由一个请求衍生出的各个 &lt;code&gt;goroutine&lt;/code&gt; 之间需要满足一定的约束关系，以实现一些诸如有效期，中止routine树，传递请求全局变量之类的功能。于是google 就为我们提供一个解决方案，开源了 &lt;code&gt;context&lt;/code&gt; 包。使用 &lt;code&gt;context&lt;/code&gt; 实现上下文功能约定需要在你的方法的传入参数的第一个传入一个 &lt;code&gt;context.Context&lt;/code&gt; 类型的变量。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;源码剖析&lt;/h4&gt;&#xA;&#xA;&lt;h6&gt;context.Context 接口&lt;/h6&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;context&lt;/code&gt; 包的核心&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;//  context 包里的方法是线程安全的，可以被多个 goroutine 使用    &#xA;type Context interface {               &#xA;    // 当Context 被 canceled 或是 times out 的时候，Done 返回一个被 closed 的channel      &#xA;    Done() &amp;lt;-chan struct{}        &#xA;    &#xA;    // 在 Done 的 channel被closed 后， Err 代表被关闭的原因   &#xA;    Err() error &#xA;&#xA;    // 如果存在，Deadline 返回Context将要关闭的时间  &#xA;    Deadline() (deadline time.Time, ok bool)&#xA;&#xA;    // 如果存在，Value 返回与 key 相关了的值，不存在返回 nil  &#xA;    Value(key interface{}) interface{}&#xA;}      &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;我们不需要手动实现这个接口，&lt;code&gt;context&lt;/code&gt; 包已经给我们提供了两个，一个是 &lt;code&gt;Background()&lt;/code&gt;，一个是 &lt;code&gt;TODO()&lt;/code&gt;，这两个函数都会返回一个 &lt;code&gt;Context&lt;/code&gt; 的实例。只是返回的这两个实例都是空 &lt;code&gt;Context&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;h6&gt;主要结构&lt;/h6&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;cancelCtx&lt;/code&gt; 结构体继承了 &lt;code&gt;Context&lt;/code&gt; ，实现了 &lt;code&gt;canceler&lt;/code&gt; 方法：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;//*cancelCtx 和 *timerCtx 都实现了canceler接口，实现该接口的类型都可以被直接canceled&#xA;type canceler interface {&#xA;    cancel(removeFromParent bool, err error)&#xA;    Done() &amp;lt;-chan struct{}&#xA;}        &#xA;&#xA;type cancelCtx struct {&#xA;    Context&#xA;    done chan struct{} // closed by the first cancel call.&#xA;    mu       sync.Mutex&#xA;    children map[canceler]bool // set to nil by the first cancel call&#xA;    err      error             // 当其被cancel时将会把err设置为非nil&#xA;}&#xA;&#xA;func (c *cancelCtx) Done() &amp;lt;-chan struct{} {&#xA;    return c.done&#xA;}&#xA;&#xA;func (c *cancelCtx) Err() error {&#xA;    c.mu.Lock()&#xA;    defer c.mu.Unlock()&#xA;    return c.err&#xA;}&#xA;&#xA;func (c *cancelCtx) String() string {&#xA;    return fmt.Sprintf(&amp;quot;%v.WithCancel&amp;quot;, c.Context)&#xA;}&#xA;&#xA;//核心是关闭c.done&#xA;//同时会设置c.err = err, c.children = nil&#xA;//依次遍历c.children，每个child分别cancel&#xA;//如果设置了removeFromParent，则将c从其parent的children中删除&#xA;func (c *cancelCtx) cancel(removeFromParent bool, err error) {&#xA;    if err == nil {&#xA;        panic(&amp;quot;context: internal error: missing cancel error&amp;quot;)&#xA;    }&#xA;    c.mu.Lock()&#xA;    if c.err != nil {&#xA;        c.mu.Unlock()&#xA;        return // already canceled&#xA;    }&#xA;    c.err = err&#xA;    close(c.done)&#xA;    for child := range c.children {&#xA;        // NOTE: acquiring the child&#39;s lock while holding parent&#39;s lock.&#xA;        child.cancel(false, err)&#xA;    }&#xA;    c.children = nil&#xA;    c.mu.Unlock()&#xA;&#xA;    if removeFromParent {&#xA;        removeChild(c.Context, c) // 从此处可以看到 cancelCtx的Context项是一个类似于parent的概念&#xA;    }&#xA;}         &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;timerCtx&lt;/code&gt; 结构继承 &lt;code&gt;cancelCtx&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;type timerCtx struct {&#xA;    cancelCtx //此处的封装为了继承来自于cancelCtx的方法，cancelCtx.Context才是父亲节点的指针&#xA;    timer *time.Timer // Under cancelCtx.mu. 是一个计时器&#xA;    deadline time.Time&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;valueCtx&lt;/code&gt; 结构继承 &lt;code&gt;cancelCtx&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;type valueCtx struct {&#xA;    Context&#xA;    key, val interface{}&#xA;}        &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h6&gt;主要方法&lt;/h6&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func WithCancel(parent Context) (ctx Context, cancel CancelFunc)&#xA;func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)&#xA;func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)&#xA;func WithValue(parent Context, key interface{}, val interface{}) Context&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;WithCancel&lt;/code&gt; 对应的是 &lt;code&gt;cancelCtx&lt;/code&gt; ,其中，返回一个 &lt;code&gt;cancelCtx&lt;/code&gt; ，同时返回一个 &lt;code&gt;CancelFunc&lt;/code&gt;，&lt;code&gt;CancelFunc&lt;/code&gt; 是 &lt;code&gt;context&lt;/code&gt; 包中定义的一个函数类型：&lt;code&gt;type CancelFunc func()&lt;/code&gt;。调用这个 &lt;code&gt;CancelFunc&lt;/code&gt; 时，关闭对应的c.done，也就是让他的后代&lt;code&gt;goroutine&lt;/code&gt;退出。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;WithDeadline&lt;/code&gt; 和 &lt;code&gt;WithTimeout&lt;/code&gt; 对应的是 &lt;code&gt;timerCtx&lt;/code&gt; ，&lt;code&gt;WithDeadline&lt;/code&gt; 和 &lt;code&gt;WithTimeout&lt;/code&gt; 是相似的，&lt;code&gt;WithDeadline&lt;/code&gt; 是设置具体的 &lt;code&gt;deadline&lt;/code&gt; 时间，到达 &lt;code&gt;deadline&lt;/code&gt; 的时候，后代 &lt;code&gt;goroutine&lt;/code&gt; 退出，而 WithTimeout 简单粗暴，直接 &lt;code&gt;return WithDeadline(parent, time.Now().Add(timeout))&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;WithValue&lt;/code&gt; 对应 &lt;code&gt;valueCtx&lt;/code&gt; ，&lt;code&gt;WithValue&lt;/code&gt; 是在 &lt;code&gt;Context&lt;/code&gt; 中设置一个 map，拿到这个 &lt;code&gt;Context&lt;/code&gt; 以及它的后代的 &lt;code&gt;goroutine&lt;/code&gt; 都可以拿到 map 里的值。&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;详细 context 包源码解读: &lt;a href=&#34;http://studygolang.com/articles/5131&#34;&gt;go源码解读&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h4&gt;使用原则&lt;/h4&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;Context&lt;/code&gt; 的程序包需要遵循如下的原则来满足接口的一致性以及便于静态分析&lt;/li&gt;&#xA;&lt;li&gt;不要把 &lt;code&gt;Context&lt;/code&gt; 存在一个结构体当中，显式地传入函数。&lt;code&gt;Context&lt;/code&gt; 变量需要作为第一个参数使用，一般命名为&lt;code&gt;ctx&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;即使方法允许，也不要传入一个 &lt;code&gt;nil&lt;/code&gt; 的 &lt;code&gt;Context&lt;/code&gt; ，如果你不确定你要用什么 &lt;code&gt;Context&lt;/code&gt; 的时候传一个 &lt;code&gt;context.TODO&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;context&lt;/code&gt; 的 &lt;code&gt;Value&lt;/code&gt; 相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数&lt;/li&gt;&#xA;&lt;li&gt;同样的 &lt;code&gt;Context&lt;/code&gt; 可以用来传递到不同的 &lt;code&gt;goroutine&lt;/code&gt; 中，&lt;code&gt;Context&lt;/code&gt; 在多个&lt;code&gt;goroutine&lt;/code&gt; 中是安全的&lt;br /&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h4&gt;使用示例&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;例子copy自: &lt;a href=&#34;https://github.com/eleme/sre/blob/master/context.md&#34;&gt;关于 Golang 中的 context 包的介绍&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;package main&#xA;&#xA;import (&#xA;    &amp;quot;fmt&amp;quot;&#xA;    &amp;quot;time&amp;quot;&#xA;    &amp;quot;golang.org/x/net/context&amp;quot;&#xA;)&#xA;&#xA;// 模拟一个最小执行时间的阻塞函数&#xA;func inc(a int) int {&#xA;    res := a + 1                // 虽然我只做了一次简单的 +1 的运算,&#xA;    time.Sleep(1 * time.Second) // 但是由于我的机器指令集中没有这条指令,&#xA;    // 所以在我执行了 1000000000 条机器指令, 续了 1s 之后, 我才终于得到结果。B)&#xA;    return res&#xA;}&#xA;&#xA;// 向外部提供的阻塞接口&#xA;// 计算 a + b, 注意 a, b 均不能为负&#xA;// 如果计算被中断, 则返回 -1&#xA;func Add(ctx context.Context, a, b int) int {&#xA;    res := 0&#xA;    for i := 0; i &amp;lt; a; i++ {&#xA;        res = inc(res)&#xA;        select {&#xA;        case &amp;lt;-ctx.Done():&#xA;            return -1&#xA;        default:&#xA;        }&#xA;    }&#xA;    for i := 0; i &amp;lt; b; i++ {&#xA;        res = inc(res)&#xA;        select {&#xA;        case &amp;lt;-ctx.Done():&#xA;            return -1&#xA;        default:&#xA;        }&#xA;    }&#xA;    return res&#xA;}&#xA;&#xA;func main() {&#xA;    {&#xA;        // 使用开放的 API 计算 a+b&#xA;        a := 1&#xA;        b := 2&#xA;        timeout := 2 * time.Second&#xA;        ctx, _ := context.WithTimeout(context.Background(), timeout)&#xA;        res := Add(ctx, 1, 2)&#xA;        fmt.Printf(&amp;quot;Compute: %d+%d, result: %d\n&amp;quot;, a, b, res)&#xA;    }&#xA;    {&#xA;        // 手动取消&#xA;        a := 1&#xA;        b := 2&#xA;        ctx, cancel := context.WithCancel(context.Background())&#xA;        go func() {&#xA;            time.Sleep(2 * time.Second)&#xA;            cancel() // 在调用处主动取消&#xA;        }()&#xA;        res := Add(ctx, 1, 2)&#xA;        fmt.Printf(&amp;quot;Compute: %d+%d, result: %d\n&amp;quot;, a, b, res)&#xA;    }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;官方完整示例:&lt;br /&gt;&#xA;&lt;a href=&#34;https://blog.golang.org/context/server/server.go&#34;&gt;server&lt;/a&gt;&lt;br /&gt;&#xA;&lt;a href=&#34;https://blog.golang.org/context/userip/userip.go&#34;&gt;userip&lt;/a&gt;&lt;br /&gt;&#xA;&lt;a href=&#34;https://blog.golang.org/context/google/google.go&#34;&gt;google&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;部分参考：&lt;br /&gt;&#xA;&lt;a href=&#34;http://studygolang.com/articles/5131&#34;&gt;go源码解读&lt;/a&gt;&lt;br /&gt;&#xA;&lt;a href=&#34;https://github.com/eleme/sre/blob/master/context.md&#34;&gt;关于 Golang 中的 context 包的介绍&lt;/a&gt;&lt;br /&gt;&#xA;&lt;a href=&#34;http://blog.golang.org/context&#34;&gt;官方博客&lt;/a&gt;&lt;br /&gt;&#xA;Thanks&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;</content>
    <link href="http://int64.me/2016/context 包解读.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>初识 Docker</title>
    <updated>2016-06-23T00:00:00Z</updated>
    <id>tag:int64.me,2016-06-23:/2016/初识 Docker.html</id>
    <content type="html">&lt;p&gt;Docker 是一个开源的应用容器引擎，使用 golang 开发实现，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。&lt;br /&gt;&#xA;Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。&lt;br /&gt;&#xA;在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;Docker 组成&lt;/h4&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Image - 镜像&lt;/li&gt;&#xA;&lt;li&gt;Containter - 容器&lt;/li&gt;&#xA;&lt;li&gt;Docker hub - 仓库&lt;br /&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h4&gt;安装 Docker&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;安装 Docker 要求 linux 内核版本不低于 3.13，Docker 依赖 linux 内核，使用 linux 的 namespae 实现进程的隔离，cgroup 来对资源的控制。(docker 与 linux 内核的关系以后单独研究，其实目前我不是太清楚，不敢瞎说) 如果你的内核版本低于 3.13，请自行 google 升级内核。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;查看自己内核版本信息&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ uname -a&#xA;Linux Host 3.16.0-43-generic #58~14.04.1-Ubuntu SMP Mon Jun 22 10:21:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;或者&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ cat /proc/version&#xA;Linux version 3.16.0-43-generic (buildd@brownie) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #58~14.04.1-Ubuntu SMP Mon Jun 22 10:21:20 UTC 2015&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4&gt;Ubuntu 安装&lt;/h4&gt;&#xA;&#xA;&lt;h6&gt;更新APT镜像源&lt;/h6&gt;&#xA;&#xA;&lt;p&gt;安装 apt-transport-https 包支持 https 协议的源&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; $ sudo apt-get update &#xA; $ sudo apt-get install apt-transport-https ca-certificates&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;添加新的 gpg 密钥&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D   &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;添加 Docker 的官方 apt 软件源&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/apt/sources.list.d/docker.list&#xA;deb https://apt.dockerproject.org/repo ubuntu-trusty main&#xA;EOF  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;非 trusty 版本的系统注意修改为自己对应的代号&lt;br /&gt;&#xA;deb &lt;a href=&#34;https://apt.dockerproject.org/repo&#34;&gt;https://apt.dockerproject.org/repo&lt;/a&gt; ubuntu-precise main&lt;br /&gt;&#xA;deb &lt;a href=&#34;https://apt.dockerproject.org/repo&#34;&gt;https://apt.dockerproject.org/repo&lt;/a&gt; ubuntu-trusty main&lt;br /&gt;&#xA;deb &lt;a href=&#34;https://apt.dockerproject.org/repo&#34;&gt;https://apt.dockerproject.org/repo&lt;/a&gt; ubuntu-wily main&lt;br /&gt;&#xA;deb &lt;a href=&#34;https://apt.dockerproject.org/repo&#34;&gt;https://apt.dockerproject.org/repo&lt;/a&gt; ubuntu-xenial main&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;更新 apt 软件包缓存&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get update   &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;如果系统中存在老版本的 Docker，请先删除&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get purge lxc-docker    &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;检查 apt 源是否发生改变&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ apt-cache policy docker-engine   &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h6&gt;更新系统内核和安装可能需要的软件包&lt;/h6&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install linux-image-extra-$(uname -r)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;code&gt;linux-image-extra&lt;/code&gt; 允许你使用 &lt;code&gt;aufs&lt;/code&gt; 文件系统&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h6&gt;安装 Docker&lt;/h6&gt;&#xA;&#xA;&lt;p&gt;更新 apt 源&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get update &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;安装 Docker&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install docker-engine     &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;启动 Docker 守护进程&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo service docker start  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;检查 Docker 是否安装成功&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo docker run hello-world  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h6&gt;使用脚本安装 Docker&lt;/h6&gt;&#xA;&#xA;&lt;p&gt;使用官方提供的安装脚本, 使用脚本我们可以直接运行，之前的步骤都可以省略&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo-i&#xA;$ wget -qO- https://get.docker.com/ | sh  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h6&gt;把当前用户加入 Docker 用户组&lt;/h6&gt;&#xA;&#xA;&lt;p&gt;运行 Docker 需 root 权限， 为了我们不必一直使用 root 权限，我们可以把用户加进 Docker 用户组&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ sudo usermod -a -G docker [username]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Ubuntu is all set up!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;</content>
    <link href="http://int64.me/2016/初识 Docker.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>jQuery 中 attr() 和 prop() 方法</title>
    <updated>2016-03-09T00:00:00Z</updated>
    <id>tag:int64.me,2016-03-09:/2016/jQuery 中 attr() 和 prop() 方法.html</id>
    <content type="html">&lt;p&gt;昨天在使用JQuery实现一个一键全选的功能的时候，在设置 &lt;code&gt;checkbox&lt;/code&gt; 属性后，只是在第一有效，过后的N次一直无法改变。一开始还以为自己代码是不是神马地方的逻辑出了问题，可是在检查的多次之后依然无法找到答案，最后只能求助Google(按常理来说一般先翻文档),先上我之前出问题的代码。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;(function() {&#xA;    var dom = {&#xA;        dbTransferAll : $(&#39;#dbTransferAll&#39;),&#xA;        dbCollections : $(&amp;quot;form div:first input[name=&#39;collection&#39;]&amp;quot;)&#xA;    }&#xA;&#xA;    var dbTransfer = {&#xA;        init : function() {&#xA;            this.eventFn();&#xA;        },&#xA;&#xA;        eventFn : function() {&#xA;            dom.dbTransferAll.bind(&#39;click&#39;,function() {&#xA;                &#xA;                if (this.checked == true) {&#xA;                    dom.dbCollections.attr(&amp;quot;checked&amp;quot;,true);&#xA;                } else {&#xA;                    dom.dbCollections.attr(&amp;quot;checked&amp;quot;, false); &#xA;                }&#xA;                &#xA;            });&#xA;        }&#xA;    }&#xA;    dbTransfer.init();&#xA;})();&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;最后通过诸位大神的博客得知，是使用了 &lt;code&gt;attr()&lt;/code&gt; 方法的问题， 在JQuery在1.6版本之后新增了一个 &lt;code&gt;prop()&lt;/code&gt; 方法(羞愧啊！一直不知道),应该使用 &lt;code&gt;prop()&lt;/code&gt; 方法替换 &lt;code&gt;attr()&lt;/code&gt; 。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;为什么要新加 &lt;code&gt;prop()&lt;/code&gt; 方法&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;jQuery 1.6之前 ，&lt;code&gt;attr()&lt;/code&gt; 方法在取某些 &lt;code&gt;attribute&lt;/code&gt; 的值时，会返回 &lt;code&gt;property&lt;/code&gt; 的值，这就导致了结果的不一致。从 jQuery 1.6 开始， &lt;code&gt;prop()&lt;/code&gt; 方法 方法返回 &lt;code&gt;property&lt;/code&gt; 的值,而 &lt;code&gt;attr()&lt;/code&gt; 方法返回 &lt;code&gt;attributes&lt;/code&gt; 的值。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;attribute和property的区别&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;attribute&lt;/code&gt; 翻译成中文术语为“特性”，&lt;code&gt;property&lt;/code&gt; 翻译成中文术语为“属性”，从中文的字面意思来看，确实是有点区别了，先来说说&lt;code&gt;attribute&lt;/code&gt; 。&lt;br /&gt;&#xA;attribute是一个特性节点，每个DOM元素都有一个对应的 &lt;code&gt;attributes&lt;/code&gt; 属性来存放所有的 &lt;code&gt;attribute&lt;/code&gt; 节点，&lt;code&gt;attributes&lt;/code&gt; 是一个类数组的容器，说得准确点就是 &lt;code&gt;NameNodeMap&lt;/code&gt;，总之就是一个类似数组但又和数组不太一样的容器。&lt;code&gt;attributes&lt;/code&gt; 的每个数字索引以名值对 &lt;code&gt;(name=”value”)&lt;/code&gt; 的形式存放了一个 &lt;code&gt;attribute&lt;/code&gt; 节点。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;box&amp;quot; id=&amp;quot;box&amp;quot; gameid=&amp;quot;880&amp;quot;&amp;gt;hello&amp;lt;/div&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;上面的div元素的HTML代码中有class、id还有自定义的gameid，这些特性都存放在attributes中，类似下面的形式：&#xA;view sourceprint?&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;[ class=&amp;quot;box&amp;quot;, id=&amp;quot;box&amp;quot;, gameid=&amp;quot;880&amp;quot; ]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;property&lt;/code&gt; 就是一个属性，如果把DOM元素看成是一个普通的 &lt;code&gt;Object&lt;/code&gt; 对象，那么 &lt;code&gt;property&lt;/code&gt; 就是一个以名值对&lt;code&gt;(name=”value”)&lt;/code&gt; 的形式存放在 &lt;code&gt;Object&lt;/code&gt; 中的属性。要添加和删除 &lt;code&gt;property&lt;/code&gt; 也简单多了，和普通的对象没啥分别。&lt;br /&gt;&#xA;之所以 &lt;code&gt;attribute&lt;/code&gt; 和 &lt;code&gt;property&lt;/code&gt; 容易混倄在一起的原因是，很多 &lt;code&gt;attribute&lt;/code&gt; 节点还有一个相对应的 &lt;code&gt;property&lt;/code&gt; 属性，比如上面的 &lt;code&gt;div&lt;/code&gt; 元素的 &lt;code&gt;id&lt;/code&gt; 和 &lt;code&gt;class&lt;/code&gt; 既是 &lt;code&gt;attribute&lt;/code&gt; ，也有对应的 &lt;code&gt;property&lt;/code&gt; ，不管使用哪种方法都可以访问和修改。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;DOM元素一些默认常见的 &lt;code&gt;attribute&lt;/code&gt; 节点都有与之对应的 &lt;code&gt;property&lt;/code&gt; 属性，比较特殊的是一些值为 &lt;code&gt;Boolean&lt;/code&gt; 类型的&lt;code&gt;property&lt;/code&gt;(这个地方&lt;code&gt;attr()&lt;/code&gt;与&lt;code&gt;prop()&lt;/code&gt;不同点)，如一些表单元素：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;input type=&amp;quot;radio&amp;quot; checked=&amp;quot;checked&amp;quot; id=&amp;quot;raido&amp;quot;&amp;gt;&#xA;var radio = document.getElementById( &#39;radio&#39; );&#xA;console.log( radio.getAttribute(&#39;checked&#39;) ); // checked&#xA;console.log( radio.checked ); // true&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;对于这些特殊的&lt;code&gt;attribute&lt;/code&gt;节点，只有存在该节点，对应的&lt;code&gt;property&lt;/code&gt; 的值就为true，如：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;input type=&amp;quot;radio&amp;quot; checked=&amp;quot;anything&amp;quot; id=&amp;quot;raido&amp;quot;&amp;gt;&#xA;var radio = document.getElementById( &#39;radio&#39; );&#xA;console.log( radio.getAttribute(&#39;checked&#39;) ); // anything&#xA;console.log( radio.checked ); // true&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;最后为了更好的区分&lt;code&gt;attribute&lt;/code&gt;和&lt;code&gt;property&lt;/code&gt;，基本可以总结为&lt;code&gt;attribute&lt;/code&gt;节点都是在HTML代码中可见的，而&lt;code&gt;property&lt;/code&gt;只是一个普通的名值对属性。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// gameid和id都是attribute节点&#xA;// id同时又可以通过property来访问和修改&#xA;&amp;lt;div gameid=&amp;quot;880&amp;quot; id=&amp;quot;box&amp;quot;&amp;gt;hello&amp;lt;/div&amp;gt;&#xA;// areaid仅仅是property&#xA;elem.areaid = 900;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4&gt;神马时候使用 &lt;code&gt;attr()&lt;/code&gt; ? 神马时候使用 &lt;code&gt;prop()&lt;/code&gt; ?&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;根据官方的建议：具有 &lt;code&gt;true&lt;/code&gt; 和 &lt;code&gt;false&lt;/code&gt; 两个属性的属性，如 &lt;code&gt;checked&lt;/code&gt;, &lt;code&gt;selected&lt;/code&gt; 或者 &lt;code&gt;disabled&lt;/code&gt; 使用&lt;code&gt;prop()&lt;/code&gt;，其他的使用 &lt;code&gt;attr()&lt;/code&gt; 。&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;文章部分参考 &lt;a href=&#34;http://stylechen.com/attribute-property.html&#34;&gt;attribute和property的区别&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;</content>
    <link href="http://int64.me/2016/jQuery 中 attr() 和 prop() 方法.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>golang 编程基础 - Hello,Word</title>
    <updated>2015-12-02T00:00:00Z</updated>
    <id>tag:int64.me,2015-12-02:/2015/golang 编程基础 - Hello,Word.html</id>
    <content type="html">&lt;p&gt;最近越发觉得自己的golang基础还是不够扎实,所有决定再从头捋一遍golang的基础知识&#xA;同时也为golang的爱好者们提供点入门材料.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们就从这个经典的 &lt;code&gt;Hello Word&lt;/code&gt; 案例开始吧!(先上代码)&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;//HelloWord.go&#xA;package main&#xA;&#xA;import &amp;quot;fmt&amp;quot;&#xA;&#xA;func main() {&#xA;    fmt.Println(&amp;quot;Hello, Word&amp;quot;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;接着我们打开终端&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ cd $GOPATH/src/***    //进入你的文件目录 &#xA;$ go run helloWord.go  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;毫不意外,命令会输出&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Hello,Word&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;同时我们还可以这样来干&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ go build helloWord.go  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这样你会在当前目录下找到一个可执行的二进制文件,不需要任何其他处理下,你就可以在任何时间来运行这个二进制文件了(注：因为是静态编译，所以也不用担心在系统库更新的时候冲突，幸福感满满)&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$ ./helloWord&#xA;Helllo,Word&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4&gt;代码详解&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;看到代码的第一行,熟悉 Java,Python 的同学会觉得很熟悉,没错golang也是使用 &lt;code&gt;package&lt;/code&gt; 的来组织代码的, 一个 &lt;code&gt;package&lt;/code&gt; 会包含一个或多个&lt;code&gt;.go&lt;/code&gt;结束的源代码文件。每一个源文件都是以一个 &lt;code&gt;package xxx&lt;/code&gt;的声明开头的，比如我们的例子里就是 &lt;code&gt;package main&lt;/code&gt; 。这行声明表示该文件是属于哪一个 &lt;code&gt;package&lt;/code&gt;，紧跟着是一系列 &lt;code&gt;import&lt;/code&gt; 的 &lt;code&gt;package&lt;/code&gt; 名，表示这个文件中引入的 &lt;code&gt;package&lt;/code&gt; 。再之后是本文件本身的代码&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;main.main 为函数的入口(main包 main函数)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;代码的第二句相信大家也都猜到了,导入 &lt;code&gt;fmt&lt;/code&gt; 包,&lt;br /&gt;&#xA;&lt;code&gt;fmt&lt;/code&gt; 包是干什么的呢?&lt;br /&gt;&#xA;&lt;code&gt;fmt&lt;/code&gt; 包实现了类似 &lt;code&gt;C&lt;/code&gt; 语言 &lt;code&gt;printf&lt;/code&gt; 和 &lt;code&gt;scanf&lt;/code&gt; 的格式化 &lt;code&gt;I/O&lt;/code&gt; 。格式化动作（&amp;rsquo;verb&amp;rsquo;）源自C语言但更简单。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;接下让我们来看 &lt;code&gt;main&lt;/code&gt; 函数, &lt;code&gt;main&lt;/code&gt; 必须存在与 &lt;code&gt;main&lt;/code&gt; 包内, 这是我们整个程序的入口(注：其实c系语言差不多都是这样)。main函数所做的事情就是我们程序做的事情。当然了，&lt;code&gt;main&lt;/code&gt; 函数一般完成的工作是调用其它 &lt;code&gt;packge&lt;/code&gt; 里的函数来完成自己的工作，比如 &lt;code&gt;fmt.Println&lt;/code&gt; 。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;main&lt;/code&gt; 函数内我们调用了 &lt;code&gt;fmt&lt;/code&gt; 包里面定义的函数 &lt;code&gt;Println&lt;/code&gt;。大家可以看到，这个函数是通过&lt;code&gt;&amp;lt;pkgName&amp;gt;.&amp;lt;funcName&amp;gt;&lt;/code&gt;的方式调用的.&lt;br /&gt;&#xA;&lt;code&gt;Println&lt;/code&gt; 函数类似与 c 语言的 &lt;code&gt;printf&lt;/code&gt; ,只是在 &lt;code&gt;printf&lt;/code&gt; 函数的基础上在输出最后加上一个格式化换行符.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;到此我们的 &lt;code&gt;helloWord.go&lt;/code&gt; 代码分析结束&lt;br /&gt;&#xA;下一篇博文让我真正的走进golang &lt;code&gt;&amp;lt;&amp;lt;goalng编程基础-基本语法&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;</content>
    <link href="http://int64.me/2015/golang 编程基础 - Hello,Word.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
</feed>