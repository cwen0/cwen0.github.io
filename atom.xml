<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>cwen</title>
  <id>http://int64.me</id>
  <updated>2017-10-28T04:16:35+08:00</updated>
  <subtitle>沉稳，不乏可爱</subtitle>
  <link href="http://int64.me"></link>
  <entry>
    <title>分布式系统里的时间、时钟和事件顺序</title>
    <updated>2017-11-22T00:00:00Z</updated>
    <id>tag:int64.me,2017-11-22:/2017/分布式系统里的时间、时钟和事件顺序.html</id>
    <content type="html">&lt;p&gt;以往编写单机程序的时候，如何来判断先后顺序，第一个想到的就是分配一个唯一时间戳，然后根据时间戳的大小来判断事件发生的先后顺序， 但是放在分布式系统就不一定有效&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;逻辑时钟和物理时钟&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;物理时间可以用严格的绝对时间来表示事件的发生顺序，但是在分布式的环境中，由于网络等因素无法做到完全的一致的时间，即使使用 NTP 时间，也是会有纳秒的误差。这样就导致在误差事件内发生的事件的先后顺序就很难判断了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1978 年，Leslie Lamport  在 &lt;a href=&#34;http://amturing.acm.org/p558-lamport.pdf&#34;&gt;Time, Clocks and the Ordering of Events in a Distributed System&lt;/a&gt; 论文中提出了逻辑时钟的概念。在分布式环境中，通过一系列规则来定义逻辑时钟的变化。从而能通过逻辑时钟来对分布式系统中的事件的先后顺序进行判断。逻辑时钟本质上定义了一种 happen before 关系。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;happen before 关系（偏序关系，部分有序）&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;在分布式系统中，一个进程 process 内的多个事件，自然地具备事件的先后顺序，或者说一个 process 本身就是一个有先验顺序的全序的事件集合。除了 process 内在的顺序，消息的发送和接收事件也是有因果序的。基于这两点，我们定义 happen-before 关系，写作 &lt;code&gt;-&amp;gt;&lt;/code&gt; 。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;&lt;strong&gt;定义&lt;/strong&gt;: 是一个分布式系统中事件集合上满足如下条件的最小关系：&lt;/h3&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果a和b是同一个process内的事件，且a在b之前发生，那么 $a-&amp;gt;b$。&lt;/li&gt;&#xA;&lt;li&gt;如果a是一个process发送消息事件，b是另一个进程接收该消息的事件，那么$a-&amp;gt;b$。&lt;/li&gt;&#xA;&lt;li&gt;$∀a,b,c,a→b,b→c⟹a→c ($即“在……之前发生”的关系具备传递性（transitivity）)&#xA;如果 $a↛b,b↛a$， 那么称 a 和 b 是并发（concurrent）的。&#xA;根据定义，可以知道happen-before关系 &lt;code&gt;-&amp;gt;&lt;/code&gt; 是一个系统所有事件集合之上的反自反偏序关系。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h2&gt;逻辑时钟&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：定义为一个以事件为输入，输出为某个有序数的函数C。若对所有事件恒满足：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$∀a,b\in E,a→b⟹C(a)&amp;lt;C(b)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;则称该函数C满足时钟约束。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们将C函数输出的有序数构成的先后关系，在逻辑上等同于物理时间，我们称由C实现的虚拟时钟为逻辑时钟。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;实现&lt;/strong&gt;: 满足如下两条规则：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在同一进程内，C单调递增；&lt;/li&gt;&#xA;&lt;li&gt;如果事件 a 是由进程 Pi发送一个消息 m , 消息 m 包含一个时间戳 T(m) = Ci(a), 进程 Pj 收到一个消息 m，这时候 Pj 设置 Cj 一定大于或等于之的时间，但是一定要比T(m) 大 。&#xA;函数 C 完全满足之前定义的偏序关系。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;h2&gt;全序关系&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;如果$C(a) = C(b)$，那a、b事件的顺序又是怎样的？假设a、b分别在节点P、Q上发生，Pi、Qj分别表示我们给P、Q的编号，如果 $C(a) = C(b)$ 并且 Pi &amp;lt; Qj，同样定义为a发生在b之前，记作 $a =&amp;gt; b$。假如我们对下图的A、B、C分别编号$Ai = 1、Bj = 2、Ck = 3$，因 $C(B4) = C(C3)$ 并且$ Bj &amp;lt; Ck$，则 $B4 =&amp;gt; C3$。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;通过以上定义，我们可以对所有事件排序、获得事件的全序关系(total order)。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/Screen%20Shot%202017-10-22%20at%205.35.32%20PM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;：→ 关系确定了唯一的部分有序关系；而 ⇒ 则是人为指定的完全排序关系，根据指定规则不同，⇒&lt;/p&gt;&#xA;&#xA;&lt;p&gt;关系可以有无穷多个。（在单一操作系统内的一个最简单的指定规则就是，当两事件时刻相等时，用进程号来分出前后）&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;fault model&lt;/strong&gt;：该结论建立在信息有序到达和信息始终可达的基础上。前者要求一个可靠的传输协议，后者则注定了该模型过于理想化，使得现实的可靠实现不能直接建立在该结论之上。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;强时钟约束&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;在上述方案中，时钟约束只定义了系统内部的有序性（或称同步性），由于 $⇒$&#xA;关系的任意性，系统内部的先后关系有可能和系统外部以真实时间为参考系的先后关系相互矛盾。为此，我们必须让系统也能模拟物理的时钟，从而将真实外部世界的先后顺序也考虑在内。处于系统外部的先后关系，我们定义为 (bold arrow, →→&lt;/p&gt;&#xA;&#xA;&lt;p&gt;)。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：若对时钟函数C，满足：&#xA;$$ ∀a,b\in E,a→→b⟹C(a)&amp;lt;C(b)$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;则称函数满足强时钟约束。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;证明强时钟约束可保证时间上的先后关系略( 数学，有点看不懂，后面子啊细细研究）&#xA;&lt;a href=&#34;http://blog.yangliu.online/2016/09/10/logic-clock-md/)&#34;&gt;http://blog.yangliu.online/2016/09/10/logic-clock-md/)&lt;/a&gt;&#xA;分布式系统理论基础 - 时间、时钟和事件顺序&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://amturing.acm.org/p558-lamport.pdf&#34;&gt;Time, Clocks and the Ordering of Events in a Distributed System&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.yangliu.online/2016/09/10/logic-clock-md/&#34;&gt;分布式系统之逻辑时钟&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/bangerlee/p/5448766.html&#34;&gt;分布式系统理论基础 - 时间、时钟和事件顺序&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/分布式系统里的时间、时钟和事件顺序.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>Leader Transfer In TiKV</title>
    <updated>2017-10-28T00:00:00Z</updated>
    <id>tag:int64.me,2017-10-28:/2017/Leader Transfer In TiKV.html</id>
    <content type="html">&lt;p&gt;在 TiKV 中，PD 当发现 TiKV 实例上 region 出现 leader 不均匀的时候，会尝试将 leader 从数量比较多的地方 transfer 到其地方，具体调度指令由 PD 发出，TiKV 接收到 PD 的 transfer leader 指令，调用 raft 操作执行真正操作&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;先看 PD&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;PD（Placement Driver）在 TiDB 集群里面主要负责 meta 信息存储，以及管理和调度 TiKV 集群， 所有可以想象 Transfer Leader 的命令显然是有 PD 发送到 TiKV。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PD 给 TiKV 发送 Transfer Leader 命令，可以分为一下两类&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;人为干预调度&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;PD 提供 pd-ctl 命令行工具，或是通过 api 接口显示的将一个 region 的 leader 调度到某一个 store 上。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; operator add transfer-leader 1 2         // 把 region 1 的 leader 调度到 store 2&#xA;&amp;gt;&amp;gt; operator add transfer-region 1 2 3 4     // 把 region 1 调度到 store 2,3,4&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;pd-ctl 实际上也是请求 PD 的api，具体请求过程略，有兴趣的同学可以去研究一下 PD 的源码。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// pd/server/coordinator.go&#xA;func (c *coordinator) sendScheduleCommand(region *core.RegionInfo, step schedule.OperatorStep) {&#xA;        log.Infof(&amp;quot;[region %v] send schedule command: %s&amp;quot;, region.GetId(), step)&#xA;        switch s := step.(type) {&#xA;        case schedule.TransferLeader:&#xA;                cmd := &amp;amp;pdpb.RegionHeartbeatResponse{&#xA;                        TransferLeader: &amp;amp;pdpb.TransferLeader{&#xA;                                Peer: region.GetStorePeer(s.ToStore),&#xA;                        },&#xA;                }&#xA;        .....&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;从上边代码可以看到，其实 PD 的调度命令是通过 heartbeat 来进行传递的，PD 和 TiKV 之间是通过 grpc 通信，当收到到这个操作指令的时候，就会调用 grpc 的send 方法，将请求发送给 TiKV。&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Leader 分布不均匀或是热点过于集中，PD 自身调度&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;PD 的主要作用就是负责管理和调度 TiKV， 如果 TiKV 各个节点上出现了 leader 分布补均匀或是热点 leader 过于集中在某一个 TiKV 节点上的时候，这时候 PD 就会作出干预，进行 transfer leader 等操作。PD 是根据每个 store 或是 leader peer 发送过来的心跳包，来作统计并决定执行哪些操作，每次收到 Region Leader 发来的心跳包时，PD 都会检查是否有对这个 Region 待进行的操作，通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 自己根据当前自身状态来定。（后面两句话直接 copy 自 &lt;a href=&#34;https://pingcap.com/blog-tidb-internal-3-zh）。&#34;&gt;https://pingcap.com/blog-tidb-internal-3-zh）。&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// HandleRegionHeartbeat processes RegionInfo reports from client.&#xA;func (c *RaftCluster) HandleRegionHeartbeat(region *core.RegionInfo) error {&#xA;        if err := c.cachedCluster.handleRegionHeartbeat(region); err != nil {&#xA;                return errors.Trace(err)&#xA;        }&#xA;&#xA;        // If the region peer count is 0, then we should not handle this.&#xA;        if len(region.GetPeers()) == 0 {&#xA;                log.Warnf(&amp;quot;invalid region, zero region peer count - %v&amp;quot;, region)&#xA;                return errors.Errorf(&amp;quot;invalid region, zero region peer count - %v&amp;quot;, region)&#xA;        }&#xA;&#xA;        c.coordinator.dispatch(region)&#xA;        return nil&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这个函数处理来自 leader peer 的heartbeat， &lt;code&gt;handleRegionHeartbeat&lt;/code&gt; 主要负责更相关region 的信息， 我们主要还是关系 如何发送操作指令，想当然就是 &lt;code&gt;c.coordinator.dispatch(region)&lt;/code&gt; 这个函数干的事情了。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (c *coordinator) dispatch(region *core.RegionInfo) {&#xA;       // Check existed operator.&#xA;       if op := c.getOperator(region.GetId()); op != nil {&#xA;               timeout := op.IsTimeout()&#xA;               if step := op.Check(region); step != nil &amp;amp;&amp;amp; !timeout {&#xA;                       operatorCounter.WithLabelValues(op.Desc(), &amp;quot;check&amp;quot;).Inc()&#xA;                       c.sendScheduleCommand(region, step)&#xA;                       return&#xA;               }&#xA;               if op.IsFinish() {&#xA;                       log.Infof(&amp;quot;[region %v] operator finish: %s&amp;quot;, region.GetId(), op)&#xA;                       operatorCounter.WithLabelValues(op.Desc(), &amp;quot;finish&amp;quot;).Inc()&#xA;                       c.removeOperator(op)&#xA;               } else if timeout {&#xA;                       log.Infof(&amp;quot;[region %v] operator timeout: %s&amp;quot;, region.GetId(), op)&#xA;                       operatorCounter.WithLabelValues(op.Desc(), &amp;quot;timeout&amp;quot;).Inc()&#xA;                       c.removeOperator(op)&#xA;               }&#xA;       }&#xA;    ....&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;可以看到这个函数，先检查是否存在已有的操作，这个 operator 可以有好多种，比如 &lt;code&gt;AddReplica、RemoveReplica、TransferLeader&lt;/code&gt;,&#xA;如果存在检查这个操作显示是到哪一步了，如果是没有结束并且没有超时，就会使用 &lt;code&gt;sendScheduleCommand&lt;/code&gt; 通过 grpc 向这个region 在此发送此次操作。 要是以及完成或是超时分别错处响应的处理并删除这个操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在看 PD 如何将 Transfer leader 这个 opertor 加到 &lt;code&gt;c.operators&lt;/code&gt; 里面的&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (l *balanceLeaderScheduler) Schedule(cluster schedule.Cluster) *schedule.Operator {&#xA;        schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;schedule&amp;quot;).Inc()&#xA;        region, newLeader := scheduleTransferLeader(cluster, l.GetName(), l.selector)&#xA;        if region == nil {&#xA;                return nil&#xA;        }&#xA;&#xA;        // Skip hot regions.&#xA;        if cluster.IsRegionHot(region.GetId()) {&#xA;                schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;region_hot&amp;quot;).Inc()&#xA;                return nil&#xA;        }&#xA;&#xA;        source := cluster.GetStore(region.Leader.GetStoreId())&#xA;        target := cluster.GetStore(newLeader.GetStoreId())&#xA;        if !shouldBalance(source, target, core.LeaderKind) {&#xA;                schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;skip&amp;quot;).Inc()&#xA;                return nil&#xA;        }&#xA;        l.limit = adjustBalanceLimit(cluster, core.LeaderKind)&#xA;        schedulerCounter.WithLabelValues(l.GetName(), &amp;quot;new_opeartor&amp;quot;).Inc()&#xA;        step := schedule.TransferLeader{FromStore: region.Leader.GetStoreId(), ToStore: newLeader.GetStoreId()}&#xA;        return schedule.NewOperator(&amp;quot;balance-leader&amp;quot;, region.GetId(), core.LeaderKind, step)&#xA;}&#xA;&#xA;...&#xA;func (c *coordinator) runScheduler(s *scheduleController) {&#xA;        defer c.wg.Done()&#xA;        defer s.Cleanup(c.cluster)&#xA;&#xA;        timer := time.NewTimer(s.GetInterval())&#xA;        defer timer.Stop()&#xA;&#xA;        for {&#xA;                select {&#xA;                case &amp;lt;-timer.C:&#xA;                        timer.Reset(s.GetInterval())&#xA;                        if !s.AllowSchedule() {&#xA;                                continue&#xA;                        }&#xA;                        if op := s.Schedule(c.cluster); op != nil {&#xA;                                c.addOperator(op)&#xA;                        }&#xA;&#xA;                case &amp;lt;-s.Ctx().Done():&#xA;                        log.Infof(&amp;quot;%v stopped: %v&amp;quot;, s.GetName(), s.Ctx().Err())&#xA;                        return&#xA;                }&#xA;        }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;可以看到&lt;code&gt;Schedule&lt;/code&gt;这个函数最后返回的是一个 &lt;code&gt;operator&lt;/code&gt; , &lt;code&gt;runScheduler&lt;/code&gt; 调用 &lt;code&gt;c.addOperator&lt;/code&gt; 将这个&lt;code&gt;operator&lt;/code&gt; 加到&lt;code&gt;c.operators&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;在看 TiKV&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;接着看 TiKV 从 PD 收到 transfer leader 指令后会做哪些操作。(刚入坑 Rust，看 TiKV 还有点费劲，可能有些地方理解的有问题，还望指出来)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;TiKV 首先是要接受到 PD 发送的命令，来看一个函数，这个函数是用来处理 PD 发送的命令&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;fn schedule_heartbeat_receiver(&amp;amp;mut self, handle: &amp;amp;Handle) {&#xA;        let ch = self.ch.clone();&#xA;        let store_id = self.store_id;&#xA;        let f = self.pd_client&#xA;            .handle_region_heartbeat_response(self.store_id, move |mut resp| {&#xA;                let region_id = resp.get_region_id();&#xA;                let epoch = resp.take_region_epoch();&#xA;                let peer = resp.take_target_peer();&#xA;&#xA;                if resp.has_change_peer() {&#xA;                   // more&#xA;                } else if resp.has_transfer_leader() {&#xA;                    PD_HEARTBEAT_COUNTER_VEC&#xA;                        .with_label_values(&amp;amp;[&amp;quot;transfer leader&amp;quot;])&#xA;                        .inc();&#xA;&#xA;                    let mut transfer_leader = resp.take_transfer_leader();&#xA;                    info!(&#xA;                        &amp;quot;[region {}] try to transfer leader from {:?} to {:?}&amp;quot;,&#xA;                        region_id,&#xA;                        peer,&#xA;                        transfer_leader.get_peer()&#xA;                    );&#xA;                    let req = new_transfer_leader_request(transfer_leader.take_peer());&#xA;                   send_admin_request(&amp;amp;ch, region_id, epoch, peer, req, None)&#xA;                } else {&#xA;                    PD_HEARTBEAT_COUNTER_VEC.with_label_values(&amp;amp;[&amp;quot;noop&amp;quot;]).inc();&#xA;                }&#xA;            })&#xA;    // more&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这段代码很好理解，就是先从 resp 中读取到 &lt;code&gt;region_id&lt;/code&gt;、&lt;code&gt;peer&lt;/code&gt;，然后在判断要执行的操作是什么，当执行的操作是 &lt;code&gt;transfer_leader&lt;/code&gt;的时候，先是更新一下监控，然后在从 resp 中获取到 &lt;code&gt;leader&lt;/code&gt; 该 &lt;code&gt;transfer&lt;/code&gt; 到什么地方, 在然后呢，就是发送这个命令去执行了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;先看启动 启动 &lt;code&gt;transfer_leader&lt;/code&gt; 函数&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pub fn transfer_leader(&amp;amp;mut self, transferee: u64) {&#xA;     let mut m = Message::new();&#xA;     m.set_msg_type(MessageType::MsgTransferLeader);&#xA;     m.set_from(transferee);&#xA;     self.raft.step(m).is_ok();&#xA; }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这个函数其实很简单，先设置一下消息类型，然后获取到目标 &lt;code&gt;leader&lt;/code&gt;，&lt;code&gt;transferee&lt;/code&gt; 就是目标&lt;code&gt;leader&lt;/code&gt;，当然自己就是当前 &lt;code&gt;leader&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在看处理过程&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;fn handle_transfer_leader(&amp;amp;mut self, m: &amp;amp;Message) {&#xA;    let lead_transferee = m.get_from();&#xA;    let last_lead_transferee = self.lead_transferee;&#xA;    if last_lead_transferee.is_some() {&#xA;        if last_lead_transferee.unwrap() == lead_transferee {&#xA;            info!(&#xA;                &amp;quot;{} [term {}] transfer leadership to {} is in progress, ignores request \&#xA;                 to same node {}&amp;quot;,&#xA;                self.tag,&#xA;                self.term,&#xA;                lead_transferee,&#xA;                lead_transferee&#xA;            );&#xA;            return;&#xA;        }&#xA;        self.abort_leader_transfer();&#xA;        info!(&#xA;            &amp;quot;{} [term {}] abort previous transferring leadership to {}&amp;quot;,&#xA;            self.tag,&#xA;            self.term,&#xA;            last_lead_transferee.unwrap()&#xA;        );&#xA;    }&#xA;    if lead_transferee == self.id {&#xA;        debug!(&#xA;            &amp;quot;{} is already leader. Ignored transferring leadership to self&amp;quot;,&#xA;            self.tag&#xA;        );&#xA;        return;&#xA;    }&#xA;    // Transfer leadership to third party.&#xA;    info!(&#xA;        &amp;quot;{} [term {}] starts to transfer leadership to {}&amp;quot;,&#xA;        self.tag,&#xA;        self.term,&#xA;        lead_transferee&#xA;    );&#xA;    // Transfer leadership should be finished in one electionTimeout&#xA;    // so reset r.electionElapsed.&#xA;    self.election_elapsed = 0;&#xA;    self.lead_transferee = Some(lead_transferee);&#xA;    if self.prs[&amp;amp;m.get_from()].matched == self.raft_log.last_index() {&#xA;        self.send_timeout_now(lead_transferee);&#xA;        info!(&#xA;            &amp;quot;{} sends MsgTimeoutNow to {} immediately as {} already has up-to-date log&amp;quot;,&#xA;            self.tag,&#xA;            lead_transferee,&#xA;            lead_transferee&#xA;        );&#xA;    } else {&#xA;        self.send_append(lead_transferee);&#xA;    }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这段代码稍有点长，我们可以一步一步的来看， 首先是进行一些检查，第一步是检查是否已经有 &lt;code&gt;transfer leader&lt;/code&gt; 在执行，如果已经正在  &lt;code&gt;transfer leader&lt;/code&gt; 并且目标 &lt;code&gt;leader&lt;/code&gt; 相同的话，就退出这次操作，如果目标不同的话，那就 调用&lt;code&gt;self.abort_leader_transfer();&lt;/code&gt; 这个函数放弃上一次正在执行的 &lt;code&gt;transfer leader&lt;/code&gt;  操作。 紧接就是判断 目标 &lt;code&gt;leader&lt;/code&gt;是不是自己，要是自己那就直接退出就好了，因为不需要&lt;code&gt;transfer leader&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;下一步就是将目标leader保存在&lt;code&gt;leadTransferee&lt;/code&gt;中，标示着有&lt;code&gt;transfer&lt;/code&gt;正在进行，后续如果有请求&lt;code&gt;propose&lt;/code&gt;进来，会检查这个&lt;code&gt;lead_transferee&lt;/code&gt; 是不是存在，如果存在，其他操作就无法成功，也就是无法进行写操作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;下一步就是检查 &lt;code&gt;transferee&lt;/code&gt; 和&lt;code&gt;leader&lt;/code&gt;的&lt;code&gt;log&lt;/code&gt;是否一样新&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果&lt;code&gt;log&lt;/code&gt; 一致的话就会给&lt;code&gt;transferee&lt;/code&gt;发送&lt;code&gt;MsgTimeoutNow&lt;/code&gt;类型的消息，告诉&lt;code&gt;transferee&lt;/code&gt;可以立即选主，不需要等到&lt;code&gt;election timeout&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;如果 &lt;code&gt;log&lt;/code&gt; 不一致，就会给 &lt;code&gt;lead_transferee&lt;/code&gt;  发送一个&lt;code&gt;append&lt;/code&gt; 的请求，追加 &lt;code&gt;log&lt;/code&gt;。 ，leader在收到响应 &lt;code&gt;MsgAppResp&lt;/code&gt;后,如果发现目前正处于&lt;code&gt;transfer leader&lt;/code&gt; 过程中并且 &lt;code&gt;transferee&lt;/code&gt;已经日志最新，则同样，给&lt;code&gt;transferee&lt;/code&gt;发送&lt;code&gt;MsgTimeoutNow&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/集群调度/blog-placement-driver-zh&#34;&gt;TiKV 源码解析系列 - Placement Driver&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pingcap.com/blog-tidb-internal-3-zh&#34;&gt;三篇文章了解 TiDB 技术内幕 - 谈调度&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27895034&#34;&gt;etcd raft如何实现leadership transfer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/pd&#34;&gt;PD&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/tikv&#34;&gt;TiKV&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/Leader Transfer In TiKV.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>rust 笔记 - 构建多线程 web server</title>
    <updated>2017-10-22T00:00:00Z</updated>
    <id>tag:int64.me,2017-10-22:/2017/rust 笔记 - 构建多线程 web server.html</id>
    <content type="html">&lt;p&gt;入坑 rust， 学习如何来用 rust 构建多线程 web server&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;先看结构&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;## main.rs&#xA;extern crate hello;&#xA;use hello::ThreadPool;&#xA;use std::io::prelude::*;&#xA;use std::net::TcpListener;&#xA;use std::net::TcpStream;&#xA;use std::fs::File;&#xA;use std::thread;&#xA;use std::time::Duration;&#xA;&#xA;fn main() {&#xA;    let listener = TcpListener::bind(&amp;quot;127.0.0.1:8080&amp;quot;).unwrap();&#xA;&#xA;    let pool = ThreadPool::new(4);&#xA;&#xA;    let mut counter = 0;&#xA;&#xA;    for stream in listener.incoming() {&#xA;        if counter == 2 {&#xA;            println!(&amp;quot;Shutting down.&amp;quot;);&#xA;            break;&#xA;        }&#xA;        counter += 1;&#xA;&#xA;        let stream = stream.unwrap();&#xA;&#xA;        pool.execute(|| {&#xA;            handle_connection(stream);&#xA;        });&#xA;    }&#xA;}&#xA;&#xA;fn handle_connection(mut stream: TcpStream) {&#xA;    let mut buffer = [0;512];&#xA;&#xA;    stream.read(&amp;amp;mut buffer).unwrap();&#xA;&#xA;    let get = b&amp;quot;GET / HTTP/1.1\r\n&amp;quot;;&#xA;    let sleep = b&amp;quot;GET /sleep HTTP/1.1\r\n&amp;quot;;&#xA;&#xA;    let (status_line, filename) = if buffer.starts_with(get) {&#xA;        (&amp;quot;HTTP/1.1 200 OK\r\n\r\n&amp;quot;, &amp;quot;html/hello.html&amp;quot;)&#xA;    } else if buffer.starts_with(sleep) {&#xA;        thread::sleep(Duration::from_secs(5));&#xA;        (&amp;quot;HTTP/1.1 200 OK\r\n\r\n&amp;quot;, &amp;quot;html/hello.html&amp;quot;)&#xA;    } else {&#xA;        (&amp;quot;HTTP/1.1 404 NOT FOUND\r\n\r\n&amp;quot;, &amp;quot;html/404.html&amp;quot;)&#xA;    };&#xA;&#xA;    let mut file = File::open(filename).unwrap();&#xA;    let mut contents = String::new();&#xA;&#xA;    file.read_to_string(&amp;amp;mut contents).unwrap();&#xA;&#xA;    let response = format!(&amp;quot;{}{}&amp;quot;, status_line, contents);&#xA;&#xA;    stream.write(response.as_bytes()).unwrap();&#xA;    stream.flush().unwrap();&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;从代码可以看出，使用 rust 构建一个 web server 并不难。 从头一点点学习&#xA;其他语言一样，要监听 TCP 端口，rust 使用 &lt;code&gt;TcpListener&lt;/code&gt; 中 &lt;code&gt;bind&lt;/code&gt; 函数绑定监听地址，&lt;code&gt;bind&lt;/code&gt; 函数返回 &lt;code&gt;Result&amp;lt;T, E&amp;gt;&lt;/code&gt;, 绑定可能会失败，例如，如果不是管理员尝试连接 80 端口。另一个绑定会失败的情况是两个程序监听相同的端口，这可能发生于运行两个本程序的实例时。&lt;code&gt;unwrap&lt;/code&gt; 取出 &lt;code&gt;T&lt;/code&gt;， 如果出现错误直接 &lt;code&gt;panic&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;let pool = ThreadPool::new(4);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;从字母意思可以看出来， 这是创建一个线程池（自己实现的，后面会详细介绍如何实现这个线程池）。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;for stream in listener.incoming() {&#xA;   let stream = stream.unwrap();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;TcpListener&lt;/code&gt; 的 &lt;code&gt;incoming&lt;/code&gt; 方法返回一个迭代器，它提供了一系列的流（更准确的说是 &lt;code&gt;TcpStream&lt;/code&gt; 类型的流）。流（&lt;code&gt;stream&lt;/code&gt;）代表一个客户端和服务端之间打开的连接。为此，&lt;code&gt;TcpStream&lt;/code&gt; 允许我们读取它来查看客户端发送了什么，并可以编写响应。所以这个 for 循环会依次处理每个连接并产生一系列的流供我们处理。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;fn handle_connection(mut stream: TcpStream) {&#xA;    let mut buffer = [0;512];&#xA;    stream.read(&amp;amp;mut buffer).unwrap();&#xA;    let get = b&amp;quot;GET / HTTP/1.1\r\n&amp;quot;;&#xA;    let (status_line, filename) = if buffer.starts_with(get) {&#xA;        (&amp;quot;HTTP/1.1 200 OK\r\n\r\n&amp;quot;, &amp;quot;html/hello.html&amp;quot;)&#xA;    } else {&#xA;        (&amp;quot;HTTP/1.1 404 NOT FOUND\r\n\r\n&amp;quot;, &amp;quot;html/404.html&amp;quot;)&#xA;    };&#xA;    let mut file = File::open(filename).unwrap();&#xA;    let mut contents = String::new();&#xA;    file.read_to_string(&amp;amp;mut contents).unwrap();&#xA;    let response = format!(&amp;quot;{}{}&amp;quot;, status_line, contents);&#xA;    stream.write(response.as_bytes()).unwrap();&#xA;    stream.flush().unwrap();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;handle_connection&lt;/code&gt; 负责处理请求和响应，在 &lt;code&gt;handle_connection&lt;/code&gt; 中，通过 &lt;code&gt;mut&lt;/code&gt; 关键字将 &lt;code&gt;stream&lt;/code&gt; 参数变为可变。我们将从流中读取数据，所以它需要是可修改的。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;接下来，需要实际读取流。这里分两步进行：首先，在栈上声明一个 &lt;code&gt;buffer&lt;/code&gt; 来存放读取到的数据。这里创建了一个 512 字节的缓冲区，它足以存放基本请求的数据。这对于本章的目的来说是足够的。如果希望处理任意大小的请求，管理所需的缓冲区将更复杂，不过现在一切从简。接着将缓冲区传递给 &lt;code&gt;stream.read&lt;/code&gt; ，它会从 &lt;code&gt;TcpStream&lt;/code&gt;中读取字节并放入缓冲区中。&#xA;接下来就是进行路由判断，当然这里是最简单判断，如果请求是 &amp;ldquo;/&amp;rdquo; 将返回 hello.html 页面否则返回 &amp;ldquo;404.html&amp;rdquo;。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;实现线程池&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;先看肿么用&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;let pool = ThreadPool::new(4);&#xA;&#xA;    let mut counter = 0;&#xA;&#xA;    for stream in listener.incoming() {&#xA;&#xA;        let stream = stream.unwrap();&#xA;        pool.execute(|| {&#xA;            handle_connection(stream);&#xA;        });&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;首先使用  &lt;code&gt;new&lt;/code&gt; 创建一个大小为 4 的连接池， 并且调用  &lt;code&gt;execute&lt;/code&gt; 方法，&lt;code&gt;execute&lt;/code&gt; 方法的参数可以看出来传入的是一个闭包，并且这个线程只会执行闭包一次。所以判断 execute 参数具有 &lt;code&gt;FnOnce trait bound&lt;/code&gt;, 同时可以从 &lt;code&gt;thread::spawn&lt;/code&gt; 函数的实现推断出。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; pub fn spawn&amp;lt;F, T&amp;gt;(f: F) -&amp;gt; JoinHandle&amp;lt;T&amp;gt;&#xA;    where&#xA;        F: FnOnce() -&amp;gt; T + Send + &#39;static,&#xA;        T: Send + &#39;static&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;所有我没制动，我的线程池 lib 需有有 &lt;code&gt;ThreadPool&lt;/code&gt; 这个 struct 并且，需要绑定  &lt;code&gt;new&lt;/code&gt; &lt;code&gt;execute&lt;/code&gt; 函数。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;// lib.rs 基本&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pub struct ThreadPool;&#xA;&#xA;impl ThreadPool {&#xA;    pub fn new(size: u32) -&amp;gt; ThreadPool {&#xA;        ThreadPool&#xA;    }&#xA;    pub fn execute&amp;lt;F&amp;gt;(&amp;amp;self, f: F)&#xA;        where&#xA;            F: FnOnce() + Send + &#39;static&#xA;    {&#xA;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;F 是这里我们关心的参数；T 与返回值有关所以我们并不关心。考虑到 &lt;code&gt;spawn&lt;/code&gt; 使用 &lt;code&gt;FnOnce&lt;/code&gt; 作为 F 的 &lt;code&gt;trait bound&lt;/code&gt;，这可能也是我们需要的，因为最终会将传递给 &lt;code&gt;execute&lt;/code&gt; 的参数传给 &lt;code&gt;spawn&lt;/code&gt;。因为处理请求的线程只会执行闭包一次，这也进一步确认了 &lt;code&gt;FnOnce&lt;/code&gt; 是我们需要的 &lt;code&gt;trait&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;F 还有 &lt;code&gt;trait bound Send&lt;/code&gt;和生命周期绑定 &lt;code&gt;&#39;static&lt;/code&gt;，这对我们的情况也是有意义的：需要 Send 来将闭包从一个线程转移到另一个线程，而 &lt;code&gt;&#39;static&lt;/code&gt; 是因为并不知道线程会执行多久。&#xA;&lt;code&gt;FnOnce trait&lt;/code&gt; 仍然需要之后的 ()，因为这里的 &lt;code&gt;FnOnce&lt;/code&gt; 代表一个没有参数也没有返回值的闭包。正如函数的定义，返回值类型可以从签名中省略，不过即便没有参数也需要括号。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;显然这不是一个完整连接池，没法提供服务。 我们接续补全。 结下来我们要做的是要储存它们，显然就是储存事先创建的线程。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们定义一个 &lt;code&gt;Worker struct&lt;/code&gt; , &lt;code&gt;ThreadPool&lt;/code&gt; 里面定义一个存放 size 个元素的 vector&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;pub struct ThreadPool {&#xA;    workers: Vec&amp;lt;Worker&amp;gt;,&#xA;}&#xA;&#xA;struct Worker {&#xA;    id: usize,&#xA;    thread: thread::JoinHandle&amp;lt;()&amp;gt;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;接下来给 &lt;code&gt;Worker&lt;/code&gt; 添加一个 new 函数&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;impl Worker {&#xA;    fn new(id: usize) -&amp;gt; Worker {&#xA;        let thread = thread::spawn(|| {});&#xA;&#xA;        Worker {&#xA;            id,&#xA;            thread,&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;在接下来就是考虑如何通信的问题，如何让 ThreodPool 接受到请求然后让worker 去执行，首先想到的就是使用通道了，搞个生产者，消费者了。&#xA;接下来我们要做什么&#xA;    1. ThreadPool 会创建一个通道并充当发送端。&#xA;    2. 每个 Worker 将会充当通道的接收端。&#xA;    3. 新建一个 Job 结构体来存放用于向通道中发送的闭包。&#xA;    4. ThreadPool 的 execute 方法会在发送端发出期望执行的任务。&#xA;    5. 在线程中，Worker 会遍历通道的接收端并执行任何接收到的任务。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// ...snip...&#xA;use std::sync::mpsc;&#xA;&#xA;pub struct ThreadPool {&#xA;    workers: Vec&amp;lt;Worker&amp;gt;,&#xA;    sender: mpsc::Sender&amp;lt;Job&amp;gt;,&#xA;}&#xA;&#xA;struct Job;&#xA;&#xA;impl ThreadPool {&#xA;    // ...snip...&#xA;    pub fn new(size: usize) -&amp;gt; ThreadPool {&#xA;        assert!(size &amp;gt; 0);&#xA;&#xA;        let (sender, receiver) = mpsc::channel();&#xA;&#xA;        let mut workers = Vec::with_capacity(size);&#xA;&#xA;        for id in 0..size {&#xA;            workers.push(Worker::new(id));&#xA;        }&#xA;&#xA;        ThreadPool {&#xA;            workers,&#xA;            sender,&#xA;        }&#xA;    }&#xA;    // ...snip...&#xA;}&#xA;&#xA;impl Worker {&#xA;    fn new(id: usize, receiver: mpsc::Receiver&amp;lt;Job&amp;gt;) -&amp;gt; Worker {&#xA;        let thread = thread::spawn(|| {&#xA;            receiver;&#xA;        });&#xA;&#xA;        Worker {&#xA;            id,&#xA;            thread,&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;ThreadPool&lt;/code&gt; 来储存一个发送 Job 实例的通道发送端&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在 &lt;code&gt;ThreadPool::new&lt;/code&gt; 中，新建了一个通道，并接着让线程池在接收端等待。这段代码能够编译，不过仍有警告。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在线程池创建每个 worker 时将通道的接收端传递给他们。须知我们希望在 &lt;code&gt;worker&lt;/code&gt; 所分配的线程中使用通道的接收端，所以将在闭包中引用 &lt;code&gt;receiver&lt;/code&gt; 参数。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;显然上边的消费者是有问题。 Rust 所提供的通道实现是多生产者，单消费者的，所以不能简单的克隆通道的消费端来解决问题。即便可以我们也不希望克隆消费端；在所有的&lt;code&gt;worker&lt;/code&gt; 中共享单一 &lt;code&gt;receiver&lt;/code&gt; 才是我们希望的在线程间分发任务的机制。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;另外，从通道队列中取出任务涉及到修改 &lt;code&gt;receiver&lt;/code&gt;，所以这些线程需要一个能安全的共享和修改 &lt;code&gt;receiver&lt;/code&gt; 的方式。如果修改不是线程安全的，则可能遇到竞争状态，例如两个线程因同时在队列中取出相同的任务并执行了相同的工作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们可以使用线程安全智能指针，为了在多个线程间共享所有权并允许线程修改其值，需要使用 &lt;code&gt;Arc&amp;lt;Mutex&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt;。&lt;code&gt;Arc&lt;/code&gt; 使得多个 &lt;code&gt;worker&lt;/code&gt; 拥有接收端，而 &lt;code&gt;Mutex&lt;/code&gt; 则确保一次只有一个 &lt;code&gt;worker&lt;/code&gt; 能从接收端得到任务。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;so 我的代码就改成这样了&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; use std::sync::Arc;&#xA;use std::sync::Mutex;&#xA;&#xA;// ...snip...&#xA;&#xA;impl ThreadPool {&#xA;    // ...snip...&#xA;    pub fn new(size: usize) -&amp;gt; ThreadPool {&#xA;        assert!(size &amp;gt; 0);&#xA;&#xA;        let (sender, receiver) = mpsc::channel();&#xA;&#xA;        let receiver = Arc::new(Mutex::new(receiver));&#xA;&#xA;        let mut workers = Vec::with_capacity(size);&#xA;&#xA;        for id in 0..size {&#xA;            workers.push(Worker::new(id, receiver.clone()));&#xA;        }&#xA;&#xA;        ThreadPool {&#xA;            workers,&#xA;            sender,&#xA;        }&#xA;    }&#xA;    // ...snip...&#xA;}&#xA;impl Worker {&#xA;    fn new(id: usize, receiver: Arc&amp;lt;Mutex&amp;lt;mpsc::Receiver&amp;lt;Job&amp;gt;&amp;gt;&amp;gt;) -&amp;gt; Worker {&#xA;        // ...snip...&#xA;    }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;让我们实现 &lt;code&gt;ThreadPool&lt;/code&gt; 上的 &lt;code&gt;execute&lt;/code&gt; 方法。同时也要修改 &lt;code&gt;Job&lt;/code&gt; 结构体：它将不再是结构体，&lt;code&gt;Job&lt;/code&gt; 将是一个有着 &lt;code&gt;execute&lt;/code&gt; 接收到的闭包类型的 &lt;code&gt;trait&lt;/code&gt; 对象的类型别名。在 worker 中，传递给 &lt;code&gt;thread::spawn&lt;/code&gt; 的闭包仍然还只是引用了通道的接收端。但是我们需要闭包一直循环，向通道的接收端请求任务，并在得到任务时执行他们。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&#xA;type Job = Box&amp;lt;FnOnce() + Send + &#39;static&amp;gt;;&#xA;&#xA;impl ThreadPool {&#xA;    // ...snip...&#xA;&#xA;    pub fn execute&amp;lt;F&amp;gt;(&amp;amp;self, f: F)&#xA;        where&#xA;            F: FnOnce() + Send + &#39;static&#xA;    {&#xA;        let job = Box::new(f);&#xA;&#xA;        self.sender.send(job).unwrap();&#xA;    }&#xA;}&#xA;&#xA;&#xA;impl Worker {&#xA;    fn new(id: usize, receiver: Arc&amp;lt;Mutex&amp;lt;mpsc::Receiver&amp;lt;Job&amp;gt;&amp;gt;&amp;gt;) -&amp;gt; Worker {&#xA;        let thread = thread::spawn(move || {&#xA;            loop {&#xA;                let job = receiver.lock().unwrap().recv().unwrap();&#xA;&#xA;                println!(&amp;quot;Worker {} got a job; executing.&amp;quot;, id);&#xA;&#xA;                (*job)();&#xA;            }&#xA;        });&#xA;&#xA;        Worker {&#xA;            id,&#xA;            thread,&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;如果现在编译我们的代码，还是会出现错误&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;error[E0161]: cannot move a value of type std::ops::FnOnce() +&#xA;std::marker::Send: the size of std::ops::FnOnce() + std::marker::Send cannot be&#xA;statically determined&#xA;  --&amp;gt; src/lib.rs:63:17&#xA;   |&#xA;63 |                 (*job)();&#xA;   |                 ^^^^^^&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;为了调用储存在 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;（这正是 Job 别名的类型）中的 &lt;code&gt;FnOnce&lt;/code&gt; 闭包，该闭包需要能将自己移动出 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;，因为当调用这个闭包时，它获取 &lt;code&gt;self&lt;/code&gt; 的所有权。通常来说，将值移动出 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; 是不被允许的，因为 Rust 不知道 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; 中的值将会有多大。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们可以使用 &lt;code&gt;self: Box&amp;lt;Self&amp;gt;&lt;/code&gt;语法的方法，获取了储存在 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; 中的 &lt;code&gt;Self&lt;/code&gt; 值的所有权。这正是我们希望做的，然而不幸的是 Rust 调用闭包的那部分实现并没有使用 &lt;code&gt;self: Box&amp;lt;Self&amp;gt;&lt;/code&gt;。所以这里 Rust 也不知道它可以使用 &lt;code&gt;self: Box&amp;lt;Self&amp;gt;&lt;/code&gt; 来获取闭包的所有权并将闭包移动出 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;不过目前让我们绕过这个问题。所幸有一个技巧可以显式的告诉 Rust 我们处于可以获取使用 &lt;code&gt;self: Box&amp;lt;Self&amp;gt;&lt;/code&gt; 的 &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; 中值的所有权的状态，而一旦获取了闭包的所有权就可以调用它了。这涉及到定义一个新 &lt;code&gt;trait&lt;/code&gt;，它带有一个在签名中使用 &lt;code&gt;self: Box&amp;lt;Self&amp;gt;&lt;/code&gt; 的方法 &lt;code&gt;call_box&lt;/code&gt;，为任何实现了 &lt;code&gt;FnOnce()&lt;/code&gt;的类型定义这个 &lt;code&gt;trait&lt;/code&gt;，修改类型别名来使用这个新 &lt;code&gt;trait&lt;/code&gt;，并修改 &lt;code&gt;Worker&lt;/code&gt; 使用 &lt;code&gt;call_box&lt;/code&gt; 方法&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;trait FnBox {&#xA;    fn call_box(self: Box&amp;lt;Self&amp;gt;);&#xA;}&#xA;&#xA;impl&amp;lt;F: FnOnce()&amp;gt; FnBox for F {&#xA;    fn call_box(self: Box&amp;lt;F&amp;gt;) {&#xA;        (*self)()&#xA;    }&#xA;}&#xA;&#xA;type Job = Box&amp;lt;FnBox + Send + &#39;static&amp;gt;;&#xA;&#xA;// ...snip...&#xA;&#xA;impl Worker {&#xA;    fn new(id: usize, receiver: Arc&amp;lt;Mutex&amp;lt;mpsc::Receiver&amp;lt;Job&amp;gt;&amp;gt;&amp;gt;) -&amp;gt; Worker {&#xA;        let thread = thread::spawn(move || {&#xA;            loop {&#xA;                let job = receiver.lock().unwrap().recv().unwrap();&#xA;&#xA;                println!(&amp;quot;Worker {} got a job; executing.&amp;quot;, id);&#xA;&#xA;                job.call_box();&#xA;            }&#xA;        });&#xA;&#xA;        Worker {&#xA;            id,&#xA;            thread,&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;Graceful Shutdown 与清理&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;如果我们编译上述表示的代码，会有一些警告说存在一些字段并没有直接被使用，这提醒了我们并没有清理任何内容。当使用 &lt;code&gt;ctrl-C&lt;/code&gt; 终止主线程，所有其他线程也会立刻停止，即便他们正在处理一个请求。现在我们要为 &lt;code&gt;ThreadPool&lt;/code&gt; 实现 &lt;code&gt;Drop trait&lt;/code&gt; 对线程池中的每一个线程调用 &lt;code&gt;join&lt;/code&gt;，这样这些线程将会执行完他们的请求。接着会为 &lt;code&gt;ThreadPool&lt;/code&gt; 实现一个方法来告诉线程他们应该停止接收新请求并结束。为了实践这些代码，修改 &lt;code&gt;server&lt;/code&gt; 在 &lt;code&gt;graceful Shutdown&lt;/code&gt; 之前只接受两个请求。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;enum Message {&#xA;    NewJob(Job),&#xA;    Terminate,&#xA;}&#xA;&#xA;pub struct ThreadPool {&#xA;    workers: Vec&amp;lt;Worker&amp;gt;,&#xA;    sender: mpsc::Sender&amp;lt;Message&amp;gt;,&#xA;}&#xA;&#xA;// ...snip...&#xA;&#xA;impl ThreadPool {&#xA;    // ...snip...&#xA;    pub fn new(size: usize) -&amp;gt; ThreadPool {&#xA;        assert!(size &amp;gt; 0);&#xA;&#xA;        let (sender, receiver) = mpsc::channel();&#xA;&#xA;        // ...snip...&#xA;    }&#xA;&#xA;    pub fn execute&amp;lt;F&amp;gt;(&amp;amp;self, f: F)&#xA;        where&#xA;            F: FnOnce() + Send + &#39;static&#xA;    {&#xA;        let job = Box::new(f);&#xA;&#xA;        self.sender.send(Message::NewJob(job)).unwrap();&#xA;    }&#xA;}&#xA;&#xA;// ...snip...&#xA;&#xA;impl Worker {&#xA;    fn new(id: usize, receiver: Arc&amp;lt;Mutex&amp;lt;mpsc::Receiver&amp;lt;Message&amp;gt;&amp;gt;&amp;gt;) -&amp;gt;&#xA;        Worker {&#xA;&#xA;        let thread = thread::spawn(move ||{&#xA;            loop {&#xA;                let message = receiver.lock().unwrap().recv().unwrap();&#xA;&#xA;                match message {&#xA;                    Message::NewJob(job) =&amp;gt; {&#xA;                        println!(&amp;quot;Worker {} got a job; executing.&amp;quot;, id);&#xA;&#xA;                        job.call_box();&#xA;                    },&#xA;                    Message::Terminate =&amp;gt; {&#xA;                        println!(&amp;quot;Worker {} was told to terminate.&amp;quot;, id);&#xA;&#xA;                        break;&#xA;                    },&#xA;                }&#xA;            }&#xA;        });&#xA;&#xA;        Worker {&#xA;            id,&#xA;            thread: Some(thread),&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;收发 &lt;code&gt;Message&lt;/code&gt; 值并在 Worker 收到 &lt;code&gt;Message::Terminate&lt;/code&gt; 时退出循环&lt;/p&gt;&#xA;&#xA;&lt;p&gt;需要将 &lt;code&gt;ThreadPool&lt;/code&gt; 定义、创建通道的 &lt;code&gt;ThreadPool::new&lt;/code&gt; 和 &lt;code&gt;Worker::new&lt;/code&gt; 签名中的 &lt;code&gt;Job&lt;/code&gt; 改为 &lt;code&gt;Message&lt;/code&gt;。&lt;code&gt;ThreadPool&lt;/code&gt; 的 &lt;code&gt;execute&lt;/code&gt; 方法需要发送封装进 &lt;code&gt;Message::NewJob&lt;/code&gt; 成员的任务，当获取到 &lt;code&gt;NewJob&lt;/code&gt; 时会处理任务而收到 &lt;code&gt;Terminate&lt;/code&gt; 成员时则会退出循环。&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;impl Drop for ThreadPool {&#xA;    fn drop(&amp;amp;mut self) {&#xA;        println!(&amp;quot;Sending terminate message to all workers.&amp;quot;);&#xA;&#xA;        for _ in &amp;amp;mut self.workers {&#xA;            self.sender.send(Message::Terminate).unwrap();&#xA;        }&#xA;&#xA;        println!(&amp;quot;Shutting down all workers.&amp;quot;);&#xA;&#xA;        for worker in &amp;amp;mut self.workers {&#xA;            println!(&amp;quot;Shutting down worker {}&amp;quot;, worker.id);&#xA;&#xA;            if let Some(thread) = worker.thread.take() {&#xA;                thread.join().unwrap();&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;在对每个 &lt;code&gt;worker&lt;/code&gt; 线程调用 &lt;code&gt;join&lt;/code&gt; 之前向 &lt;code&gt;worker&lt;/code&gt; 发送 &lt;code&gt;Message::Terminate&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;现在遍历了 &lt;code&gt;worker&lt;/code&gt; 两次，一次向每个 &lt;code&gt;worker&lt;/code&gt; 发送一个 &lt;code&gt;Terminate&lt;/code&gt; 消息，一个调用每个 &lt;code&gt;worker&lt;/code&gt; 线程上的 &lt;code&gt;join&lt;/code&gt;。如果尝试在同一循环中发送消息并立即 &lt;code&gt;join&lt;/code&gt; 线程，则无法保证当前迭代的 &lt;code&gt;worker&lt;/code&gt; 是从通道收到终止消息的&lt;code&gt;worker&lt;/code&gt;。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;为了更好的理解为什么需要两个分开的循环，想象一下只有两个 &lt;code&gt;worker&lt;/code&gt; 的场景。如果在一个循环中遍历每个&lt;code&gt;worker&lt;/code&gt;，在第一次迭代中 &lt;code&gt;worker&lt;/code&gt; 是第一个 &lt;code&gt;worker&lt;/code&gt;，我们向通道发出终止消息并对第一个 &lt;code&gt;worker&lt;/code&gt; 线程调用 &lt;code&gt;join&lt;/code&gt;。如果第一个 &lt;code&gt;worker&lt;/code&gt; 当时正忙于处理请求，则第二个 &lt;code&gt;worker&lt;/code&gt; 会从通道接收这个终止消息并结束。而我们在等待第一个 &lt;code&gt;worker&lt;/code&gt; 结束，不过它永远也不会结束因为第二个线程取走了终止消息。现在我们就阻塞在了等待第一个 &lt;code&gt;worker&lt;/code&gt; 结束，而无法发出第二条终止消息。死锁！&lt;/p&gt;&#xA;&#xA;&lt;p&gt;为了避免此情况，首先从通道中取出所有的 &lt;code&gt;Terminate&lt;/code&gt; 消息，接着 &lt;code&gt;join&lt;/code&gt; 所有的线程。因为每个 &lt;code&gt;worker&lt;/code&gt; 一旦收到终止消息即会停止从通道接收消息，我们就可以确保如果发送同 &lt;code&gt;worker&lt;/code&gt; 数相同的终止消息，在 &lt;code&gt;join&lt;/code&gt; 之前每个线程都会收到一个终止消息。&lt;/p&gt;&#xA;&#xA;&lt;h4&gt;简易线程池完整代码&lt;/h4&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// lib.rs&#xA;use std::thread;&#xA;use std::sync::mpsc;&#xA;use std::sync::Arc;&#xA;use std::sync::Mutex;&#xA;&#xA;enum Message {&#xA;    NewJob(Job),&#xA;    Terminate,&#xA;}&#xA;&#xA;pub struct ThreadPool{&#xA;    workers: Vec&amp;lt;Worker&amp;gt;,&#xA;    sender: mpsc::Sender&amp;lt;Message&amp;gt;,&#xA;}&#xA;&#xA;type Job = Box&amp;lt;FnBox + Send + &#39;static&amp;gt;;&#xA;&#xA;impl ThreadPool {&#xA;    /// Create a new ThreadPool.&#xA;    ///&#xA;    /// The size is the number of threads in the pool.&#xA;    ///&#xA;    /// # Panics&#xA;    ///&#xA;    /// The `new` function will panic if the size is zero.&#xA;    pub fn new(size :usize) -&amp;gt;ThreadPool{&#xA;        assert!(size &amp;gt; 0);&#xA;&#xA;        let (sender, receiver) = mpsc::channel();&#xA;&#xA;        let receiver = Arc::new(Mutex::new(receiver));&#xA;&#xA;        let mut workers = Vec::with_capacity(size);&#xA;&#xA;        for id in 0..size {&#xA;            workers.push(Worker::new(id, receiver.clone()));&#xA;        }&#xA;&#xA;        ThreadPool {&#xA;            workers,&#xA;            sender,&#xA;        }&#xA;    }&#xA;&#xA;    pub fn execute&amp;lt;F&amp;gt; (&amp;amp;self, f: F)&#xA;        where&#xA;        F: FnOnce() + Send + &#39;static&#xA;    {&#xA;        let job = Box::new(f);&#xA;        self.sender.send(Message::NewJob(job)).unwrap();&#xA;    }&#xA;}&#xA;&#xA;impl Drop for ThreadPool {&#xA;    fn drop(&amp;amp;mut self) {&#xA;        println!(&amp;quot;Sending terminate message to all workers.&amp;quot;);&#xA;&#xA;        for _ in &amp;amp;mut self.workers {&#xA;            self.sender.send(Message::Terminate).unwrap();&#xA;        }&#xA;&#xA;        println!(&amp;quot;Shutting down all workers.&amp;quot;);&#xA;&#xA;        for worker in &amp;amp;mut self.workers {&#xA;            println!(&amp;quot;Shutting down worker {}&amp;quot;, worker.id);&#xA;&#xA;            if let Some(thread) = worker.thread.take() {&#xA;                thread.join().unwrap();&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;trait FnBox {&#xA;    fn call_box(self: Box&amp;lt;Self&amp;gt;);&#xA;}&#xA;&#xA;impl&amp;lt;F: FnOnce()&amp;gt; FnBox for F {&#xA;    fn call_box(self: Box&amp;lt;F&amp;gt;) {&#xA;        (*self)()&#xA;    }&#xA;}&#xA;&#xA;struct Worker {&#xA;    id: usize,&#xA;    thread: Option&amp;lt;thread::JoinHandle&amp;lt;()&amp;gt;&amp;gt;,&#xA;}&#xA;&#xA;impl Worker {&#xA;    fn new(id: usize, receiver: Arc&amp;lt;Mutex&amp;lt;mpsc::Receiver&amp;lt;Message&amp;gt;&amp;gt;&amp;gt;) -&amp;gt; Worker {&#xA;        let thread = thread::spawn(move || {&#xA;            loop {&#xA;                let message = receiver.lock().unwrap().recv().unwrap();&#xA;&#xA;                match message {&#xA;                    Message::NewJob(job) =&amp;gt; {&#xA;                        println!(&amp;quot;Worker {} got a job; executing.&amp;quot;, id);&#xA;&#xA;                        job.call_box();&#xA;                    },&#xA;                    Message::Terminate =&amp;gt; {&#xA;                        println!(&amp;quot;Worker {} was told to terminate.&amp;quot;, id);&#xA;&#xA;                        break;&#xA;                    },&#xA;                }&#xA;            }&#xA;        });&#xA;&#xA;        Worker {&#xA;            id,&#xA;            thread: Some(thread),&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://doc.rust-lang.org/book/second-edition/ch20-00-final-project-a-web-server.html&#34;&gt;The Rust Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kaisery.github.io/trpl-zh-cn/&#34;&gt;Rust程序设计-中文版&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 构建多线程 web server.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>GFS 笔记 - MIT-6.824</title>
    <updated>2017-08-31T00:00:00Z</updated>
    <id>tag:int64.me,2017-08-31:/2017/GFS 笔记 - MIT-6.824.html</id>
    <content type="html">&lt;p&gt;GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，并提供容错功能。它可以给大量的用户提供总体性能较高的服务&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;什么是一致性？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个正确性条件&lt;/li&gt;&#xA;&lt;li&gt;当存在副本和程序并发访问的时候，一致性是很重要的&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果一个应用进行写操作，那么之后的读操作可以观察到什么？如果这个读操作来自其他应用程序又会看到什么？&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;弱一致性&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;read() 可能返回旧的数据 &amp;mdash; 不是最新写入的数据&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;强一致性&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;read() 总是返回最新写入的数据&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;一般的权衡&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;强一致性对程序的写操作（application writers）表现不错&lt;/li&gt;&#xA;&lt;li&gt;强一致性对性能有一定的影响&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;更多的正确性条件（通常被称为一致性模型）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;&amp;ldquo;理想&amp;rdquo; 的一致性模型&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个有副本的文件系统和一个没有副本的文件系统表现的一样，就像许多客户端访问痛一台机器上的单独磁盘&lt;/li&gt;&#xA;&lt;li&gt;如果一个程序写数据，那么之后的就可以读到之前写的数据&lt;/li&gt;&#xA;&lt;li&gt;如果两个程序并发的写同一个文件呢？&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在文件系统中这种行为经常是未定义的 —— 文件也许会混合两个写操作的内容&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果两个程序并发的写同一个目录呢？&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个一个顺序执行&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;去实现理想的一致性的挑战&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;并发&lt;/li&gt;&#xA;&lt;li&gt;机器失败&lt;/li&gt;&#xA;&lt;li&gt;网络分割&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;为什么去克服这些挑战是困难的？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;clients 和 servers 之前要求通信，可能会消耗性能&lt;/li&gt;&#xA;&lt;li&gt;协议可能变得复杂 &amp;mdash;  后面的课程我们会看到很难实现正确的系统&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;GFS 中的主要挑战&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;存在许多机器，所有机器出现故障是很常见的现象，假设一台机器一年出错一次，那么当存在1000台机器的时候，每天都有三台机器出现问题。&lt;/li&gt;&#xA;&lt;li&gt;高性能：很多并发的读写操作，Map/Reduce工作会从 GFS 读取数据，然后保存最后的结果，注意：保存的不是中间临时文件。&lt;/li&gt;&#xA;&lt;li&gt;有效的使用网络&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;高层次的设计&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定义目录、文件、命名、打开/读/写操作，但是不是符合posix标准&lt;/li&gt;&#xA;&lt;li&gt;成千上百的带有硬盘的 linux 服务器&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;存储64MB的块(an ordinary Linux file for each chunk)&lt;/li&gt;&#xA;&lt;li&gt;each chunk 在三个服务器上存在副本&lt;/li&gt;&#xA;&lt;li&gt;Q: 为什么三副本？&lt;/li&gt;&#xA;&lt;li&gt;Q：除了数据的可用性，三副本方案给我们带来了什么？对热点文件的读取做负载均衡&lt;/li&gt;&#xA;&lt;li&gt;Q: 为什么不只存储一份文件到 RAID 磁盘？ RAID 磁盘不是常用品，我们想给整台机器做容错，而不是仅仅针对存储系统。&lt;/li&gt;&#xA;&lt;li&gt;Q: 为什么 chunks 这么大？&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;GFS 的 master server 知道目录层级&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对于目录而言，知道里面有哪些文件&lt;/li&gt;&#xA;&lt;li&gt;对于为难而言，知道哪些数据块服务器存储了相关的64MB大小数据块&lt;/li&gt;&#xA;&lt;li&gt;master server 在内存里面保存状态信息，每个chunk在主控服务器上面只保存64bytes大小的metadata&lt;/li&gt;&#xA;&lt;li&gt;master server 有为元数据准备的可回收数据库，可以从断电故障后快速恢复&lt;/li&gt;&#xA;&lt;li&gt;同时存在备份的主控服务器(shadow master)，数据略比主控服务器服务器延迟，可以被提升为主控服务器&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;基础的文件操作&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;客户端读操作&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;客户端发送文件名和偏移量到 master&lt;/li&gt;&#xA;&lt;li&gt;主控服务器回复带有相关 chunk 的数据块服务器集合，相应信息包括版本信息，客户端临时缓存这些信息，然后访问最近的数据块服务器，版本检查，如果版本是不正确的，重新从 master 获取最新的数据&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;客户端 append&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;客户端询问 master 去存储在什么地方&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果文件大小超过64MB，master 也许会选择一些新的数据块服务器&lt;/li&gt;&#xA;&lt;li&gt;master 把 chunk servers 和版本信息返回给客户端，其中一个 chunk 是 primary&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;客户端把数据推送的副本&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;副本构成一个链表&lt;/li&gt;&#xA;&lt;li&gt;链表涉及到网络拓扑&lt;/li&gt;&#xA;&lt;li&gt;允许快速复杂&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;当数据都在所有的 chunk servers 时候客户端与 primary server 沟通&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;primary 分配序列号&lt;/li&gt;&#xA;&lt;li&gt;primary apply 本地的修改&lt;/li&gt;&#xA;&lt;li&gt;primary 转发请求到副本&lt;/li&gt;&#xA;&lt;li&gt;当 primary 收到所有副本的 ack 后，返回给客户端&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果一个副本是没有响应，客户端将要重试&lt;/li&gt;&#xA;&lt;li&gt;如果 master 没有重置 lease， master 可以重新指定新的 master，&lt;/li&gt;&#xA;&lt;li&gt;如果副本的数量小于某个值的时候，master 会重新添加副本，重新负载副本&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;GFS 达到了理想中的一致性了吗？&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;两种情况：目录和文件&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;目录 yes，but&amp;hellip;&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;yes: 强一致性 （仅有一个副本)&lt;/li&gt;&#xA;&lt;li&gt;but:&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Master 有可能挂掉并且 GFS 是不可用的&lt;/li&gt;&#xA;&lt;li&gt;shadow master 可以提供只读操作，但是它返回老的数据&lt;/li&gt;&#xA;&lt;li&gt;Q: 那写操作呢？ 脑裂现象&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;文件：不一定&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;带有原子追加的突变&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个文件可以有重复的 enties 和空洞，如果 primary 与一个副本连接失败，primary 会给客户端报一个错误，客户端重试并且 primary 选择一个新的偏移量，记录可能是重复写入，其他的副本可能存在空洞&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;一个不幸运的客户端可能在短时间内读到一个老的数据&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一个失败的突变导致 chunks 的不一致，primary chunk 更新 chunck 但是失败了并且副本数据过时了&lt;/li&gt;&#xA;&lt;li&gt;一个客户端可能去读一个没有跟新数据的 chunk&lt;/li&gt;&#xA;&lt;li&gt;当客户端刷新 lease  的时候，他将获得到最新版本&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;没有原子追加的突变&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不同客户端的数据可能被混合&lt;/li&gt;&#xA;&lt;li&gt;如果你是在使用原子追加或是临时文件和自动重命名，并发的写在不同的 Unix 机器上可能导致奇怪的现象&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;作者主张弱一致性对app而言不是什么大问题&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;大多数文件更新操作只是追加&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;应用程序可以使用添加记录中的uid判断是否重复&lt;/li&gt;&#xA;&lt;li&gt;应用程序也许只是读取到少量的数据（而不是不新鲜的数据）&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;应用程序可以使用临时文件和原子的重命名操作&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;性能&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;巨大的读操作总吞吐量（3个副本，striping ？？？）&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;125 MB/sec&lt;/li&gt;&#xA;&lt;li&gt;接近网络饱和状态&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;写入不同的文件低于可能的最大值&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;作者怪网络堆栈&lt;/li&gt;&#xA;&lt;li&gt;chunk直接的复制操作会引起延迟&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;并发追加同一份文件&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;被服务器存在的最新的chunk所限制&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;总结&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GFS使用的比较重要的容错技术riz&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;操作日志、检查点&lt;/li&gt;&#xA;&lt;li&gt;chunk之间的主备备份（but with consistencies？？）&lt;/li&gt;&#xA;&lt;li&gt;我们将会在其他系统中也看到这里&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;哪些在GFS中工作很好&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;巨大的顺序读写操作&lt;/li&gt;&#xA;&lt;li&gt;追加&lt;/li&gt;&#xA;&lt;li&gt;巨大的吞吐量&lt;/li&gt;&#xA;&lt;li&gt;数据之间的容错&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;哪些在GFS中做的不怎么好&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;master服务器的容错&lt;/li&gt;&#xA;&lt;li&gt;小文件（master服务器的瓶颈）&lt;/li&gt;&#xA;&lt;li&gt;多个客户端并发的向同一份文件更新操作（除了追加）&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pdos.csail.mit.edu/6.824/papers/gfs.pdf&#34;&gt;The Google File System&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pdos.csail.mit.edu/6.824/notes/l-gfs-short.txt&#34;&gt;6.824-nodes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/feixiao/Distributed-Systems/blob/master/Lec03_GFS/GFS.md&#34;&gt;GFS案例学习&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/GFS 笔记 - MIT-6.824.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>RPC in GO - MIT-6.824</title>
    <updated>2017-08-10T00:00:00Z</updated>
    <id>tag:int64.me,2017-08-10:/2017/RPC in GO - MIT-6.824.html</id>
    <content type="html">&lt;p&gt;RPC 理想上想把网络通信做的跟函数调用一样&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;远程调用 (RPC)&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分布式系统的关键模块&lt;/li&gt;&#xA;&lt;li&gt;目的：&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;容易编写网络通信程序&lt;/li&gt;&#xA;&lt;li&gt;隐藏大多数 client/server 之间通信的细节&lt;/li&gt;&#xA;&lt;li&gt;客户端调用更加像传统的过程调用&lt;/li&gt;&#xA;&lt;li&gt;服务端处理更加像传统的过程调用&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;RPC 已经被广泛应用&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;RPC 理想上想把网络通信就当做函数调用一样简单&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Client:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    z = fn(x,y)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Server:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    fn(x, y) {&#xA;        compute&#xA;        return z&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;RPC 的目标是这样的水平透明&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Go example &lt;a href=&#34;https://pdos.csail.mit.edu/6.824&#34;&gt;kv.go&lt;/a&gt;&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;client &amp;ldquo;dial&amp;rdquo; 向 server 端请求调用就像寻常函数调用一样&lt;/li&gt;&#xA;&lt;li&gt;server 并发的处理每一个请求，当然，对于keyvalue要用到锁&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;RPC消息流程图：&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Client             Server&#xA;&#x9;request---&amp;gt;&#xA;   &#x9;&#x9;&amp;lt;---response&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;软件架构&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;client app         handlers&#xA;&#x9;stubs           dispatcher&#xA;RPC lib           RPC lib&#xA; 　　net  ------------ net&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;一些细节&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;应该调用哪个服务器函数（handler）？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;去掉用 Call() 中指定的函数&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;序列化数据： 数列换数据到包中&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;棘手的数组，指针，对象等。&lt;/li&gt;&#xA;&lt;li&gt;Go的RPC库非常强大。&lt;/li&gt;&#xA;&lt;li&gt;有些东西你不能传递：比如channels和function。&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;绑定：client 如何知道该和谁交互&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;client 也许使用 server host name&lt;/li&gt;&#xA;&lt;li&gt;也许使用命名服务，将服务名字映射到最好的服务器。&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;RPC 问题： 当遇到失败会做一些什么操作？&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;eg: 丢包，网络中断, server 响应缓慢，server 端挂掉&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;错误对RPC客户端意味着什么?&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;client 永远不会收到 server 的响应&lt;/li&gt;&#xA;&lt;li&gt;clinet 不知道 server 是否收到请求(可能在server 发送响应的时候网络中断)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;简单的方案：“最少一次” 执行&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RPC client 等待响应一定时间，在这段时间内没有收到响应，则重新发送请求，持续这样的操作一定次数后，依然吗没有响应，则向应用汇报错误&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Q: &amp;ldquo;至少一次&amp;rdquo;容易被应用程序处理吗？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;至少一次写的简单问题： 客户端发送&amp;rdquo;deduct $10 from bank account&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Q: 客户端可能出现什么错误？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Put(&amp;ldquo;k&amp;rdquo;,10) &amp;ndash; 一个RPC调用在数据库服务器中设置键值对。&lt;/li&gt;&#xA;&lt;li&gt;Put(&amp;ldquo;k&amp;rdquo;,20) &amp;ndash; 客户端对同一个键设置其他值。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Q: &amp;ldquo;至少一次&amp;rdquo; 是否是正确的？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果只是读操作没有问题&lt;/li&gt;&#xA;&lt;li&gt;如果应用对于重复写做了处理，也是OK 的&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;更好的RPC行为：&amp;rdquo;最多一次&amp;rdquo;&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;idea:服务器的RPC代码发现重复的请求，返回之前的回复，而不是重写运行。&lt;/li&gt;&#xA;&lt;li&gt;Q：如何发现相同的请求?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;client让每一个请求带有唯一标示码XID(unique ID),相同请求使用相同的XID重新发送。&#xA;server：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;if seen[xid]:&#xA;    r = old[xid]&#xA;else&#xA;    r = handler()&#xA;    old[xid] = r&#xA;    seen[xid] = true&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;&amp;ldquo;最多一次&amp;rdquo; 的复杂度&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;如何确保 XID 是唯一的？&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;很大的随机数?&lt;/li&gt;&#xA;&lt;li&gt;将唯一的客户端ID（ip address？）和序列号组合起来？&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;server 最后必须丢弃老的 RPC 信息&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;什么时候的确是安全的？&lt;/li&gt;&#xA;&lt;li&gt;想法：&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;唯一的client  IDs&lt;/li&gt;&#xA;&lt;li&gt;前一个rpc请求的序列号&lt;/li&gt;&#xA;&lt;li&gt;客户端每个 RPC 请求都包括 &amp;ldquo;seen all replies &amp;lt;= x&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;类似tcp中的seq和ack&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;或者每次只允许一个RPC调用，到达的是seq+1，那么忽略其他小于seq&lt;/li&gt;&#xA;&lt;li&gt;客户端最多可以尝试5次，服务器会忽略大于5次的请求&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;当原来的请求还在执行，怎么样处理相同seq的请求？&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;服务器不想运行两次，也不想回复。&lt;/li&gt;&#xA;&lt;li&gt;想法：给每个执行的RPC，pending标识；等待或者忽略。&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;如果一个 &amp;ldquo;最多一次&amp;rdquo; 的server挂掉了或是重启了肿么办？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果服务器将副本信息保存在内存中，服务器会忘记请求，同时在重启之后接受相同的请求。&lt;/li&gt;&#xA;&lt;li&gt;也许，你应该将副本信息保存到磁盘？&lt;/li&gt;&#xA;&lt;li&gt;也许，副本服务器应该保存副本信息？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;&amp;ldquo;至少执行一次&amp;rdquo; 如何？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;至多一次+无限重试+容错服务&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Go RPC实现的”最多一次“？&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;打开TCP连接&lt;/li&gt;&#xA;&lt;li&gt;向TCP连接写入请求&lt;/li&gt;&#xA;&lt;li&gt;TCP也许会重传，但是服务器的TCP协议栈会过滤重复的信息&lt;/li&gt;&#xA;&lt;li&gt;在Go代码里面不会有重试（即：不会创建第二个TCP连接）&lt;/li&gt;&#xA;&lt;li&gt;Go RPC代码当没有获取到回复之后将返回错误&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;也许是TCP连接的超时&lt;/li&gt;&#xA;&lt;li&gt;也许是服务器没有看到请求&lt;/li&gt;&#xA;&lt;li&gt;也许服务器处理了请求，但是在返回回复之前服务器的网络故障&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pdos.csail.mit.edu/6.824/notes/l-rpc.txt&#34;&gt;MIT-8.624 nodes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/feixiao/Distributed-Systems&#34;&gt;Distributed-Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/RPC in GO - MIT-6.824.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>MapReduce 笔记 - MIT-6.824</title>
    <updated>2017-08-04T00:00:00Z</updated>
    <id>tag:int64.me,2017-08-04:/2017/MapReduce 笔记 - MIT-6.824.html</id>
    <content type="html">&lt;p&gt;MapReduce 由google提出的软件架构，主要用于大规模数据集的并行计算&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;MapReduce 概念&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;背景：在几个小时内处理晚TB级别的数据量，eg: 分析一个爬行网也的图形结构，由非分布式系统专家开发的程序运行成千的机器上会是一件很痛苦的事情， eg：错误处理&lt;/li&gt;&#xA;&lt;li&gt;总体目标：非专业程序员可以轻松的在合理的效率下解决的巨大的数据处理问题。程序员定义Map函数和Reduce函数、顺序代码一般都比较简单。 MR在成千的机器上面运行处理大量的数据输入，隐藏全部分布式的细节。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;MapReduce 抽象&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;输入是被切分成 M 个分片&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Input1 -&amp;gt; Map -&amp;gt; a,1   b,1  c,1&#xA;Input2 -&amp;gt; Map -&amp;gt;     b,1&#xA;Input3 -&amp;gt; Map -&amp;gt; a,1      c,1&#xA;                  |   |   |&#xA;                  |   |    -&amp;gt; Reduce -&amp;gt; c,2&#xA;                  |    ----&amp;gt; Reduce -&amp;gt; b,2&#xA;                    ------&amp;gt; Reduce -&amp;gt; a,2&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;MR 在每个输入分片上调用 Map() 函数，产生(k2, v2)这样的中间数据集。  每一个Map()函数的调用就是一个 &amp;ldquo;task&amp;rdquo;&#xA;MR 收集所有key为k2的所有值, 并且把他们传递给Reduce 调用， 最后Reduce输出是这样&lt;k2, v3&gt;这样的一对数值，并存储到输出文件中。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Example: 单词计算&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;输入是成千文本文件&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; Map(k, v)&#xA;    split v into words&#xA;    for each word w&#xA;      emit(w, &amp;quot;1&amp;quot;)&#xA;  Reduce(k, v)&#xA;    emit(len(v))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;MapReduce 隐藏了很多让人痛苦的细节&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在服务器上启动软件(s/w)&lt;/li&gt;&#xA;&lt;li&gt;跟踪哪些&amp;rdquo;tasks&amp;rdquo;已经完成&lt;/li&gt;&#xA;&lt;li&gt;数据传送&lt;/li&gt;&#xA;&lt;li&gt;失败恢复&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;MapReduce 易拓展&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;N 台计算机具有 Nx 的吞吐量，假设 M 和 R 都是 大于等于N (即，大量的输入文件和输出的keys), 因为每个Map() 互不影响，所用Map() 函数可以并发的执行。 Reduce() 同样如此。&#xA;所以我们可以通过买更多的电脑来增加吞吐。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;什么会限制性能？&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;这是我们关系去优化的地方？ CPU? memory? disk? network?&#xA;MepReduce 的作者在 2004 时候，网络带宽是个大问题。关键所有Map()， Reduce() 交互过程中的所有数据都是经过网络的，网络速度是远小于磁盘和内存的速度。 所有当初作者尽量减少网络搬迁数据（如今网络速度相比2004年快了很多)&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;更多细节&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;master: 分发&amp;rdquo;task&amp;rdquo;给 workers;&lt;/li&gt;&#xA;&lt;li&gt;记录m Map task 的中间输出文件、r Reduce&lt;/li&gt;&#xA;&lt;li&gt;输入文件是被存储在 GFS，每个Map 输出文件都有三份;&lt;/li&gt;&#xA;&lt;li&gt;所有计算机都同时运行这GFS 和 MR workers;&lt;/li&gt;&#xA;&lt;li&gt;输入文件是比 workers 多；&lt;/li&gt;&#xA;&lt;li&gt;master 给每个 worker 一个 map task, 只有当老的 task 完成后 master 才会分发新的任务&lt;/li&gt;&#xA;&lt;li&gt;map worker 在本地磁盘上使用 hash 算法将 中间 key 分成 R 份&lt;/li&gt;&#xA;&lt;li&gt;直达所有的Map tasks 全部完成，才会调用 Reduce&lt;/li&gt;&#xA;&lt;li&gt;master 通知 Reducers 从 Map workers 去回去中间数据分区&lt;/li&gt;&#xA;&lt;li&gt;Reduce worker 将最终结果写入GFS(每个 Reduce task 产生一个 文件)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;如何设计去减少慢网络的影响&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Map worker 的输入是从本地磁盘上的GFS副本读取，不经过网络&lt;/li&gt;&#xA;&lt;li&gt;中间数据只经过一次网络&lt;/li&gt;&#xA;&lt;li&gt;Map worker 写数据到本地磁盘，而不是 GFS&lt;/li&gt;&#xA;&lt;li&gt;每个中间数据切分成的文件中都包含许多keys&lt;/li&gt;&#xA;&lt;li&gt;大的网络传输是更加有效率&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;如何更好的负载均衡&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;让n-1 servers 去等待一个server 的结束，这是非常糟糕的， 但是总有 tasks 是别其他的tasks 运行的时间要久。&#xA;解决办法： tasks 的数量要比 workers 多。 master 检测到 workers 的老的tasks 执行结束后， 给他分配新的 task。所以没有比这个 worker自己所能允许的最大时间还长的task存在(希望这样) 。所以运行速度快的 servers 比运行速度慢的servers做更多的工作，但是能在同时完成&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;worker 失败恢复的细节(如何做容错 ）&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;Map worker 崩溃&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;master 检查到 worker 不在相应心跳&lt;/li&gt;&#xA;&lt;li&gt;崩溃的 worker 的 map 中间输出数据丢失，但是可能每一个 Reduce task 都需要这个数据&lt;/li&gt;&#xA;&lt;li&gt;master 重新调度，在GFS拥有输入文件的其他副本的计算机上重新启动 task&lt;/li&gt;&#xA;&lt;li&gt;有些 Reduce worker 可能已经拥有了读到了崩溃掉机器上的中间数据，在这里我们依赖 map 函数的功能和确定性&lt;/li&gt;&#xA;&lt;li&gt;如果Reduce 以及获取到所有中间数据，那么master不需要重新运行 Map&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;Reduce worker 崩溃&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;已经执行结束的 Tasks 是没有问题的- 别存储到了 GFS，带有多个副本&lt;/li&gt;&#xA;&lt;li&gt;master 在其他 workers 上重启崩溃掉的 worker 没有完成的 task&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;Reduce worker 在正在写他的输出文件的时候崩溃掉&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;GFS会自动重命名输出，然后使其保持不可见直到Reduce完成，所以master在其他地方再次运行Reduce worker将会是安全的。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;其他错误和问题&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果 master 给两个 workers 同样的 Map() task 肿么办？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;可能 master 错误的认为其中一个 worker 以及死亡， 它只会告诉Reduce worker其中的一个&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果 master 给两个 workers 同样的 Reducer() task 肿么办？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;它们都会将同一份数据写到GFS上面，GFS的原子重命名操作会触发，先完成的获胜将结果写到GFS.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果某一个单独的 worker 是非常的慢 &amp;ndash; 一个掉队者？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;产生原因可能是非常糟糕的硬件设施。 master会对这些最后的任务创建第二份拷贝任务执行。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果由于硬件或是软件原因造成一个worker计算出一个错误的输出肿么办？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;太糟糕了！MR假设是建立在&amp;rdquo;fail-stop&amp;rdquo;的cpu和软件之上。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果 master 崩溃了肿么办？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;单独的 master 挂了， 那就挂了&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;关于那些MapReduce不能很好执行的应用&lt;/h2&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;并不是所以工作都适合map/shuffle/reduce这种模式&lt;/li&gt;&#xA;&lt;li&gt;小的数据，因为管理成本太高,如非网站后端&lt;/li&gt;&#xA;&lt;li&gt;大数据中的小更新，比如添加一些文件到大的索引&lt;/li&gt;&#xA;&lt;li&gt;不可预知的读(Map 和 Reduce都不能选择输入)&lt;/li&gt;&#xA;&lt;li&gt;Multiple shuffles, e.g. page-rank (can use multiple MR but not very efficient)&lt;/li&gt;&#xA;&lt;li&gt;多数灵活的系统允许MR，但是使用非常复杂的r模型&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;总结&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;MapReduce 的出现使得大数据计算变得流行起来&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不是最有效或是灵活的&lt;/li&gt;&#xA;&lt;li&gt;拓展性好&lt;/li&gt;&#xA;&lt;li&gt;容易编程 &amp;ndash; 失败和数据迁移被隐藏起来&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pdos.csail.mit.edu/6.824/notes/l01.txt&#34;&gt;MIT-8.624 nodes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf&#34;&gt;MapReduce: Simplified Data Processing on Large Clusters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/MapReduce 笔记 - MIT-6.824.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>How to use Raft</title>
    <updated>2017-07-30T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-30:/2017/How to use Raft.html</id>
    <content type="html">&lt;p&gt;记录如何使用 ETCD raft Library&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;先说 ETCD Raft library&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;ETCD Raft library 作为目前使用最为广泛的 raft 库，也可以说是目前最为完善稳定的。以一个使用者的姿态来看看该如何将这个 raft library 用在自己的项目中。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;这个库实现了 Raft 算法的核心内容，比如 append log 、选主、snapshot、成员变更，但是用户需要自己实现网络传输和网络IO， 用户必须实现自己的传输层，用来不同node 之间进行消息传输，用户也需要自行实现存储层用来Raft日志和状态。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;ETCD Raft library 实现的功能&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Leader election&lt;/li&gt;&#xA;&lt;li&gt;Log replication&lt;/li&gt;&#xA;&lt;li&gt;Log compaction&lt;/li&gt;&#xA;&lt;li&gt;Membership changes&lt;/li&gt;&#xA;&lt;li&gt;Leadership transfer extension&lt;/li&gt;&#xA;&lt;li&gt;Efficient linearizable read-only queries served by both the leader and followers&lt;/li&gt;&#xA;&lt;li&gt;leader checks with quorum and bypasses Raft log before processing read-only queries&lt;/li&gt;&#xA;&lt;li&gt;followers asks leader to get a safe read index before processing read-only queries&lt;/li&gt;&#xA;&lt;li&gt;More efficient lease-based linearizable read-only queries served by both the leader and followers&lt;/li&gt;&#xA;&lt;li&gt;leader bypasses Raft log and processing read-only queries locally&lt;/li&gt;&#xA;&lt;li&gt;followers asks leader to get a safe read index before processing read-only queries&lt;/li&gt;&#xA;&lt;li&gt;this approach relies on the clock of the all the machines in raft group&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h4&gt;More&lt;/h4&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Optimistic pipelining to reduce log replication latency&lt;/li&gt;&#xA;&lt;li&gt;Flow control for log replication&lt;/li&gt;&#xA;&lt;li&gt;Batching Raft messages to reduce synchronized network I/O calls&lt;/li&gt;&#xA;&lt;li&gt;Batching log entries to reduce disk synchronized I/O&lt;/li&gt;&#xA;&lt;li&gt;Writing to leader&amp;rsquo;s disk in parallel&lt;/li&gt;&#xA;&lt;li&gt;Internal proposal redirection from followers to leader&lt;/li&gt;&#xA;&lt;li&gt;Automatic stepping down when the leader loses quorum&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h3&gt;Storage 接口&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;library 定义了一个 Storage 接口，但是需要用户自己实现&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// Storage is an interface that may be implemented by the application&#xA;// to retrieve log entries from storage.&#xA;//&#xA;// If any Storage method returns an error, the raft instance will&#xA;// become inoperable and refuse to participate in elections; the&#xA;// application is responsible for cleanup and recovery in this case.&#xA;type Storage interface {&#xA;    // InitialState returns the saved HardState and ConfState information.&#xA;    InitialState() (pb.HardState, pb.ConfState, error)&#xA;    // Entries returns a slice of log entries in the range [lo,hi).&#xA;    // MaxSize limits the total size of the log entries returned, but&#xA;    // Entries returns at least one entry if any.&#xA;    Entries(lo, hi, maxSize uint64) ([]pb.Entry, error)&#xA;    // Term returns the term of entry i, which must be in the range&#xA;    // [FirstIndex()-1, LastIndex()]. The term of the entry before&#xA;    // FirstIndex is retained for matching purposes even though the&#xA;    // rest of that entry may not be available.&#xA;    Term(i uint64) (uint64, error)&#xA;    // LastIndex returns the index of the last entry in the log.&#xA;    LastIndex() (uint64, error)&#xA;    // FirstIndex returns the index of the first log entry that is&#xA;    // possibly available via Entries (older entries have been incorporated&#xA;    // into the latest Snapshot; if storage only contains the dummy entry the&#xA;    // first log entry is not available).&#xA;    FirstIndex() (uint64, error)&#xA;    // Snapshot returns the most recent snapshot.&#xA;    // If snapshot is temporarily unavailable, it should return ErrSnapshotTemporarilyUnavailable,&#xA;    // so raft state machine could know that Storage needs some time to prepare&#xA;    // snapshot and call Snapshot later.&#xA;    Snapshot() (pb.Snapshot, error)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;用户实现 Storage 接口用以实现持久化存储，&lt;a href=&#34;https://github.com/coreos/etcd/tree/master/contrib/raftexample&#34;&gt;raftexample&lt;/a&gt;  使用library 提供 的 MemoryStorage, 配合使用 etcd 的wal 和sanp 包可是实现持久化， 重启的时候从wal和snap中获取日志恢复MemoryStorage。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Ready struct&lt;/h3&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// Ready encapsulates the entries and messages that are ready to read,&#xA;// be saved to stable storage, committed or sent to other peers.&#xA;// All fields in Ready are read-only.&#xA;type Ready struct {&#xA;    // The current volatile state of a Node.&#xA;    // SoftState will be nil if there is no update.&#xA;    // It is not required to consume or store SoftState.&#xA;    *SoftState&#xA;&#xA;    // The current state of a Node to be saved to stable storage BEFORE&#xA;    // Messages are sent.&#xA;    // HardState will be equal to empty state if there is no update.&#xA;    pb.HardState&#xA;&#xA;    // ReadStates can be used for node to serve linearizable read requests locally&#xA;    // when its applied index is greater than the index in ReadState.&#xA;    // Note that the readState will be returned when raft receives msgReadIndex.&#xA;    // The returned is only valid for the request that requested to read.&#xA;    ReadStates []ReadState&#xA;&#xA;    // Entries specifies entries to be saved to stable storage BEFORE&#xA;    // Messages are sent.&#xA;    Entries []pb.Entry&#xA;&#xA;    // Snapshot specifies the snapshot to be saved to stable storage.&#xA;    Snapshot pb.Snapshot&#xA;&#xA;    // CommittedEntries specifies entries to be committed to a&#xA;    // store/state-machine. These have previously been committed to stable&#xA;    // store.&#xA;    CommittedEntries []pb.Entry&#xA;&#xA;    // Messages specifies outbound messages to be sent AFTER Entries are&#xA;    // committed to stable storage.&#xA;    // If it contains a MsgSnap message, the application MUST report back to raft&#xA;    // when the snapshot has been received or has failed by calling ReportSnapshot.&#xA;    Messages []pb.Message&#xA;&#xA;    // MustSync indicates whether the HardState and Entries must be synchronously&#xA;    // written to disk or if an asynchronous write is permissible.&#xA;    MustSync bool&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这个Ready结构体封装了一批更新，这些更新包括：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;pb.HardState: 包含当前节点见过的最大的term，以及在这个term给谁投过票，已经当前节点知道的commit index&lt;/li&gt;&#xA;&lt;li&gt;Messages: 需要广播给所有peers的消息&lt;/li&gt;&#xA;&lt;li&gt;CommittedEntries:已经commit了，还没有apply到状态机的日志&lt;/li&gt;&#xA;&lt;li&gt;Snapshot:需要持久化的快照&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;用户从 node struct 提供一个 ready channel 中不断的 pop 出 Ready 进行处理，library user 使用如下方法获取Ready Channel&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (n *node) Ready() &amp;lt;- chan Ready{ return n.readyc}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;应用需要对 Ready 的处理如下：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;将HardState, Entries, Snapshot持久化到storage。&lt;/li&gt;&#xA;&lt;li&gt;将Messages(上文提到的msgs)非阻塞的广播给其他peers&lt;/li&gt;&#xA;&lt;li&gt;将CommittedEntries(已经commit还没有apply)应用到状态机。&lt;/li&gt;&#xA;&lt;li&gt;如果发现CommittedEntries中有成员变更类型的entry，调用node的ApplyConfChange()方法让node知道(这里和raft论文不一样，论文中只要节点收到了成员变更日志就应用)&lt;/li&gt;&#xA;&lt;li&gt;调用Node.Advance()告诉raft node，这批状态更新处理完了，状态已经演进了，可以给我下一批Ready让我处理。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;应用通过raft.StartNode()来启动raft中的一个副本，函数内部通过启动一个goroutine运行来启动服务&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (n *node) run(r *raft)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;应用通过调用&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (n *node) Propose(ctx context.Context, data []byte) error&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;来Propose一个请求给raft，被raft开始处理后返回。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;增删节点通过调用&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (n *node) ProposeConfChange(ctx context.Context, cc pb.ConfChange) error&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;node结构体包含几个重要的channel:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// node is the canonical implementation of the Node interface&#xA;type node struct {&#xA;    propc      chan pb.Message&#xA;    recvc      chan pb.Message&#xA;    confc      chan pb.ConfChange&#xA;    confstatec chan pb.ConfState&#xA;    readyc     chan Ready&#xA;    advancec   chan struct{}&#xA;    tickc      chan struct{}&#xA;    done       chan struct{}&#xA;    stop       chan struct{}&#xA;    status     chan chan Status&#xA;&#xA;    logger Logger&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;propc: propc是一个没有buffer的channel，应用通过Propose接口写入的请求被封装成Message被push到propc中，node的run方法从propc中pop出Message，append自己的raft log中，并且将Message放入mailbox中(raft结构体中的msgs []pb.Message)，这个msgs会被封装在Ready中，被应用从readyc中取出来，然后通过应用自定义的transport发送出去。&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;recvc: 应用自定义的transport在收到Message后需要调用&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (n *node) Step(ctx context.Context, m pb.Message) error&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;来把Message放入recvc中，经过一些处理后，同样，会把需要发送的Message放入到对应peers的mailbox中。后续通过自定义transport发送出去。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;readyc／advancec: readyc和advancec都是没有buffer的channel，node.run()内部把相关的一些状态更新打包成Ready结构体(其中一种状态就是上面提到的msgs)放入readyc中。应用从readyc中pop出Ready中，对相应的状态进行处理，处理完成后，调用&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;rc.node.Advance()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;往advancec中push一个空结构体告诉raft，已经对这批Ready包含的状态进行了相应的处理，node.run()内部从advancec中得到通知后，对内部一些状态进行处理，比如把已经持久化到storage中的entries从内存(对应type unstable struct)中删除等。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;tickc:应用定期往tickc中push空结构体，node.run()会调用tick()函数，对于leader来说，tick()会给其他peers发心跳，对于follower来说，会检查是否需要发起选主操作。&lt;/p&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;confc/confstatec:应用从Ready中拿出CommittedEntries，检查其如果含有成员变更类型的日志，则需要调用&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func (n *node) ApplyConfChange(cc pb.ConfChange) *pb.ConfState&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;这个函数会push ConfChange到confc中，confc同样是个无buffer的channel，node.run()内部会从confc中拿出ConfChange，然后进行真正的增减peers操作，之后将最新的成员组push到confstatec中，而ApplyConfChange函数从confstatec pop出最新的成员组返回给应用。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Usage&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;raft library 使用raft.StartNode 开启一个 node ，或是使用raft.RestartNode 从一些初始状态启动一个 node。&#xA;启动三节点 node&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;  storage := raft.NewMemoryStorage()&#xA;  c := &amp;amp;Config{&#xA;    ID:              0x01,&#xA;    ElectionTick:    10,&#xA;    HeartbeatTick:   1,&#xA;    Storage:         storage,&#xA;    MaxSizePerMsg:   4096,&#xA;    MaxInflightMsgs: 256,&#xA;  }&#xA;  // Set peer list to the other nodes in the cluster.&#xA;  // Note that they need to be started separately as well.&#xA;  n := raft.StartNode(, []raft.Peer{{ID: 0x01}, {ID: 0x02}, {ID: 0x03}})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;启动一个单节点集群&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// Create storage and config as shown above.&#xA;// Set peer list to itself, so this node can become the leader of this single-node cluster.&#xA;peers := []raft.Peer{{ID: 0x01}}&#xA;n := raft.StartNode(c, peers)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;加入新节点到集群的时候，新集群不能存在任何 peer 。首先，通过在集群内其他节点上调用ProposeConfChange将节点添加到现有集群。然后，启动新的节点，如下所示：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;// Create storage and config as shown above.&#xA;n := raft.StartNode(c, nil)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;重启节点&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;  storage := raft.NewMemoryStorage()&#xA;&#xA;  // Recover the in-memory storage from persistent snapshot, state and entries.&#xA;  storage.ApplySnapshot(snapshot)&#xA;  storage.SetHardState(state)&#xA;  storage.Append(entries)&#xA;&#xA;  c := &amp;amp;Config{&#xA;    ID:              0x01,&#xA;    ElectionTick:    10,&#xA;    HeartbeatTick:   1,&#xA;    Storage:         storage,&#xA;    MaxSizePerMsg:   4096,&#xA;    MaxInflightMsgs: 256,&#xA;  }&#xA;&#xA;  // Restart raft without peer information.&#xA;  // Peer information is already included in the storage.&#xA;  n := raft.RestartNode(c)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;在创建了node 后，用户需要做这些：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First ，从Node.Ready（）通道读取并处理其包含的更新。这些步骤可以并行执行，除了步骤2中所述。&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;将HardState，Entries和Snapshot写入storage（如果它们不为空）。如果写入 entry 的索引是 i， 那么就得丢弃索引大于 i 的所有log。&lt;/li&gt;&#xA;&lt;li&gt;将所有消息发送到目的的节点。一直发送消息直到最新的HardState已经持久存储到磁盘，并且以Ready batch 方式写入所用的 entry。为了减少I/O延迟，可以应用优化使领导者与其追随者并行写入磁盘。如果任何消息类型为MsgSnap，则在发送后调用Node.ReportSnapshot()（这些消息可能很大）。注意：marshal message 不是线程安全的;确保 在marshalling 的时候没有新的 entry 。实现这一目标的最简单的方法是直接在在 raft loop 内串行执行。&lt;/li&gt;&#xA;&lt;li&gt;将快照（如果有）和CommittedEntries应用到状态机。如果任何已提交的Entry具有TypeConfChange类型，则调用Node.ApplyConfChange（）将其应用于该节点。此时可以通过在调用ApplyConfChange之前将NodeID字段设置为零（但是ApplyConfChange必须以某种方式调用，并且取消决定必须完全基于状态机而不是外部信息，例如观察到节点的健康状况）。&lt;/li&gt;&#xA;&lt;li&gt;调用Node.Advance（）来指示下一批更新的准备状态。这可以在步骤1之后的任何时间完成，尽管所有更新必须按照Ready所返回的顺序进行处理。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Second, 所有持久化的日志条目必须通过Storage接口的实现来提供。可以使用提供的MemoryStorage类型（如果在重新启动时重新填充其状态），或者可以提供自定义的磁盘支持实现。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Third，从另一个节点收到消息后，将其传递给Node.Step：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;func recvRaftRPC(ctx context.Context, m raftpb.Message) {&#xA;&#x9;n.Step(ctx, m)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;最后，定期调用Node.Tick（）（可能通过time.Ticker）。raft 有两个重要的超时：心跳和选举超时。但是，在 fraft library 内部抽象 &amp;ldquo;tick&amp;rdquo; 代表时间。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;状态机处理循环，如下所示：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; for {&#xA;    select {&#xA;    case &amp;lt;-s.Ticker:&#xA;      n.Tick()&#xA;    case rd := &amp;lt;-s.Node.Ready():&#xA;      saveToStorage(rd.State, rd.Entries, rd.Snapshot)&#xA;      send(rd.Messages)&#xA;      if !raft.IsEmptySnap(rd.Snapshot) {&#xA;        processSnapshot(rd.Snapshot)&#xA;      }&#xA;      for _, entry := range rd.CommittedEntries {&#xA;        process(entry)&#xA;        if entry.Type == raftpb.EntryConfChange {&#xA;          var cc raftpb.ConfChange&#xA;          cc.Unmarshal(entry.Data)&#xA;          s.Node.ApplyConfChange(cc)&#xA;        }&#xA;      }&#xA;      s.Node.Advance()&#xA;    case &amp;lt;-s.done:&#xA;      return&#xA;    }&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;节点获取应用程序数据并同步到状态机，把数据序列化到slice，并调用：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;n.Propose(ctx，data)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;如果proposal 被 commit ，数据将出现在类型为raftpb.EntryNormal的提交的条目中。不能保证提出的命令将被提交;该命令超时后会重试。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;要添加或删除集群中的节点，请申请 ConfChange struct&amp;rsquo;cc&amp;rsquo;并调用：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;n.ProposeConfChange(ctx，cc)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;配置更改提交后，将返回类型为raftpb.EntryConfChange已经被提交的 entry 。这必须通过以下方式应用于节点：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;var cc raftpb.ConfChange&#xA;cc.Unmarshal(data)&#xA;n.ApplyConfChange(cc)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;注意：ID表示集群中所有时间的唯一节点。即使旧节点被删除，给定的ID也只能使用一次。这意味着，例如IP地址可能会导致糟糕的节点ID，因为它们可能被重用。节点ID必须不为零。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/etcd/tree/master/raft&#34;&gt;Etcd Raft&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/foxmailed/p/7137431.html&#34;&gt;etcd raft library设计原理和使用&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/How to use Raft.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>Raft 算法笔记</title>
    <updated>2017-07-23T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-23:/2017/Raft 算法笔记.html</id>
    <content type="html">&lt;p&gt;花了一个周末仔细读了 Raft 论文，此处只是做个简单的笔记，方便以后查看回顾&amp;hellip;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Raft 使用用来保证复杂日志一致性的算法，相比paxos 算法，更加简单容易理解。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Features&lt;/h3&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Strong leader： Raft 约束，日志只能从 leader 复制到 follower&lt;/li&gt;&#xA;&lt;li&gt;Leader election: Raft 采用随机定时器来选主，简单的方法避免了冲突的问题。&lt;/li&gt;&#xA;&lt;li&gt;Membership change：Raft 引用一个中间态( joint consensus) ，来做成员变更&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Replicated State Machine&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;一致性算法产生的背景，在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导者，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fbxcex0w1fj20gt08vwfr.jpg&#34; alt=&#34;复制状态机&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;图1: 复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;每台机器上都有一系列的日志，每条日志就是一条 command ，已经确认的日志会被状态机按顺序执行。一致性算法主要用来保证每台机器上 的已经确认的日志是一样到，因此内存中的状态机也是一致的，输出也是一致的。一致性协议模块从客户端接收到一条命令，并添加到日志中，然后和其他机器的一致性模块通信，来保证日志最终都是一样的。一旦一条日志被确认了，那么，少数派的机器宕机并不会影响对外服务。整个系统看起来就像是一个高可用的状态机。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一致性协议又如下特点:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;保证safety：不管网络延迟或者分区，网络包丢失、重复或者乱序，都要保证一致性。&lt;/li&gt;&#xA;&lt;li&gt;可用性：只要多数派机器在线，就应该能提供服务。&lt;/li&gt;&#xA;&lt;li&gt;不依赖时钟来保证正确性：时钟出错或者网络消息延迟过大只是会导致可用性，并不会导致一致性错误。&lt;/li&gt;&#xA;&lt;li&gt;通常，一次网路来回的事件就可以对一个command确认。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;h2&gt;Overview&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Raft首先选主，然后leader全权负责同步日志。有了leader极大地简化了日志复制：leader可以单方面决定日志写在什么位置上；日志流只能是从leader到follower。&#xA;通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Leader election&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;一个新的领导人需要被选举出来，当现存的领导人宕机的时候&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Log replication&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;状态&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;状态&lt;/th&gt;&#xA;&lt;th&gt;所有服务器上持久存在的&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;currentTerm&lt;/td&gt;&#xA;&lt;td&gt;服务器最后一次知道的任期号（初始化为 0，持续递增）&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;votedFor&lt;/td&gt;&#xA;&lt;td&gt;在当前获得选票的候选人的 Id&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;log[]&lt;/td&gt;&#xA;&lt;td&gt;日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;状态&lt;/th&gt;&#xA;&lt;th&gt;所有服务器上经常变的&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;commitIndex&lt;/td&gt;&#xA;&lt;td&gt;已知的最大的已经被提交的日志条目的索引值&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;lastApplied&lt;/td&gt;&#xA;&lt;td&gt;最后被应用到状态机的日志条目索引值（初始化为 0，持续递增）&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;状态&lt;/th&gt;&#xA;&lt;th&gt;在领导人里经常改变的 （选举后重新初始化）&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;nextIndex[]&lt;/td&gt;&#xA;&lt;td&gt;对于每一个服务器，需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一）&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;matchIndex[]&lt;/td&gt;&#xA;&lt;td&gt;对于每一个服务器，已经复制给他的日志的最高索引值&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;附加日志 RPC&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;由领导人负责调用来复制日志指令；也会用作heartbeat&lt;/p&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;参数&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;term&lt;/td&gt;&#xA;&lt;td&gt;领导人的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;leaderId&lt;/td&gt;&#xA;&lt;td&gt;领导人的 Id，以便于跟随者重定向请求&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;prevLogIndex&lt;/td&gt;&#xA;&lt;td&gt;新的日志条目紧随之前的索引值&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;prevLogTerm&lt;/td&gt;&#xA;&lt;td&gt;prevLogIndex 条目的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;entries[]&lt;/td&gt;&#xA;&lt;td&gt;准备存储的日志条目（表示心跳时为空；一次性发送多个是为了提高效率）&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;leaderCommit&lt;/td&gt;&#xA;&lt;td&gt;领导人已经提交的日志的索引值&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;返回值&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;term&lt;/td&gt;&#xA;&lt;td&gt;当前的任期号，用于领导人去更新自己&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;success&lt;/td&gt;&#xA;&lt;td&gt;跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;p&gt;接收者实现：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果 &lt;code&gt;term &amp;lt; currentTerm&lt;/code&gt; 就返回 false&lt;/li&gt;&#xA;&lt;li&gt;如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false&lt;/li&gt;&#xA;&lt;li&gt;如果已经存在的日志条目和新的产生冲突（索引值相同但是任期号不同），删除这一条和之后所有的&lt;/li&gt;&#xA;&lt;li&gt;附加任何在已有的日志中不存在的条目&lt;/li&gt;&#xA;&lt;li&gt;如果 &lt;code&gt;leaderCommit &amp;gt; commitIndex&lt;/code&gt;，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;请求投票 RPC&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;由候选人负责调用用来征集选票&lt;/p&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;参数&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;term&lt;/td&gt;&#xA;&lt;td&gt;候选人的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;candidateId&lt;/td&gt;&#xA;&lt;td&gt;请求选票的候选人的 Id&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;lastLogIndex&lt;/td&gt;&#xA;&lt;td&gt;候选人的最后日志条目的索引值&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;lastLogTerm&lt;/td&gt;&#xA;&lt;td&gt;候选人最后日志条目的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;返回值&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;term&lt;/td&gt;&#xA;&lt;td&gt;当前任期号，以便于候选人去更新自己的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;voteGranted&lt;/td&gt;&#xA;&lt;td&gt;候选人赢得了此张选票时为真&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;p&gt;接收者实现：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果&lt;code&gt;term &amp;lt; currentTerm&lt;/code&gt;返回 false&lt;/li&gt;&#xA;&lt;li&gt;如果 votedFor 为空或者就是 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;所有服务器需遵守的规则&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;所有服务器：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果&lt;code&gt;commitIndex &amp;gt; lastApplied&lt;/code&gt;，那么就 lastApplied 加一，并把&lt;code&gt;log[lastApplied]&lt;/code&gt;应用到状态机中&lt;/li&gt;&#xA;&lt;li&gt;如果接收到的 RPC 请求或响应中，任期号&lt;code&gt;T &amp;gt; currentTerm&lt;/code&gt;，那么就令 currentTerm 等于 T，并切换状态为跟随者&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;跟随者：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;响应来自候选人和领导者的请求&lt;/li&gt;&#xA;&lt;li&gt;如果在超过选举超时时间的情况之前都没有收到领导人的心跳，或者是候选人请求投票的，就自己变成候选人&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;候选人 ：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在转变成候选人后就立即开始选举过程&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;自增当前的任期号（currentTerm）&lt;/li&gt;&#xA;&lt;li&gt;给自己投票&lt;/li&gt;&#xA;&lt;li&gt;重置选举超时计时器&lt;/li&gt;&#xA;&lt;li&gt;发送请求投票的 RPC 给其他所有服务器&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果接收到大多数服务器的选票，那么就变成领导人&lt;/li&gt;&#xA;&lt;li&gt;如果接收到来自新的领导人的附加日志 RPC，转变成跟随者&lt;/li&gt;&#xA;&lt;li&gt;如果选举过程超时，再次发起一轮选举&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;领导人：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一旦成为领导人：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以阻止跟随者超时&lt;/li&gt;&#xA;&lt;li&gt;如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端&lt;/li&gt;&#xA;&lt;li&gt;如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex，那么：发送从 nextIndex 开始的所有日志条目：&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果成功：更新相应跟随者的 nextIndex 和 matchIndex&lt;/li&gt;&#xA;&lt;li&gt;如果因为日志不一致而失败，减少 nextIndex 重试&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果存在一个满足&lt;code&gt;N &amp;gt; commitIndex&lt;/code&gt;的 N，并且大多数的&lt;code&gt;matchIndex[i] ≥ N&lt;/code&gt;成立，并且&lt;code&gt;log[N].term == currentTerm&lt;/code&gt;成立，那么令 commitIndex 等于这个 N&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;特性&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;选举安全特性&lt;/td&gt;&#xA;&lt;td&gt;对于一个给定的任期号，最多只会有一个领导人被选举出来&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;领导人只附加原则&lt;/td&gt;&#xA;&lt;td&gt;领导人绝对不会删除或者覆盖自己的日志，只会增加&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;日志匹配原则&lt;/td&gt;&#xA;&lt;td&gt;如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;领导人完全特性&lt;/td&gt;&#xA;&lt;td&gt;如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;状态机安全特性&lt;/td&gt;&#xA;&lt;td&gt;如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;h3&gt;Safty&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Raft Basic&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Raft中的server只有三种状态：Leader / Follower / Candidate。通常情况下（无主备切换时），一个leader其他是follower。Follower处于被动的状态，它不能发起任何请求，只能回应leader和candidate的请求。Leader处理客户端的请求，如果客户端请求发到了follower，follower负责将请求重定向到leader。Candidate是选主过程中用于选出新主。状态转移图如下：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fc9uv9fx6wj20hn07xt9z.jpg&#34; alt=&#34;状态转移图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Raft 将时间话费为不同的 Term, Term 可以是任意长的时间，但是在每个 Term 时间内最多只能有又一个 Leader, Term有一个连续递增的id。每个term以选主开始，选主过程中，若干candidate尝试成为leader。选主过程成功之后进度normal operation的阶段，leader开始服务。选主可能因为选票分裂而失败，此时当前term没有leader，在下一个term继续选主。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fc9vx0s6l6j20ef05odg9.jpg&#34; alt=&#34;Term&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Term是需要持久化保存的。因为是分布式环境，所以不同的机器维护的term可能不一样，term是一个逻辑时钟，因此，当一台机器在与其他机器通信时发现自己的term比较小，应该推进本地的term。如果一台机器发现请求方的term比较小，则要拒绝请求。如果一个candidate发现自己的term落后了，就要退回到follower。&#xA;机器之间使用RPC通信，Raft中只有两种RPC：RequstVote 和 AppendEntries。RequstVote RPC 用于candidate在选主期间拉票。AppendEntries RPC 用于 leader 复制日志到 follower，同时也作为主备之间的心跳 RPC。RPC 请求收不到任何结果时，要定时重试。为了优化性能，RPC可以并发发起。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Leader Election&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Raft使用了心跳机制来触发选主。Server刚启动时，状态处于follower，只要follewer一直收到leader或者candidate发来的rpc，就保持为follower。Leader周期性地向follower发送心跳（用的是AppendEntries RPC，里面不带日志内容）来保持leader的权限。如果一个follower在election timeout时间内没有收到leader的心跳，follower就认为没有leader了，就会开始选主。&#xA;开始选主时，follower先递增本地term（要持久化），然后主机状态切换为candidate。然后主机向其他发送拉票请求，同时也给自己投票。Candidate在这个状态等待，直到如下三种情况发生：&#xA;* a) 该candidate赢得了选主&#xA;* b) 其他机器成为了leader&#xA;* c) 超时间内未能选主成功&#xA;一个candidate赢得选主的判定：在相同的term内，收到了多数派的投票。在给定的term内，每台机器都只能按照先来先服务的规则投一个candidate（要持久化）。收到多数派才可能成为leader，可以避免出现双主。选主成功之后，新主向其他主机发送心跳AppendEntries RPC，宣告自己当选了。&#xA;在选主时间内， candidate如果收到了其他主机宣告当选的心跳AppendEntries RPC且RPC中携带的term比本机维护的term更大或相等，本机就自动退为follower。&#xA;超时时间未能内选主成功，可能是发生了选票分裂。同时有若干参与者拉票，选票分流，没有candidate能够拉倒多数派的选票。选主失败时，所有candidate递增term开始下一轮。为了减少选票分裂出现的概率，选举超时时间使用随机化的方法避开多个candidate同时拉票。&#xA;Raft的选主方案的进化。一开始Raft使用的是ranking system，每个candidate都分配一个唯一的rank，低rank的主机收到高rank的主机的拉票请求，就把自己转为follower，这样rank高的就能尽快被选出来（可能在下一轮选主中）。这个方案有些微妙的可用性问题：如果高rank的主机宕机了，低rank的主机还要等超时才有机会转为candidate。这个方案调整了几次，每次调整都引入新的corner case。最后才选择了这个随机化方案。&#xA;Raft的选主方案还要加上一些约束，以支持log replication实现。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Log replication&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Leader被选出来之后，就开始服务客户端的请求。Leader收到客户端请求之后，将命令记入日志并同步到follower。当这条日志被确认之后，就把日志对应的命令应用到状态机。如果某个follower没有收到AppendEntries RPC，leader会不停地重试，确保follower最终有全部的日志。&#xA;日志组织方式如图，&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fc9zgzzchkj20hl0d7wg4.jpg&#34; alt=&#34;日志&#34; /&gt;&#xA;&amp;gt; 日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候，就认为是可以提交了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;每条日志都记录了term值，这个值是提交这条日志的leader当时的term值。这个term值可以用以检测不一致性。&#xA;当leader将日志复制到多数派的时候，这条日志就commit了。Raft保证任何commit的日志最终都会被副本的状态机执行。&#xA;Raft约束日志是连续commit的，leader维护最大已经commit的日志id，并将这个信息附加到AppendEntries告知follower，follower了解到之后即可将本机已有的且已经commit的日志应用到本地的状态机。&#xA;Raft维护了更高级别的不同主机之间的日志的一致性，简化了系统的行为、使得系统行为更加可预测、更容易保证safety。&#xA;Raft保证了如下的约束（Log Matching Safety）：&#xA;不同主机上日志文件中，相同term和相同log id的日志内容一定相同。&#xA;这条相同的日志之前的日志文件内容也一定相同。&#xA;实现这两点也很简单。第一点，只要保证leader给每一条log id只分配一条日志即可。第二点，由AppendEntries RPC保证，AppendEntries RPC在消息中携带term和前一条log id。如果follower发现自己本地的日志并不匹配这个AppendEntries RPC中的log id时，会拒绝这条日志。因此按照归纳法，就可以证明只要某条日志被接收了，那么前面的日志都被接收了，前面的日志文件内容都是一致的。&#xA;正常运行时，主备之间通常都是一致的，AppendEntries RPC也一直成功。但是如果有leader宕机了，就会有不一致。例如如图。&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fca1aw93cnj20gf0baabf.jpg&#34; alt=&#34;冲突&#34; /&gt;&#xA;&amp;gt; 当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能这样发生，那个服务器在任期 2 的时候是领导人，附加了一些日志条目到自己的日志中，在提交之前就崩溃了；很快这个机器就重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在这些任期 2 和任期 3 重点日志被提交之前，这个服务器又宕机了，然后的几个任期里一直处于宕机状态。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;主备不一致可能有如下几种情况：少了一些日志（term可能相同或者少了）；多了一些未commit的日志（term可能多了也可能少了）；某些term多了一些日志且某些term少了一些日志。&#xA;Raft中如何解决这些不一致呢？leader强制让follower的日志文件复制leader的日志文件，即follower上不一致的日志文件内容被覆写。新主上任之后，在和某个follower同步日志时，先确定和这个follower最后一条相同的日志，然后用leader上的内容覆盖之后不相同的部分。当然，为了避免已经commit的日志被覆盖，选主时需要特别注意，后面会讨论这个问题。&#xA;Leader确定与follower不一致点的方法：leader维护一个log id，初始为leader本地最大的log id，然后发送AppendEntries RPC到follower，follower在收到AppendEntries之后，检查RPC中携带的term和log id（leader上被追加的这条日志的前面一条日志的term和log id），如果follower本地没有这条日志，就拒绝此次AppendEntries RPC，leader就能知道follower的同步点更靠前，逐渐就能知道同步点的位置。当然，实际实现时，会使用更有效率的方法。&#xA;通过这种方法，leader上任后，并不需要做特殊的操作，只用AppendEntries就可以逐渐使follower上的日志文件保持一致。Leader从不覆写自己的日志文件，即Leader Append-Only Property。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Safety&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;Election restriction&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;如果不对选主加约束，那么，可能一个落后的follower被选为主，落后的那些日志可能已经commit了，要保证log matching property，就必然要有从旧主或者其他不落后的follower上拉取这些已经commit的日志。&#xA;Raft使用的方案是：确保包含所有commit日志的candidate才能有机会被选为leader。因为一条日志commit，必然在任意一个多数派中，至少有一台主机包含了这条日志。选举时，candidate要和至少多数派的主机通信，通信时带上自己本地的日志信息（本地最后一条的term和log id），接收消息的主机发现发送消息的candidate的日志并不比我本地更新，就拒绝投票。也就是说，candidate至少是某个多数派中拥有最新日志的主机，才能被选为leader。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Commit entries from previous terms&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;考虑如下场景：&#xA;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fcc521xcvnj20ih08o75m.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;如图的时间序列展示了为什么领导人无法通过老的日志的任期号来判断其提交状态。在 (a) 中，S1 是领导者，部分的复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 &amp;copy;，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。但是，在崩溃之前，如果 S1 在自己的任期里复制了日志条目到大多数机器上，如 (e) 中，然后这个条目就会被提交（S5 就不可能选举成功）。 在这个时候，之前的所有日志就会被正常提交处理。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;出现这个问题的根本原因是S1在时序&amp;copy; 的任期4内提交了一个之前任期2的log，这样S1提交的日志中最大的term仅仅是2，那么一些日志比较旧的server，比如S5(它最日志的term为 3)，就有机会成为leader，并覆盖S1提交的日志。解决办法就是S1在时序&amp;copy;的任期term4提交term2的旧日志时，旧日志必须附带在当前term 4的日志下一起提交。这样就把S1日志的最大term提高到了4，让那些日志比较旧的S5没有机会竞选成为Leader，也就不会用旧的日志覆盖已经提交的日志了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;简单点说，Leader如果要提交之前term的旧日志，那么必须要提交一条当前term的日志。提交一条当前term的日志相当于为那些旧的日志加了一把安全锁，让那些日志比较旧的server失去得到Leader的机会，从而不会修改那些之前term的旧日志。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Safety argument&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到该领导人未来某个任期的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fcc713vey3j20d3075js9.jpg&#34; alt=&#34;安全性论证&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;如果 S1 （任期 T 的领导者）提交了一条新的日志在它的任期里，然后 S5 在之后的任期 U 里被选举为领导人，然后至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。&lt;/li&gt;&#xA;&lt;li&gt;领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人T 的日志条目，并且给领导人U 投票了，如图 9。这个投票者是产生这个矛盾的关键。&lt;/li&gt;&#xA;&lt;li&gt;这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。&lt;/li&gt;&#xA;&lt;li&gt;投票者在给领导人 U 投票时依然保有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有和领导人冲突的时候才会删除条目。&lt;/li&gt;&#xA;&lt;li&gt;投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。&lt;/li&gt;&#xA;&lt;li&gt;首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。&lt;/li&gt;&#xA;&lt;li&gt;除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交当然日志，这里产生矛盾。&lt;/li&gt;&#xA;&lt;li&gt;这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。&lt;/li&gt;&#xA;&lt;li&gt;日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (d) 中的索引 2。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果已经服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Follower and candidate crash&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Timing and availability&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换在服务器崩溃时花费更多的时间，候选人将不会等待太长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举出并维持一个稳定的领导人除非整个系统满足下面的时间要求：&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;广播时间（broadcastTime）  &amp;lt;&amp;lt;  选举超时时间（electionTimeout） &amp;lt;&amp;lt;  平均故障间隔时间（MTBF）&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统上是很小的情况。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Cluster Membership changes&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;之前的讨论都是假设成员组是不变的。这一节描述Raft的成员变更方案。&#xA;要保证成员变更过程中的safety，就要保证在任何时候，都不会出现双主。&#xA;如果一次成员变更中，将成员组立刻切换为新的成员组，那么就会因为各个成员之间不能同时生效而导致双主，如图。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fccbvshy16j20f00a374x.jpg&#34; alt=&#34;双主的情况&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;从(S1,S2,S3)变为(S1,S2,S3,S4,S5)的变更中，因为各个成员上变更生效时间不同，可能导致在中间某个时刻，出现两个disjoint majorities，两个多数派能够分别选主并服务客户端，导致一致性无法保证。&#xA;为了保证safety，常规的解法是使用两个阶段。例如，在Viewstamped Replication协议里，成员变更先停止旧的成员组，然后启用新的成员组，但是这样导致中间会有停服务的问题。&#xA;Raft里采用的两阶段方案是，集群先进入一个称之为Joint Consensus的过渡状态，等过渡状态commit了，再只使用新的成员组。在Joint Consensus中，不管是日志复制（客户端提交的普通日志）还是选主，都要在新旧两个成员组C_old、C_new内分别形成多数派。&#xA;成员变更命令通过成员变更日志作为载体复制到其他副本。一个副本只要收到了成员变更日志，之后的日志就立刻使用新的成员组开始工作，不管这条成员变更是不是commit了。也就是说，leader要用两个多数派C_old,new同时满足来commit这条成员变更日志。&#xA;因为有Joint Consensus，所以在C_old,new commit之前，C_new无法单方面确认任何事情。那么，在C_old,new commit之前如果leader宕机了呢？这种情况下，C_old或者C_old,new可能选出新的leader（取决于新主上是否有C_old,new这条日志）。同样，C_new仍然无法单方面确认任何事情。&#xA;一旦C_old,new commit了，那么即使leader宕机，选出来的新leader也一定有C_old,new这条日志了（选主的约束：Leader拥有全部commit的日志）。此时，leader发起一个成员变更，将状态转为只使用C_new的状态（这条日志也记为C_new）。直到C_new被commit了，C_old便不再被需要。成员变更的两个阶段就完成了。&#xA;这个过程如图示：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fccchdn7t2j20gq088q3t.jpg&#34; alt=&#34;中间态&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;成员变更保证safety，要遵循的原则是：在任何时候都不允许C_old和C_new同时可以单方面做决定。例如图中上半部分，C_old和C_new分别可以单方面做决定的时间段是没有重叠的，中间使用C_old,new过渡。&#xA;成员变更还有三个延伸的问题：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;问题1：新加入的主机上可能没有任何日志，在实际执行成员变更前，我们希望这台主机先作为观察者基本追上leader的日志，再做成员变更。否则加入的这台空机器在追上之前，几乎起不到高可用的目的。&lt;/li&gt;&#xA;&lt;li&gt;问题2：如果leader并不是C_new的一员，那么leader要卸任。因为C_new的commit是这个leader主导的，因此在C_new commit之后，leader要卸任。&lt;/li&gt;&#xA;&lt;li&gt;问题3：如果是机器下线的变更，被下线的机器因为不会再收到C_new中的leader的心跳而超时触发选主了。C_new中的leader因为term比下线机器的term小，因此会卸任，又因为C_new中的副本拥有最多的日志，选主约束仍会从C_new中选出一个leader。同样，下线的机器会再次超时，又触发选主，周而复始，虽然不会有safety问题，但是可用性却因为leader反复卸任再上任而降低。Raft的方法也很简单：如果一台主机认为还有leader，那么就不会给其他人投票。这是一个非常有效的补丁（是补丁），这个补丁完美躲避了对选举核心机制的修改，我真是不知道说什么好了。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Raft在Joint Consensus之后，引入了一阶段成员变更：在一次只变更一个成员组的情况下，成员变更可以直接从C_old变为C_new，接收到C_new的成员立刻使用新的成员组。&#xA;因为每次只变更一个成员，所以新旧多数派必有交集（可以按照奇偶加减成员四种情况穷举推算）。 那么，即使没有过渡阶段，也不会出现新旧成员组同时能够单方面做决定的情况。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;日志压缩&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Raft 的日志在正常操作中不断的增长，但是在实际的系统中，日志不能无限制的增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://7xnp02.com1.z0.glb.clouddn.com/4858d6a8ly1fccdvbs2y7j20g70ae75i.jpg&#34; alt=&#34;snapshap&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：&lt;strong&gt;最后被包含索引&lt;/strong&gt;指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），&lt;strong&gt;最后被包含的任期&lt;/strong&gt;指的是该条目的任期号。保留这些数据是为了支持快照前的第一个条目的附加日志请求时的一致性检查，因为这个条目需要最后的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;安装快照 RPC&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&lt;p&gt;在领导人发送快照给跟随者时使用到。领导人总是按顺序发送。&lt;/p&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;参数&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;term&lt;/td&gt;&#xA;&lt;td&gt;领导人的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;leaderId&lt;/td&gt;&#xA;&lt;td&gt;领导人的 Id，以便于跟随者重定向请求&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;lastIncludedIndex&lt;/td&gt;&#xA;&lt;td&gt;快照中包含的最后日志条目的索引值&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;lastIncludedTerm&lt;/td&gt;&#xA;&lt;td&gt;快照中包含的最后日志条目的任期号&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;offset&lt;/td&gt;&#xA;&lt;td&gt;分块在快照中的偏移量&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;data[]&lt;/td&gt;&#xA;&lt;td&gt;原始数据&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;done&lt;/td&gt;&#xA;&lt;td&gt;如果这是最后一个分块则为 true&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;结果&lt;/th&gt;&#xA;&lt;th&gt;解释&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;term&lt;/td&gt;&#xA;&lt;td&gt;当前任期号，便于领导人更新自己&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;接收者实现&lt;/strong&gt;：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果&lt;code&gt;term &amp;lt; currentTerm&lt;/code&gt;就立即回复&lt;/li&gt;&#xA;&lt;li&gt;如果是第一个分块（offset 为 0）就创建一个新的快照&lt;/li&gt;&#xA;&lt;li&gt;在指定偏移量写入数据&lt;/li&gt;&#xA;&lt;li&gt;如果 done 是 false，则继续等待更多的数据&lt;/li&gt;&#xA;&lt;li&gt;保存快照文件，丢弃索引值小于快照的日志&lt;/li&gt;&#xA;&lt;li&gt;如果现存的日志拥有相同的最后任期号和索引值，则后面的数据继续保持&lt;/li&gt;&#xA;&lt;li&gt;丢弃整个日志&lt;/li&gt;&#xA;&lt;li&gt;使用快照重置状态机&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者直接丢弃他所有的日志；这些会被快照所取代，但是可能会和没有提交的日志产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照之后的条目必须正确和保留。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;客户端交互&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可以执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为领导人响应客户端请求时可能已经被新的领导人作废了，但是他还不知道。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道那些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;参考&lt;/h2&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf&#34;&gt;In Search of an Understandable Consensus Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md&#34;&gt;Raft 论文中文翻译&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://loopjump.com/raft_paper_note/&#34;&gt;Raft论文解读 | LoopJump&amp;rsquo;s Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.jianshu.com/p/4711c4c32aab&#34;&gt;raft理解&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/Raft 算法笔记.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>rust 笔记 - 结构体</title>
    <updated>2017-07-05T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-05:/2017/rust 笔记 - 结构体.html</id>
    <content type="html">&lt;p&gt;入坑 rust&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;结构体&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// 定义&#xA; struct User {&#xA;    username: String,&#xA;    email: String,&#xA;    sign_in_count: u64,&#xA;    active: bool,&#xA;}&#xA;// 声明使用&#xA;let user1 = User {&#xA;    email: String::from(&amp;quot;someone@example.com&amp;quot;),&#xA;    username: String::from(&amp;quot;someusername123&amp;quot;),&#xA;    active: true,&#xA;    sign_in_count: 1,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;为了从结构体中获取某个值，可以使用点号。如果我们只想要用户的邮箱地址，可以用user1.email。&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;通过衍生 trait 增加实用功能&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#[derive(Debug)]&#xA;struct Rectangle {&#xA;    length: u32,&#xA;    width: u32,&#xA;}&#xA;&#xA;fn main() {&#xA;    let rect1 = Rectangle { length: 50, width: 30 };&#xA;&#xA;    println!(&amp;quot;rect1 is {:?}&amp;quot;, rect1); // {} Display , {:?} Debug&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;方法&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#[derive(Debug)]&#xA;struct Rectangle {&#xA;    length: u32,&#xA;    width: u32,&#xA;}&#xA;&#xA;impl Rectangle {&#xA;    fn area(&amp;amp;self) -&amp;gt; u32 {&#xA;        self.length * self.width&#xA;    }&#xA;}&#xA;&#xA;fn main() {&#xA;    let rect1 = Rectangle { length: 50, width: 30 };&#xA;&#xA;    println!(&#xA;        &amp;quot;The area of the rectangle is {} square pixels.&amp;quot;,&#xA;        rect1.area()&#xA;    );&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;方法的第一个参数可以是 &amp;amp;self / self / &amp;amp;mut self(可变引用)&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;关联函数&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;impl块的另一个好用的功能是：允许在impl块中定义不以self作为参数的函数。这被称为关联函数（associated functions），因为他们与结构体相关联。即便如此他们也是函数而不是方法，因为他们并不作用于一个结构体的实例。你已经使用过一个关联函数了：String::from。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;关联函数经常被用作返回一个结构体新实例的构造函数。例如我们可以提供一个关联函数，它接受一个维度参数并且用来作为长和宽，这样可以更轻松的创建一个正方形Rectangle而不必指定两次同样的值：&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;impl Rectangle {&#xA;    fn square(size: u32) -&amp;gt; Rectangle {&#xA;        Rectangle { length: size, width: size }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;使用结构体名和::语法来调用这个关联函数：比如let sq = Rectangle::square(3);。这个方法位于结构体的命名空间中：::语法用于关联函数和模块创建的命名空间。&lt;/p&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 结构体.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
  <entry>
    <title>rust 笔记 - 所有权 &amp;&amp; 引用</title>
    <updated>2017-07-03T00:00:00Z</updated>
    <id>tag:int64.me,2017-07-03:/2017/rust 笔记 - 所有权 &amp;&amp; 引用.html</id>
    <content type="html">&lt;p&gt;入坑 rust&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;所有权&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;规则：&#xA;1. 每一个值都被它的所有者（owner）变量拥有。&#xA;2. 值在任意时刻只能被一个所有者拥有。&#xA;3. 当所有者离开作用域，这个值将被丢弃。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;变量作用域&lt;/h3&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当变量进入作用域，它就是有效的。&lt;/li&gt;&#xA;&lt;li&gt;这一直持续到它离开作用域为止。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;{                      // s is not valid here, it’s not yet declared&#xA;    let s = &amp;quot;hello&amp;quot;;   // s is valid from this point forward&#xA;&#xA;    // do stuff with s&#xA;}                      // this scope is now over, and s is no longer valid&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;String 类型&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;基础类型大多数都是存储在栈上并且在离开作用域的时候被移出栈，String 类型是存储在堆上的类型，以 String 类型研究 Rust 如何清理数据都。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;先说 String 数据移动&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let s1 = String::from(&amp;quot;hello&amp;quot;);&#xA;let s2 = s1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;https://kaisery.github.io/trpl-zh-cn/img/trpl04-02.svg&#34; alt=&#34;内存操作图&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;String::form 从堆上分配一块内存存储数据，然后s1指针指向数据内存，当将 s1 赋值给 s2 的时候，不会复制数据，只是将 s2 的指针同样指向之前分配的数据块，同事s1将数据的控制权移交给s2, s1也就无法被继续操作。&#xA;但是对于栈上的数据，就是会直接copy数据，并不会存在这样的控制权移交的情况。栈上的数据实际是拥有copy trait，如果一个类型拥有Copy trait，一个旧的变量在（重新）赋值后仍然可用。Rust 不允许自身或其任何部分实现了Drop trait 的类型使用Copy trait。如果我们对其值离开作用域时需要特殊处理的类型使用Copy注解，将会出现一个编译时错误。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;所有权与函数&lt;/h3&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let s = String::from(&amp;quot;hello&amp;quot;);  // s comes into scope.&#xA;&#xA;    takes_ownership(s);             // s&#39;s value moves into the function...&#xA;                                    // ... and so is no longer valid here.&#xA;    let x = 5;                      // x comes into scope.&#xA;&#xA;    makes_copy(x);                  // x would move into the function,&#xA;                                    // but i32 is Copy, so it’s okay to still&#xA;                                    // use x afterward.&#xA;&#xA;} // Here, x goes out of scope, then s. But since s&#39;s value was moved, nothing&#xA;  // special happens.&#xA;&#xA;fn takes_ownership(some_string: String) { // some_string comes into scope.&#xA;    println!(&amp;quot;{}&amp;quot;, some_string);&#xA;} // Here, some_string goes out of scope and `drop` is called. The backing&#xA;  // memory is freed.&#xA;&#xA;fn makes_copy(some_integer: i32) { // some_integer comes into scope.&#xA;    println!(&amp;quot;{}&amp;quot;, some_integer);&#xA;} // Here, some_integer goes out of scope. Nothing special happens.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3&gt;返回值与作用域&lt;/h3&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let s1 = gives_ownership();         // gives_ownership moves its return&#xA;                                        // value into s1.&#xA;&#xA;    let s2 = String::from(&amp;quot;hello&amp;quot;);     // s2 comes into scope.&#xA;&#xA;    let s3 = takes_and_gives_back(s2);  // s2 is moved into&#xA;                                        // takes_and_gives_back, which also&#xA;                                        // moves its return value into s3.&#xA;} // Here, s3 goes out of scope and is dropped. s2 goes out of scope but was&#xA;  // moved, so nothing happens. s1 goes out of scope and is dropped.&#xA;&#xA;fn gives_ownership() -&amp;gt; String {             // gives_ownership will move its&#xA;                                             // return value into the function&#xA;                                             // that calls it.&#xA;&#xA;    let some_string = String::from(&amp;quot;hello&amp;quot;); // some_string comes into scope.&#xA;&#xA;    some_string                              // some_string is returned and&#xA;                                             // moves out to the ```callfn main() {&#xA;    let s1 = String::from(&amp;quot;hello&amp;quot;);&#xA;&#xA;    let len = calculate_length(&amp;amp;s1);&#xA;&#xA;    println!(&amp;quot;The length of &#39;{}&#39; is {}.&amp;quot;, s1, len);&#xA;}&#xA;&#xA;fn calculate_length(s: &amp;amp;String) -&amp;gt; usize {&#xA;    s.len()&#xA;}&#xA;                                             // function.&#xA;}&#xA;&#xA;// takes_and_gives_back will take a String and return one.&#xA;fn takes_and_gives_back(a_string: String) -&amp;gt; String { // a_string comes into&#xA;                                                      // scope.&#xA;&#xA;    a_string  // a_string is returned and moves out to the calling function.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2&gt;引用&lt;/h2&gt;&#xA;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() {&#xA;    let s1 = String::from(&amp;quot;hello&amp;quot;);&#xA;&#xA;    let len = calculate_length(&amp;amp;s1);&#xA;&#xA;    println!(&amp;quot;The length of &#39;{}&#39; is {}.&amp;quot;, s1, len);&#xA;}&#xA;&#xA;fn calculate_length(s: &amp;amp;String) -&amp;gt; usize {&#xA;    s.len()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;https://kaisery.github.io/trpl-zh-cn/img/trpl04-05.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;可变引用&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;使用 mut 修饰，不过可变引用有一个很大的限制：在特定作用域中的特定数据有且只有一个可变引用，我们也不能在拥有不可变引用的同时拥有可变引用。不可变引用的用户可不希望在它的眼皮底下值突然就被改变了！然而，多个不可变引用是没有问题的因为没有哪个读取数据的人有能力影响其他人读取到的数据。&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;引用的规则&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;简要的概括一下对引用的讨论：&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在任意给定时间，只能拥有如下中的一个:一个可变引用;任意数量的不可变引用。&lt;/li&gt;&#xA;&lt;li&gt;引用必须总是有效的。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="http://int64.me/2017/rust 笔记 - 所有权 &amp;&amp; 引用.html"></link>
    <author>
      <name>cwen</name>
    </author>
  </entry>
</feed>